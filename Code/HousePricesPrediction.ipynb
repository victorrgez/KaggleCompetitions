{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 79)\n",
      "(1459, 79)\n"
     ]
    }
   ],
   "source": [
    "# The input file is read and it is splitted into X and Y:\n",
    "\n",
    "train_data = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\n",
    "test_data  = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\n",
    "Y = train_data[\"SalePrice\"]\n",
    "X = train_data.drop([\"SalePrice\",\"Id\"], axis=1)\n",
    "IdTest = test_data.Id\n",
    "test_data = test_data.drop(\"Id\", axis = 1)\n",
    "\n",
    "print (X.shape)\n",
    "print (test_data.shape)\n",
    "#print (train_data.iloc[:,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the columns of the original dataset were analysed and the following conclusions were drawn:\n",
    "\n",
    "# For some columns we just dont have enough data so as the model could learn what each categorical possibility means in terms of price. For example the neighborhood. This kind of categorical features that are splitted into several columns just add noise to the data if you dont have enough examples.\n",
    "X         = X.drop        ([\"Neighborhood\",\"Exterior1st\",\"Exterior2nd\",\"GarageType\",\"Condition1\",\"Condition2\"], axis =1)\n",
    "test_data = test_data.drop([\"Neighborhood\",\"Exterior1st\",\"Exterior2nd\",\"GarageType\",\"Condition1\",\"Condition2\"], axis =1)\n",
    "\n",
    "# For MSSubClass, there is no point in treating the categories as numbers, given that a bigger or smaller number doesn't mean more or less value:\n",
    "X[\"MSSubClass\"]          = X[\"MSSubClass\"].astype(str)\n",
    "test_data [\"MSSubClass\"] = test_data[\"MSSubClass\"].astype(str)\n",
    "\n",
    "# Other columns express the quality of some part of the house. That should not be included in the get_dummies function.\n",
    "# It would be desirable to transform the scale from Excellent to Poor into a numerical scale, such as from 5 to 1.\n",
    "fromStringToInt = {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,np.nan:0}\n",
    "qualityColumns = [\"ExterQual\",\"ExterCond\",\"BsmtQual\",\"BsmtCond\",\"HeatingQC\",\"KitchenQual\",\"FireplaceQu\",\"GarageQual\",\"GarageCond\",\"PoolQC\"]\n",
    "for column in qualityColumns:\n",
    "    X[column].replace(fromStringToInt, inplace=True)\n",
    "    test_data[column].replace(fromStringToInt, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the columns need a specific dictionary to convert from String to Categorical Quality Numbers:\n",
    "fromStringToIntLotShape = {\"Reg\":4,\"IR1\":3,\"IR2\":2,\"IR3\":1,np.nan:0}\n",
    "X[\"LotShape\"].replace(fromStringToIntLotShape, inplace=True)\n",
    "test_data[\"LotShape\"].replace(fromStringToIntLotShape, inplace=True)\n",
    "\n",
    "fromStringToIntUtilities = {\"AllPub\":4,\"NoSewr\":3,\"NoSeWa\":2,\"ELO\":1,np.nan:0}\n",
    "X[\"Utilities\"].replace(fromStringToIntUtilities, inplace=True)\n",
    "test_data[\"Utilities\"].replace(fromStringToIntUtilities, inplace=True)\n",
    "\n",
    "fromStringToIntLandSlope = {\"Gtl\":3,\"Mod\":2,\"Sev\":1,np.nan:0}\n",
    "X[\"LandSlope\"].replace(fromStringToIntLandSlope, inplace=True)\n",
    "test_data[\"LandSlope\"].replace(fromStringToIntLandSlope, inplace=True)\n",
    "\n",
    "fromStringToIntBsmtFinType = {\"GLQ\":6,\"ALQ\":5,\"BLQ\":4,\"Rec\":3,\"LwQ\":2,\"Unf\":1,np.nan:0}\n",
    "X[\"BsmtFinType1\"].replace(fromStringToIntBsmtFinType, inplace=True)\n",
    "test_data[\"BsmtFinType1\"].replace(fromStringToIntBsmtFinType, inplace=True)\n",
    "X[\"BsmtFinType2\"].replace(fromStringToIntBsmtFinType, inplace=True)\n",
    "test_data[\"BsmtFinType2\"].replace(fromStringToIntBsmtFinType, inplace=True)\n",
    "\n",
    "fromStringToIntFunctional = {\"Typ\":8,\"Min1\":7,\"Min2\":6,\"Mod\":5,\"Maj1\":4,\"Maj2\":3,\"Sev\":2,\"Sal\":1,np.nan:0}\n",
    "X[\"Functional\"].replace(fromStringToIntFunctional, inplace=True)\n",
    "test_data[\"Functional\"].replace(fromStringToIntFunctional, inplace=True)\n",
    "\n",
    "fromStringToIntGarageFinish = {\"Fin\":3,\"RFn\":2,\"Unf\":1,np.nan:0}\n",
    "X[\"GarageFinish\"].replace(fromStringToIntGarageFinish, inplace=True)\n",
    "test_data[\"GarageFinish\"].replace(fromStringToIntGarageFinish, inplace=True)\n",
    "\n",
    "fromStringToIntPavedDrive = {\"Y\":3,\"P\":2,\"N\":1,np.nan:0}\n",
    "X[\"PavedDrive\"].replace(fromStringToIntPavedDrive, inplace=True)\n",
    "test_data[\"PavedDrive\"].replace(fromStringToIntPavedDrive, inplace=True)\n",
    "\n",
    "fromStringToIntFence = {\"GdPrv\":4,\"MnPrv\":3,\"GdWo\":2,\"MnWw\":1,np.nan:0}\n",
    "X[\"Fence\"].replace(fromStringToIntFence, inplace=True)\n",
    "test_data[\"Fence\"].replace(fromStringToIntFence, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 73)\n",
      "(1459, 73)\n"
     ]
    }
   ],
   "source": [
    "print (X.shape)\n",
    "print (test_data.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before splitting categorical variables, let's get only the numerical columns and check which ones are skewed:\n",
    "nameOfNumericColumns = X.dtypes[X.dtypes!=\"object\"].index\n",
    "skewedVariables = X[nameOfNumericColumns].skew()\n",
    "for index, value in enumerate (skewedVariables):\n",
    "    if (value > 1):\n",
    "        X[nameOfNumericColumns[index]]         = np.log (X[nameOfNumericColumns[index]]+0.001)\n",
    "        test_data[nameOfNumericColumns[index]] = np.log (test_data[nameOfNumericColumns[index]]+0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 73)\n",
      "(2919, 65)\n",
      "(2919, 139)\n"
     ]
    }
   ],
   "source": [
    "# All the columns with a greater percentage than desired of NaNs are dropped since they will not generalise well:\n",
    "\n",
    "percentageMissingValuesPerColumn = (len(X)-X.count())/len(X)*100\n",
    "maxPercentageDesired = 0.05 # 5%\n",
    "falseTrueColumns = percentageMissingValuesPerColumn>maxPercentageDesired\n",
    "columnIndexesToBeDropped = []\n",
    "for i in range (X.shape[1]):\n",
    "    if (falseTrueColumns[i]): # True means that column has more percentage of NaNs than desired\n",
    "        columnIndexesToBeDropped.append(i)\n",
    "print (X.shape)\n",
    "X_clean = X.drop(X.columns[columnIndexesToBeDropped], axis=1)\n",
    "test_data_clean = test_data.drop(test_data.columns[columnIndexesToBeDropped], axis=1)\n",
    "allData = pd.concat([X_clean, test_data_clean])\n",
    "print (allData.shape)\n",
    "allData_clean = pd.get_dummies(allData)\n",
    "print (allData_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2919, 97)\n"
     ]
    }
   ],
   "source": [
    "variancePerColumn  = allData_clean.var( axis=0)\n",
    "maximumPerColumn   = allData_clean.max( axis=0)\n",
    "\n",
    "columnsWorthKeeping = []\n",
    "\n",
    "for i in range (len (variancePerColumn)):\n",
    "     if ((variancePerColumn[i]/maximumPerColumn[i])> 0.01):\n",
    "        columnsWorthKeeping.append(i)\n",
    "allData_clean = allData_clean.iloc[:,columnsWorthKeeping]\n",
    "print (allData_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 97)\n",
      "(1459, 97)\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean (allData_clean)\n",
    "#print (mean.shape)\n",
    "allData_clean = np.array(allData_clean.values)\n",
    "\n",
    "\n",
    "for i in range (allData_clean.shape[0]):\n",
    "    for j in range (allData_clean.shape[1]):\n",
    "        if (np.isnan(allData_clean[i][j])):\n",
    "            allData_clean[i][j] = mean[j]\n",
    "\n",
    "X_clean = allData_clean[:1460]\n",
    "test_data_clean = allData_clean[1460:]\n",
    "\n",
    "print (X_clean.shape)\n",
    "print (test_data_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 97)\n",
      "(1460,)\n",
      "(1459, 97)\n",
      "(1459,)\n"
     ]
    }
   ],
   "source": [
    "# Split the X_clean data into train and validation sets. There are 1460 examples so 1200 / 260 seems reasonable:\n",
    "random_list = np.random.permutation(1460)\n",
    "cuttingNumber = 1200\n",
    "\n",
    "X_clean = np.array(X_clean)\n",
    "X_train = X_clean [random_list[:cuttingNumber]]\n",
    "Y_train = Y       [random_list[:cuttingNumber]]\n",
    "X_val   = X_clean [random_list[cuttingNumber:]]\n",
    "Y_val   = Y       [random_list[cuttingNumber:]]\n",
    "test_data_clean = np.array(test_data_clean)\n",
    "\n",
    "print (X_clean.shape)\n",
    "print (Y.shape)\n",
    "print (test_data_clean.shape)\n",
    "print (IdTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAAEWCAYAAAAkUJMMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOxdd3xN5xv/ngyJJCREECJiz0hCrBg1S9WqUbOqqOqgtHSYQXWqUlVarWqNosMufkWNKjVjb2JTQiIisu7398dzzh3JvclNZOF8P5/zOfe88znjvs/7jPd5FZLQoUOHDh068goOeU2ADh06dOh4sqEzIh06dOjQkafQGZEOHTp06MhT6IxIhw4dOnTkKXRGpEOHDh068hQ6I9KhQ4cOHXkKnRFlAxRFCVcUhYqizFev+6vXWx6mnfwERVECVNqoKIpXXtOTk1AUJVK9z2ZZrG98VtlMWr6Coihb1Pvsn9e05BXM/rMr1Otm6nVkDvRlMa7kcF+5OhblO0ZkNghoxy1FUTYoihKaqlwHRVE2KYoSrSjKfUVRjiuKMilVmQpm7VxVFMXxIehaYNbWq1ltx6w9ra2Ah20rv0JRlPnqPYY/zn3mV2TXQJWTA95jiMsAZgCYZ0/hTE56jqlt/5p18qzSYG0s2qX29b/s7MsWnHKjkyxiDYDzAJ4C8DSAuoqiVCX5n6IoowB8qpb7B/KCqgB4A8B4szb6mv32BdASWXiwiqK4AehslvQCgNmZbScnoCiKE8nkvKZDhw4dAMkzAIZnd7uKojiT3A1gd3a3bQ0k1wNYnxt9aR3mqwNAJAAC6KxeF1OvCaATgDIAEtXrD1PVrZbq+pRabr96/ilVfn81PSIDmvqo5Y4BeKD+rmCWH66mzU/V7hYb7dHK0cysnaUAvgdwD8AZAK2sPJ8xAI4CSFHTvQF8o+bHAtgBoIlZPTcAH6vtxanPpHM691wAwmzvqHUGm9HqpZb5XO3vAYD7kFlUMzVvvpV7nA/AGcCfAK6r7zEawCoAZdR6CoAPAVwCkKCW2wDAO6P7TKfPAgDmqm0lqG2vsuMbfAtAhNrPco0GtUxjAFvU53MVMgPWaAzQ+jcrHwDgFwDX1Dp/Aahvlr9FrfMRgG3q89wBoKxZmS7qu7gLYBqArWqd4VbuoZmVZ0E1zx3AZwDOQr6xCAAv2HgW6bWj0TwRwGYbNNcEsBbAfwBuAvgNgH86z364StcDtfwWAFXUvJEATkO+3wQABwF0M6urvf+fAKwDEA+ZeJZV+40DsBNAuYegrzrkO78PYDWAmWqfK1I9r0iz/5HVbw+m78z86A/T+PE35D8YCxkbtPQtqfsCMEql/wqAt618V/1t0JfRWDTfrK3nAOxR6bkAYBZMY0GAWf0BAC5CvvMv7Br3s4N5ZOdh9nI6Q1SHXc1usBGAl9XfKQDc0mmnvlruHmTQ0H67m5XRXmxGjGidWm4sRFIjgAlm+RYvLfUHY6W96Wb3NE+9rmjWjgHARsgHTwAXrTyfZABLIIObg/rREjKILVI/lniY/sQ/q/n7IH/Um2o/zWzQOFEtH6XSeNWMZu3j+x3CNGdB/sxU2y0EoDeEcVO9j+lqmguAIwB+VOtpk4T1aputYPpzfQ1gmdp3QEb3mU6fg9S0I2qbKwBE2fEN3lXv/bx6/ZvZ4JWg9v0zTH/2zRBGGqA9K7OB/5yathUy2BEyMFZINWCkqPd1Ub1eoOZXBJCkpq2EDKgpsM2IKkJUONp9TAcwXc1bpqafUu8vTr3ulcl2NJqTbNBcEsBtyITjd5j+O8cBuNjoS/uG5gBYrD43bXIzS21nlnoPyRCGFZCKERkg/4sr6nU0gE0ADqvXC7NInxNkIkDIgKzRkB4jsvntQbQ3d9X8X9VnWw+m8YMATkImXv1gmxGlqPe2AKZvpIOdjCijsUgb055RrxMg/90jsPzfBpi1cxHyPWjfZ8tHmRGlPlZBBqIx6vX1DNrRZiq/qtcX1Os+ZmU8AVSF+iHbaKe42cutCeH2BHA6q4xILaPdV4CVdo5ABrRyZuWKpXo+k8zq1UWqgQKmAf5jAD5mH+xMNV/7QJfYoE/7w72gXncwo0VjREUhktKHapvagBaWamAIT9V2JYi08an6URMyoDiYffAbIX+a4uqzcMjoPm31CeBVNe1nyGSmCABHO77BN9XrILN794AMhObMbjpMknJVpGVEz6vXZwEoatpyNe3DVAPGLPX6Je1bUK/Hqtd/qdcFILN4q4zI2qBj9j1r91JWTXtTvf7H3nbspHmUen3M7DlpNLe10k81Ne8gRB3vp6Y7qmd3yIA8GcAXEOmSAHqnevcbU/2frkG+H+0bPppF+rQJ7V2ok2CYJhW2GFG63x5M31ozs7T+Zv14WUlPzYiSYBofvlDTfkn1jqwyIjvGIm1M+0O9nqBeF4NpXKwMS0ZUVy2jSewjMxr387uN6AxkRr4PwnmpKMp/ar6PoihuJO+nrqgoihPkzw/IDEQ7D4PYdxYBAMkYADEZ0NELMhM6S/KIoijXIQN6RUVRGpDcleU7tI0I9V6jzdI8ANwyu95h9jtAPReCDCrmqGiW7wCxo6XOt4bS6vmkej5lnqkoijdkFuZrpa6PjTahKEoTiFoqteOIC4T+/0Fmji+o5QCZfXZCxvdpCz9B/oCdAPSEOlgpivIcybh06h1XzyfM0kqb0VFfPVLTcSRVmlb+pMaZzNosm6rsAfWsvXsPs36NNJFMVBTlLNJ51jag0RJP8kIGtNgLWzRrfVVTD3OkeV8kjyuKMgHyP90AAIqinATQTVGUUxDGX9NK/6mfgfbeNHrOkDQoihKrXrtnhT6Y3sFls3HnlJVy5sjqtwcIw4zOoAwA3CSpjQ3au/SzUTarDlsB6ln7/m4pinILIlWWhahMNdj6Hmwi33nNmeF7kiNIfkByndkfeANEHNakIyMURamk/mwDmfkBwALVjXaYet1KUZSSanlPRVGqZuC5pjk8VFDbuQnTy+xrvYpdMKhna+9Acz6glTwNCWa/I9XzVQCuJBWSCsQu9IZZfiIAH7P8AhC9rzVcUc9V1HPlVPlNIEzoJuRjdIHpw1PUc4p6Nr/HrpDntx4yIJgP5Iqa9wYAL8hg8BNEEhpkx33a6jOZZA8AhSEDzkYArSE2l/SgDU5VzdKumNExTaNBpaM8yTVW2tHKV1YURXs22nO9kKqsrXevvY9KgBivAZTPgH5rz0KjpaCiKP4Z0JJeO+awRbPW1++pnpMvxAZqAdWrdQrJYpDB7ROVthEQ20xNlZZKKi3HtKo26LV1nSX6YHoHfqoDE5D2f5EaGX176T3bBCtp1uCjKEox9bf2rV5WzxqzK6yerTHy9MYiDZHm7asTUa1Pi++GJuep9MYvC+RnRmQVJC8CGKdejlYUZYeiKN8qiqLZVAATgzgH0adrxx3IQNdLzX8OwuE1qckCiqJUBqC5jf9h1s5ONa2HOiBkBZfU81eKokxXFMU93dLpY59KUykAexRFmaOua7gKUTHchOizCwD4V83/RaVhoI02F6vn6YqifA/g21T5N9SzD0QdsA1pZz7aPfZVFGWGoijNzerVh6gJF6eqEwaxySyCqO8aqenRGd1nOn32UhTlOIAfIJJUoFmb6WGyoijzYPo+lpO8B3kWSQDeVBRluaIocxVF+RuierOGtZA/cgUAfymK8ivk24uHnW6+ENVOMmQitRyicimWbg3Ts/BTFOU7RVHeJfkfTO6/f6r396F6/ZW97dhJ8yLIM+6iLsH4Rv2fXgJQwkr5MgCuqt/muzC902iINsAA+f9Ogzi8VLLSRmaQWfp2QcaUQgC2KIqyDLYnchoy+va0ZztJHQfKZOE+HCDf1QKYJmQL1LMmnbylKMpUiO03NewZi2ap59Hq2qItEE3RnyQzkgozRka6u9w+kMprLp1ynSCqmxjIH/oEgEmQwVCzVbRLVWeCmr4vlc7VqrOC2h4B7EmVXkjtlxC9czgybyPqAfkADGrZYlba8UIq/S2s6JTVdB+Ih00kxF5xAfJHq6rme0A8sk6r+VchdooGNuhzgRhJoyGMYagZLZqN6AOIsfcm5E9m8e4gqowdkJkdIV5PhdR+41RaXjJvFzK4/AnR1SeqdM6Gajy24z6t9dkQwHaImjdRrTMZqr0mnW9Q85q7B5mAFDMr0xTinBAFcVo4CJO9J0C7J7Py5SEM4Lr6TLcAaGiWvwWWuvzOSKvLN/ea+wImZ5ZX0/nOPoNMwMxtN4Ugg/l59T0c0vrNZDv20FwL4l12Q+3rOMQW42Glj6Jq2avqe/oPwoCLqPmvqc8vBiItaf0PV/Pnq9eaM8VwWLepZIk+tXxNAP9CxpwNkG8xPRtRut+eWv40TIb9UNgYP1Knm/cFk9fcVQDvpHqm6yDf8D6YxkDzZ5DhWKSW6662cQ/ikDDH7N0EIO03vwJWbMTWDu1h6NChI59DURRPil0T6qz1EsT43YrkpjwlToeOh0B+dlbQoUOHJdapap6LANpDmNBBiFpUh45HFjoj0qHj0cFeiDdoEYgK5jsA40km5SlVOnQ8JHTVnA4dOnToyFM8cl5zOnTo0KHj8cJjr5orVqwYAwIC8poMHTp06HiksG/fvlskM7tgOkt47BlRQEAA9u7dm9dk6NChQ8cjBUVRbC1wznboqjkdOnTo0JGn0BmRDh06dOjIU+iMSIcOHTp05CkeexuRDh06sgdJSUm4fPkyHjx4kNek6MhGuLq6ws/PD87OWQ2b+fDQGZEOHTrswuXLl1GoUCEEBATAFERcx6MMkoiKisLly5dRrly5PKNDV83p0KHDLjx48ADe3t46E3qMoCgKvL2981zK1RmRDh067IbOhB4/5Id3qjMiHdmP/fuBLVvymgodOnQ8ItAZkY7sx4wZQLt2wIVcWw+n4wlAVFQUgoODERwcjJIlS6J06dLG68TExHTr7t27F8OGDUu3DACEhYVlC61btmyBp6cnQkJCUK1aNUycaG0/OhPGjx+PjRs3ZtjmP//8ky305Tfozgo6sh9BQcBPPwHDhgErV+Y1NToeE3h7eyMiIgIAEB4eDg8PD4wcOdKYn5ycDCcn60NaaGgoQkNDreaZIzsH+iZNmmDNmjWIi4tDcHAw2rdvjzp16lgtO2nSpAzb27JlCzw8PLKNWeYn6BKRjuyH9kdZtUoOHTpyCP3798dbb72F5s2b491338Xu3bsRFhaGkJAQhIWF4eTJkwBkEG/fvj0AYWIDBgxAs2bNUL58eXz55ZfG9jw8PIzlmzVrhm7duqFq1aro06ePtuso/vjjD1StWhWNGzfGsGHDjO3agru7O+rUqYOzZ88iIiICDRo0QK1atfDcc8/hzp07xvv49VfZwT0gIAATJkxA7dq1ERgYiBMnTiAyMhJz5szBF198geDgYGzfvh2//PILatasiaCgIDRt2jR7H2wuQ5eIdGQ/QkIAFxcgIUGkopYtAXf3vKZKR3Zi+HBAlU6yDcHBwPTpma526tQpbNy4EY6Ojrh79y62bdsGJycnbNy4EaNHj8Zvv/2Wps6JEyfw119/ITY2FlWqVMGrr76aZh3NgQMHcPToUZQqVQqNGjXCjh07EBoaildeeQXbtm1DuXLl0KtXrwzpi4qKwq5duzBu3Dj06tULM2fOxFNPPYXx48dj4sSJmG7lnosVK4b9+/fj66+/xtSpU/Hdd99hyJAhFlJgYGAgNmzYgNKlSyM6OjrTzy0/QZeIdGQ/XFyA0FCgYEGxE02ZktcU6XiM0b17dzg6OgIAYmJi0L17d9SsWRMjRozA0aNHrdZ59tln4eLigmLFiqF48eK4ceNGmjL16tWDn58fHBwcEBwcjMjISJw4cQLly5c3rrlJjxFt374dISEhePrpp/Hee+/Bz88P0dHReOqppwAAL774IrZts765bpcuXQAAderUQWRkpNUyjRo1Qv/+/TF37lykpKTYpONRgC4R6cgZNGwI7NkD9OwJTJ0KvPACUK1aXlOlI7uQBcklp+BuJm2PGzcOzZs3x/LlyxEZGYlmzZpZrePi4mL87ejoiOTkZLvKZGYjUc1GpCEmJsbuulrftmgDgDlz5uDff//F2rVrERwcjIiICHh7e9vdR36CLhHpyBmEhQGJiUCvXoCHB/Daa4C+G7COHEZMTAxKly4NAJg/f362t1+1alWcO3fOKKUsXbrU7rqenp4oUqQItm/fDgBYsGCBUTqyB4UKFUJsbKzx+uzZs6hfvz4mTZqEYsWK4dKlS3a3ld+gMyIdOYOGDeV8+jTw0UeyrmjRojwlScfjj3feeQfvv/8+GjVqlCPqqoIFC+Lrr79G27Zt0bhxY5QoUQKenp521//xxx8xatQo1KpVCxERERg/frzddTt06IDly5cbnRVGjRqFwMBA1KxZE02bNkVQUFBWbilfQMmMqPkoIjQ0lPrGeHmEChXEAP3LL8KYIiOBkycBL6+8pkxHFnD8+HFU09WruHfvHjw8PEASr7/+OipVqoQRI0bkNVkPBWvvVlGUfSQz9nnPBugSkY6cQ8OGwD//AIoCzJkD3LoFjBmT11Tp0PFQmDt3LoKDg1GjRg3ExMTglVdeyWuSHnnojEhHziEsDLh+XTznQkKAN94AZs8GdAlVxyOMESNGICIiAseOHcOiRYvg5uaW1yQ98tAZkY6cg7awVVutPmkSUKIEMGQI8Ii7m+rQoSP7oDMiHTmHmjXFY05jRJ6ewBdfAPv2Ad98k7e06dChI99AZ0Q6cg5OTkD9+iZGBAA9ekikhdGjRW2nQ4eOJx46I9KRs2jYEDh0CLh3T64VBfj6ayA+Hhg1Km9p06FDR76Azoh05CzCwsQetGePKa1yZeCdd4CFC4G//so72nQ8UmjWrBk2bNhgkTZ9+nS89tpr6dbRlm+0a9fOaky28PBwTJ06Nd2+V6xYgWPHjhmv7dm2wR7o20UIdEakI2fRoIGcU/8xRo8GypeXiAsZ7CWjQwcgcd2WLFlikbZkyRK7Ao8CEjXbK4tr2FIzokmTJqFVq1ZZais1mjRpggMHDmDv3r1YuHAh9u3bZ7OsPf3qjEiHjtQoUgSoXj0tIypYEPjqK+DECeDzz/OGNh2PFLp164Y1a9YgISEBABAZGYmrV6+icePGePXVVxEaGooaNWpgwoQJVusHBATg1q1bAIApU6agSpUqaNWqlXGrCEDWCNWtWxdBQUHo2rUr7t+/j3/++QerVq3CqFGjEBwcjLNnz1ps27Bp0yaEhIQgMDAQAwYMMNJnbTuH9PAkbxehBz3VkfNo2BBYvhwwGAAHs7nPM88AXboAkydLcFQ1orGO/I/h64cj4nr2bgMRXDIY09vaDqbq7e2NevXqYf369ejUqROWLFmCHj16QFEUTJkyBUWLFkVKSgpatmyJQ4cOoVatWlbb2bdvH5YsWYIDBw4gOTkZtWvXNm5Y16VLF7z88ssAgLFjx+L777/H0KFD0bFjR7Rv3x7dunWzaOvBgwfo378/Nm3ahMqVK6Nfv36YPXs2hg8fDsD6dg628CRvF6FLRDpyHmFhwO3bwKlTafOmTxfm9OabuU+XjkcO5uo5c7XcsmXLULt2bYSEhODo0aMWarTU2L59O5577jm4ubmhcOHC6NixozHvyJEjaNKkCQIDA7Fo0SKb20hoOHnyJMqVK4fKlSsDSLu1gz3bOejbReSCRKQoyjwA7QH8R7KmmhYO4GUAN9Vio0n+oea9D2AggBQAw0huUNPrAJgPoCCAPwC8ycc9UN7jAvOFrVWrWuaVKQOEh4sH3cqVQKdOuU6ejswjPcklJ9G5c2e89dZb2L9/P+Lj41G7dm2cP38eU6dOxZ49e1CkSBH0798fDx48SLcdRVGspvfv3x8rVqxAUFAQ5s+fjy1btqTbTkZDkD3bOejbReSORDQfQFsr6V+QDFYPjQlVB9ATQA21zteKojiq5WcDGAygknpYa1NHfkTlykDRomntRBrefFMWvw4bBsTF5S5tOh4peHh4oFmzZhgwYIBRGrp79y7c3d3h6emJGzduYN26dem20bRpUyxfvhzx8fGIjY3F6tWrjXmxsbHw9fVFUlISFplFi0+9BYOGqlWrIjIyEmfOnAGQ+a0drOFJ3C4ixxkRyW0AbttZvBOAJSQTSJ4HcAZAPUVRfAEUJrlTlYJ+AtA5ZyjWke1wcBDvuZ07rec7O0sMuosXxV6kQ0c66NWrFw4ePIiePXsCAIKCghASEoIaNWpgwIABaNSoUbr1a9eujR49eiA4OBhdu3ZFkyZNjHmTJ09G/fr10bp1a1Q1k9579uyJzz77DCEhITh79qwx3dXVFT/88AO6d++OwMBAODg4YMiQIQ99j0/cdhEkc/wAEADgiNl1OIBIAIcAzANQRE3/CkBfs3LfA+gGIBTARrP0JgDWpNPfYAB7Aez19/enjnyADz4gAfL2bdtlXnqJdHIijx7NPbryOxYsID/+OK+pIEkeO3Ysr0nQkUOw9m4B7GUu8AeSeeasMBtABQDBAK4B0Px3rSlumU66VZD8lmQoyVAfH5+HpTVHIaNzXlORC9DsRLt22S7zySdAoUL6bq6A3H94uGyxbr4YWIeOxxB5wohI3iCZQtIAYC6AemrWZQBlzIr6AbiqpvtZSX/kER4O1K0L3LiR15TkMOrWBRwdbduJAMDHR5jR1q0SdSEj/Pkn0KdP9tEI2Uj2al5/WcnJwCuvABMnAsWKATNn5jFBOnTkLPKEEak2Hw3PATii/l4FoKeiKC6KopSDOCXsJnkNQKyiKA0UcXfpB2BlrhKdQ/DykmDULVoA//2X19TkIDw8gFq10mdEADBwoNiT3n4bUBfx2cSmTcDixUBSUraQ+MMPQPPmwLRp2dJc1nD/PtC1KzB3rlzPnw/4+qZbRYeORx05zogURfkZwE4AVRRFuawoykAAnyqKclhRlEMAmgMYAQAkjwJYBuAYgPUAXiepOb6/CuA7iAPDWQDpu8Y8IujZU2z5x449AcwoLAzYvVtm/Lbg4CCOC1FRGe/mGh8v5/v3H5q0338HBg2S33fvPnRzWUNUFNCqFbBqlVwPGwY8+2weEaNDR+4hN7zmepH0JelM0o/k9yRfIBlIshbJjqrEo5WfQrICySok15ml7yVZU817QzWmPfLw9ZWxBwDOnn3MmVFYmEThPnIk/XLBwcDQobK9+O7dtstlEyPauBHo1Ut2rChdOlv4WuZx4QLQuLHJszAoSNSUOnQ8AdAjK+QD9O0r5zFjgHPnZLuex5IZpd6xNT1MmgSULAm8+qrt3Vw1jvEQnGPXLqBzZ1lnu3athMbT+Fuu4fBheTZXrgBubhKH7+efAVfXXCZEh468gc6I8gE6d5ax58oVGQzPnhVmdPNmxnXzAu+8A8yYkYWKZcsKc7GHERUuLLu57t8vqjpr0DhGFjnH4cNAu3ZC0oYNwoTc3HJZItq6FWjSRPZpeu456XzGDKBatVwkIvdASshBe8olJoqa9L//ZInZuXNRCA4ORnBwMEqWLInSpUsbrxPtiOCeXlTq+fPnw8fHB8HBwahevTrmajY6Gxg0aFC6YYSAtBG7ddiGzojyAQoVEma0dCnQqBGwZo1JTZffmFFKivCFQ4eyUFlRZOZva2Frajz/PNC6tYiK1nZzfQjV3LlzwNNPywRg40ZhRoBc5xoj+uUXIaJUKfGMW7xYHBU0Y9VjBk0re/68KS0lRYJpREWJt+K5c2IvPXBAvrFTp4QJ/fcf4OrqjYiICERERGDIkCEYMWKE8bpAgQIZ9p/R9gg9evRAREQEtmzZgtGjR+NGOq6s3333HapXr55ufzojsh86I8on6NtXnMTWrRMGlF+Z0bFjMqCoMR4zj7AwGW3s2SZcUWSriAcPxIsuNbKomrt6VexySUniAR4QYMpzc8sl1dzMmbJtemgosH69iJm+vuItZyMO2qMKg0GYz4kTQEKCvM6TJ4XRHDgAHD8u+VevAtHRxP37JqnJyUkmCTVrCr9OjX379uGpp55CnTp10KZNG1y7JubmL7/8EtWrV0etWrXQs2dPq9sj2ELx4sVRoUIFXLhwweYWD+Yb7nl4eGDMmDEICgpCgwYNcOPGDatbR6SmSYcJ+jYQ+QStW8symkWLJO5nixbA6tVAhw6iptu0SfLzGtp61CpVstiAZifauVNUURmhcmXgvffEZjRwoDwYDVmQiKKiRAi5eRPYvFm2SjJHjqvmSJHwPvpIXvTPP4sd7Nw5WcRUpEgOdp59GD4ciEi1C4SmdjM/rDlIKoo4R5ofTDGgUvlkDB3hBEBBoULyvXt5We4cYtkfMXToUKxcuRI+Pj5YunQpxowZg3nz5uHjjz/G+fPn4eLigujoaHh5eaXZHsEWzp07h3PnzsHPzw/169e3ucWDhri4ODRo0ABTpkzBO++8g7lz52Ls2LFpto5ITZMOE3SJKJ/A2VlcuVetArTguy1bCjM6fTr/2Iw0RpRliah2baBAAfvsRBree8+0m6s6IwWQaUZ0757YhM6ckedct27aMjmqmktKAl56SZjQ4MHAr7/KPk0//giMHSu2onwOUl5BQoLYcB48kOd1754c9+9LWmJiWiZUsKAsJ/PwEIYvgaOJhAcGPEh0QKLBCT7u91GjBlGlisTJtcWEACAhIQFHjhxB69atERwcjA8++ACXL18GANSqVQt9+vTBwoUL4eRk33x76dKlCA4ORq9evfDNN9/g5s2b6W7xoKFAgQJo3749gPS3Y8gKTU8K9KeRj9C3r2hsfvsNGDBA0lq2FDVd+/bye/NmWWyfV9i1S2a0FSpksQEXF6BOHfvtRIBpN9d27WQ319GjJT0TqrkHD8QOt2+fPN/mza2XyzHVXFwc0L276F4nTgTGjRN91JAhYhgcNy4HOs06YmJEfaYdJ06I4Hb/vjCjgQOlnKOjOPeZHw4OwLVrwpgAkWzKlFElH8qjuHmTuH0bIBW4Iw4+BeNQpLwXHAt62E0jSdSoUQM7rXxLa9euxbZt27Bq1SpMnjw5w32FALERffXVV8briNQinw04Ozsbt5VIbzsGazTpDEmgP4V8hLp1gUqVJLqNxogAk2RkrqbLC2YUHS02onLltNlsFqxWBZ8AACAASURBVBEWJowlIcH+hp55Rgz5kyfLop9y5eyWiJKTpcqmTSJ8pLflUY6o5m7elIWp+/YB334LvPyySEe9e8vovGiRGENyGSkpQGSkMBlzpnPypKUJz9FRBFInJ6B4cUum4+RkadK6fVu0jJrHfZkyUsdgEIeDW7eI+/cVOMCAYoiCj3MM3Mr6AF4lMk2/i4sLbt68iZ07d6Jhw4ZISkrCqVOnUK1aNVy6dAnNmzdH48aNsXjxYty7dw+FChXC3UysVjbf4qFixYoPtR2DwWCwSpOXl1em7/txhM6I8hEURUKnTZwIXLokf2INrVrlPTPS1pZm2T6kISxMJJsDByScj72YPl0M+0OHysOwgxEZDDLur1gBfPkl0K9f+l0ULJjNEtG5c0CbNsDly6KG03YDDQ8H/v0XWLZM3NpzEHfuWEo22u8zZ0SFpqFoUXm3zzwjZ+2oUEG0qcePW36T5khOFu+22+qGLw4OUs/ZWdKjouRdFHRIQFncQFHlDhxL+gC+FdLXv6UDBwcH/Prrrxg2bBhiYmKQnJyM4cOHo3Llyujbty9iYmJAEiNGjICXlxc6dOiAbt26YeXKlZg5c6bF9g/WYL7FQ3JyMurWrZupLR569uyJl19+GV9++SWWLFmCgQMHpqFJh4rcCvOdV0edOnX4KOH0aYnH/ckn1vP/9z/S1ZUMCiJv3iSTksjp08kNG8gHD3KWtokThbZhw2yXOX2aLFuW3LMnnYauXpWGPv8880RMnSp1ly+XBwGQkydbLWowkMOHS5GJE+1rfvJkKZ+YmHnS0mDfPrJECbJoUXLHDlP65s2kopADB2ZDJ4KkJPLkSXLVKvKzz8hBg8jGjUkfHy2+uxxOTmSVKmTHjuSoUeT335N//y3fUkawtQ1ETAx58KC88z17yIgI8uJF8tgxud6718Bzh2MZu+cYDXv2kKdOkfHx2XbvOh4eeb0NhC4R5TNUrChCwsKF4tGbGq1bi6G9Y0eRkn7+WcwLsbFiBH76aZGa2rUTlUhWcfjGYXy771t89vRncHWSFf72OCoMHy7RajZsEM9kq/D1FZ/pf/4B3norc4QNGyb6taFDxfAD2BRhPvhAhKg337TfBFOwoKlJZ+fMkWaBjRvFK7BoUeCvv0wLVKOiZGuHypWztCo4KiqtZHPypLj6m8d+9fERaaZjR5NkU7WqaDQf6r7MYDDIIuzUy22SkiTN1ZUo4xkL79hIOD1IFLHKvyLg6fnYuajreDjojCgfom9f4I03ZJ1FrVpp81u3BlauFFtHr15i9//mGzl+/10ORZHYaR06iKNDYGDm/vuf/vMpFh5aCGdHZ0xrMw1kxq7bZ89KZAjADi/ksDBxVyYzR5i2m2vjxqY0K6q5mTOB8eOB/v0lmra9Xbi5yTk+XoI7ZAmLF0vHVauKc0Lp0pKuWflv3hTVoru71epJSfIsUzsLnDwpjEiDs7NMXKpWFUcMc3Va0aJZpN1O3L8vvhbW5gBFixI+LrHwiIqEEpMoD9/XV44squF0PN7QGVE+xPPPi2SxaJF1RgSI5LNypcx4+/QRm9Hbb4stf/58MRbv2iXHmDGAv7+JKTVrln4Ys/tJ97HixAoUKlAIX+z6Am0rtkVAytPGXRlsSUTmuxlrwopNhIXJgH3xYuZtJI0aCRdeqe4EkooRLVggglPnzrI+NDNjn8aIsuyw8PnnwMiRwFNPiWHK3A4we7bQPG0aGByCWzdtSzfm4fVKlBDm0qWLSbKpUkWEytz2cTAYiBs3FFy5kjavdGmgmFscnK9eBG7HSaKnpxiW9Lh5+RbMD/Gjc0sHmFfHo2Yj0tC+PVm6NJmSkn65DRtIFxcyOJi8dUvSTp0ie/cWMwRA+vuTzZuTbm5y7e5Odu4s9oHr19O2ufTIUiIcXHtqLavPqs6SU0vyq2/vEiALFrRO04ED0vZbb8n5ww8zuMH9+6Xg4sV2PQ+b9QGyTx9Ju3ePK1eSjo5kixZZM0MsXSpNHjmSyYopKaab79bN2PmDB7Lz+e/TI/mR01i+WOp/bNDAwCJFLG03BQqQNWqQXbuSo0eTP/5I7tpF3rmT+XvIKRw+fI47d97knj0Goz1ozx4yMpI0PHhAnj1rSjx4UIg3GPKabB3pwGAw8ObNmzx37lyaPOg2Ih19+8r6oa1bba95AUQyMrcZbdwoLuCLFsk60PHjZWIeFyfX1auL9LR6taQDQL16JmkpKAhYfHgxfD180aZCG/gV9kPduXXx2fq/ATyDSpWsSxhjxog6buxYUYVlKBEFBopq6p9/RL+YWZirtVTR8a+xm/C8w3rUqaNgxYqsTcLNVXP2ggmJ+K/nMJxYcRwnmy3GSb8eONnNASdOiPpKwtWUBTAZvikpqOKq4PnnTZJNlSoiFDo6Zp7e3MDFiyKExsX5ITz8MipWvGn8BnxLGnD/6l2cOHHXtL27p6cY265dk0NHvoarqyv8/PwyLpiTyC2Ol1fHoyoRxcWRhQqRAwbYV379epGMQkLIqCjLvN27yTZtZObt60t+9ZXM1A8cEC+xevVMM/PSfil0qDeHnSd9a5Qovtj5BVFyv3Gynxpbt9LC08/FhXz3XTuIbt6czOr7iYiwECl2I5QejnGsUcNglAyzgk2bpMmtW9PmxceThw+Tv/5KfvAB+cILZL06yfR0irWQblxdyVq1yO7dybFjyQUtf+Ae1GHM7xuzTlguIzmZXLuWbNDAUnIrU0bO9eoaePWzheIVqGU+84y4Tep4LIBclIjynFHk9PGoMiKSfPFFsnBh8v59+8qvW2ebGZEyuDZpIm+9bFlRzSUlSd61a3Id0uw84XyPgKjyOnUiv/gixTjWDB5u6edrMJBhYWSpUsI8SaH5zTftIHjMGNGj3btn3w2aY+dO4wB4FNXojZss55/EK1cy35Q5/vlHmn33XXL2bHH/btuWLFfOpOo0Mm3fZLbw+JevKbM4o/curl9Pnj+fSnW5YoUUfvvthyMsl3DtGjllinwf5vf68stkv37yu0ez67xfs64ps2xZcafX1XCPFXRGpDMikuSff8obWrbM/joZMSODQexKob6XCJCVKxn488+mwbPljy1Z/vPq/OMPA197zTQDNtoyfC5w1+4E45izapWkf/ONqY/ixckhQ+wgdu1aqfzXX5bpn3wiDacHVXQ5j7IsjUssias881uEHZ0K7t8XM8bSpeSkSWJmCg21vFeNGQcHkz16kOPHi0lr3z4y9sBp4U5ubuQff1jv5PJlWUNUuzaZkGA3bbkNg0EeZ/fuss7I/P6rVpW8xo3lekLlxTSYG7bGjjXNQHQ8VtAZkc6ISIp6xNdXFh9mBhozql3bOjMiSUPzFlyOTqzpcZ4AGRhIzvs5ipigcNzmcaZyBnF8SD1Aly4ts2SA9POzXABapgzZv78dhEZFSQNTplime3uLyie9AW7NGl5DCVbAaRZBFA/5tBDum5xsQfulS+TGjeSsWeTQoeTTT8sEPrV0U6YM2bq1SYXZv78syrTqLPLvv2SxYnL8+691+pKTyWbNxDPk5Ek7Hkbu49YtWR9cubLcc9GiIt0C8nzeeUd8QsqVTaarYwJ/djD7ENq0Ea8YHY8tdEakMyIj3n5bZqmZtXusWycTVpvMqH9/0sGByYoTF1cYy0rlk2SMKb2L3y27YKFl6dzZNP70+Dqc6NSfjdvcsBjIO3Qgv/2WvHKFrFSJ7NnTTkKrVhUXQQ0Gg6jrAAkRYAO3h09kLUTQHbHc5NCK+z/5H39GD4Y/s4u9esl9u7tbMht3d0nv1UsiLSxZInYyc83gpUtSdu5cGx3/8YdIQeXKpc9gpkyRhubNs/NB5A4MBomk0LevTFYAslEjIXPkSNLBQRj11q3kulWJLOz6gCWU69wF1ZDo70/+/ruuhnsCoDMinREZoblFz56d+bp//GFiRrdvp8ocN05GnV9/JV1dmVSxKsv1nkDnolcJkE2bktu3y3hTsqTQ4O1NxiXGsepXVen7SQBLlBTb0WuvpbUpAOTevXaMVwMGyFRcKxgTI5UdHETiiI0lKZLJhQsS4ujjiQ/S9KUdClIYUCaJbdpIKKJZs0QiunzZvrFTE9JmzLCSOX++MMmQEDGm2MLOnVKuR498M2BHR4uTSs2acn+FCpGvv04eOkQePy4+I4DYJWOiDZwx6BAdkMwgHOBF+MmHNGaMVSn10CEJF+TvL2cdjwd0RqQzIiMMBllf0qhR1urbZEZz58rrj4wk//6bZwIKE+Hgh4ve4syZJuZTrZppkA8Lk6r7r+6nQ7s3CZDr1xuMdB46JOuHzBlDqVKiwlu1yoam7bvvpOCJEyTJ2COR3IvaXNRiLscjnD0CjzIoSNYvWWM8fctu5eQCk7hsGXlw9QXeL+ApIk8Wcf++tPvRR2aJBoMkAGTLlsIsbSE6WqQlIP2gfLmEvXsl7py2hqxOHXn1sbHC3GfOFC8/b2+ZkyT+u59DSq0kQHbCcsbC3aoa7upVUesFBUm7Tk7ipBIamkc3qiPboTOiJ5kRJSfLgkCzmbQ2Bp49m7Um164VZlSnjhkz2rBBGt22jSQ5+ZehRDh4oZQ7+eefjIsTnwHzQb9uXal69y7p7hVHBGzmt3vT6rAaNRKb0/z5skDTw4NGt+ZnnyW//lrUQ+vXk9Pfv8ZXMYstql1h6dKW/TkgmeUdzvGZ1okcPlykGx83cZWeh/40imOOjqbnNWGCpP/5Z5aelcEg1cePVxOSk8k33pDEXr3SdzqwZlDLA9y7J8xGc75wcxNmZB6I9vJlsZcB4nV99cB13u79OlviT/EaxEdMKVPWQg137x65cKHwJQcHqVuvnjCz//4jBw+WIKs6Hg/ojOhJZkS7dslrMQtNcOGCJNkIMm0X0jCjY8ek0UWLaDAYWO2ramwyp77obpydjREP+ve3HFf79BH1DUCGjnuDblPcePKWpa2kZUuRnmJiZA3T99+T9etbtpP6qOtzjv36kVMGnOGv6MLD83Yzfsc+yZw0iQYDObDrHQLkNAw3VRw3Ts4ag4iPJytUEAt8FsORu7mJvYTx8bJwCpCoCRmFuZg/3/Kmrl7NUv9ZxaFDom4rXFi6r1lT1HHR0Zblli4lixSR+5w9I4GGiZN4qmAtVsYJOiOBPzgOkPAO9+4xOVlUmy++aJpQlC0rznKqEGuEZhbLije+jvwHnRE9yYxIs5Y7OIhBREXTphK+/2FMDmvWCDMKDSXvXIqlpoOKuBZBhINf7/5awrI0bSp506axfn2xJwBkxYqW4+zuo9dY5KNirPlBR65Ylchp08hXXrHOaBwcpP6zz8q6nPLlLfN9nUzOD7dQVHyrSbJTJxoKe3LkEJGExmKSZcVp0+RsHgtn/fqH4tze3uRrAx+QTz0l7UydmnGlw4ct6coll+b4eHLBApFCAXFA6NtXJM7U38qdOzKREEnGwJOfriD9/LgZzVgEUfTGTW6r+xZ58iSPHJG1VJqUWriwSFVbt9rmx4sWSVkbu0XoeMSgM6InmREZDKSXF43eAZGRJMUjDchgnx87sHq1GTPyLEu++irf/fNdOk1y4s04dbFqfDzZtSsfoAALOCbR399AwGTOSe8wj6H20Uei2Tl2zLZG6+ZN8scuK9gNyyzaadfiPmfPJi+uP8oP8R4B8nXMlDUsmq4SIOfMkXPqlazdu4suMAv6zDKlkvhSkd9FMly0KOMKly9bPoSMJKdswMmTIqQVLSpdBlRI4Gefpdj0rty0SdzsHR3JiQMimRQqIRO+xSA6IZHVnU7ynw//4rTPDQwJodHu0769SFD2LKr++2+pZ2tZlY5HCzojepIZESnhD0qVkmlonTpkfDxv3xYGYlfEggywerWMsaEFjzCqzfP0/8Kfzyx8hklJYpNevZqc+mkKA70v22Q42p50xsN/G+dv3EmDQUwpFStmgqBNm3gAQRkyuZ2ozxQoEg5CS3zzTTmnDi1z+bLoktq1y5wYeewYqzidZg+nX+yzM2kqzlywCSUkyOLmFi00RmFgrRYnWGZof2K8wj9OpeUA8fGmWKyVyyVwd8v3SIDJcOAIfG4ku1HDZKPXfGgo+eWXYvfJDDR+nBUPTx35DzojetIZkaboX75cXtGgQSTJLl1knacWlicNoqLsmrpGRYkJwDh+BmxiqfJ36OycPiPwKZaSZsw/dYp8vmcSoaRQcY3he2Pj2LWrzL7tRmwsJynjCJBnXvmU5XGGFSoYjAOo+VHC/S4HDCCXN/iY9+BGI9GaKs8cmtru99/to2PHDrJoUQY7HWLHp+wIe62FvshhJnT+vLwvLaxb8dL3WaPnIjqN8iPCQYSD9efWZ3ySZbjxAwfE4xIgXw/ZwThnTxLgHXiyIOIsSPf3lz6OH886nSkp8jrsijOoI99DZ0RPOiPS1E2RkSaOMXcuf/9dfq5fb6NeSIjVkAbTpokXWOPGsjTHGpNp0jSJ774rCxt37JAFtD16kP6OlxmK3fRHJB2QzOGDrVuil2w8QqXa71k2k9R1O8z6hY+Rgwdzq1dHYxtPFdrL+3DlLRTlAvTh8y1vGY3xLohnW/zBWXiVF5bvS9toUpJEH/XzM65HsomVK0XMq1iRYbXj2apVBgRr7yiHbELJyeLy3q6dRDlwcDCwctgJFhvUjxjvQO9PvNnr1150nOjIMtPK8FrsNYu6H39MOjsbWLLwPa7zfJ6ExOTricUWZA8YIBGWskubWKGCfDc6Hn3ojOhJZ0Q7dsirWbVKRpXWrckCBfjg7z308hJjtFX4+5OenhJv5+JF8cu9ccNoR9BmvlOnivrt6Ntfs3CnznRwTGS9emn3vvH3J7tjKQsjmgDpgbv8r2yo5ZqSPXskds7Ro/x4+8fEy3WMfZlH+k4PV69K+Q8KhJNdunCrf19jG7/DLKwDQI4cycREclPDMRzuOpsVcNqYVauWrLncudNsYNWeZXorLb/9Vrwp6tYlb9wwev3ZxPDhljQdOpT+DWYCly9L1Actxl8Rn/ss33kBMaIMlXCFTy94msuOLGN0fDTrz61PtyluPHDtgLH+uXOmuHBdC2/gMVTldAxjHeyxIHnQoJzxp2jRQiJ263j0oTOiJ50RadEFtBhsN28KV/D35+B+9+nmZmOCr41ef/1Fvie2AG7axFKlLBeE/vKLFF83910iHBw9cRWdnWVNiObqe+WKlH0XHxnrhQ+6JA4UPj7il02a1u0oClN6PM/ms+rRuelnImXZiPSdGtra2oMI5D6vFizsGMuAEnEshv/oj0hGQxWBnJ3lRq5dI1u1Ihs2pKFqNR5HFX7aYy+bNjWtbylenHzpJfK338jYfq+J5f3wYcuODQYZ9QFh2upD7dBBhEuraNbMkgnNnGnfO00HKSmyrOu550zRjcrWPsFC/foR45xYZloZTvhrAiPvRKpkG9j7t95EOPjbsd+MtzJvHunhlkxnJZHPYjXbYQ0dkWRBbuHCad2usxMDnrnCkgVuSWRYHY80dEb0pDMikgwIsAzYtmcP6eLCbXWGE5CFhWng5yevdNgw0teX72MKF7xzSNQlPZMZ9sIG44C0ZQvZb05ber4HPli7kitX0oIZaWrATzHSWOfuXYq7VkCABG5bt05WmQISPsHDgxc9QdemkwiQDxITJdK3urCycmVaRPrW0LEj6V8qkcdRhT64QX/nq7xUJJC7UI8OSOYAz1/FPezIERmp33xT/JVbtJAGAQmRTbF/LVwoj85TTCIsUMDANs4bObP8NEaeVx0XkpPJV15hEhy5tc0UfvpRstwfRbVUpUqqZ5uSYgpPoB0dOjyUP/1//8miYc2V3cPrPku1XUAMK0/nSc7stqwb151ex+SUZIt6U7ZNIcLBD7Z+YGynU9u0YY/8cJHveMxip7ridNKsWeZjFtqN27fJgQM5CWMJkPEnL+RQRzpyCzoj0hmRDHLVq1umffcdU6DQv/Bttm1rpY5ZaIJYuBsHpBo1yDbt7xHhoGuHt43prv2f5YCOENUUacGMXnmFLIAH7Ayx+wwfbtbP1asy8Ds5CRcBZKO6W7fI0aPZu5QMRu++EkQePkyDQfwutDhngYGyTY/BIL4VBQuSHToYWMbhEovjOk/BtGBpdOh6AuSajuo+EwMGyGKZEiVkUdK5c6aRN9Xe4ImJIhy+9RZZqUS0sVhA2RRWcr/MijhFL9f7xvS9e6Ve//4iXBoRH285wpcuLXrHm5Z7M9kDg0EmAT17ig0HIEvWOEGXHv2JsQVY7atqnLpjKm/cu2G1/u/HfifCwd6/9abBYODnn1hKPG64x/6Yx82OrXh3xHh26ZhkVMXlyE4UBoPEBlJjQv1YfxaBfBtwXEcmoDMinRGJk4KjY1oDy6BBfB9T6OBg4PXrqeqUKmX0IhuFTwiQg9tEMjSUbNvWQJfJLkQ4qLQZYTK5+Lwky+RVrFhhckSrguPGcmmc8WJiJISCVmDDBmPWtMmysR7e9eTWspA1PYcPMyVFAjZUqiRV6tUzeV8DpKfzPR5AkCkhKIgPpkxlIA6yZLFEiSJ+/rxp05xu3cjr103lbYbMJi9dSOGbvkvTSA3mhxZC7rXXxKmDpIgb5oVeekm8BzZmbrfV27fJ6dMl2DhAFiwUT+/mPxGvVaPbFDe+tOIl7ri4g4Z0JKwD1w7QbYobQ6Y9zUkfJFjyRuUKFzu9wDgUJFu14uUtp1m7tqgqp03Lodirly+bQrN7eJA//sitW4S5mq3F1vGI4rFiRADmAfgPwBGztKIA/gRwWj0XMct7H8AZACcBtDFLrwPgsJr3JQDFnv4fWUa0ZAmNkoY54uN5tEZ3AuT00almzb6+xiiU2gB168c1bNJE1DKBXwey+fzm7LasG9Hgc4uBTLMbkTLBTT1IW0VCgkRT1QqpOreAALkMmFSX/hMK804xDxPjOHSISUmyONbf37KPvxu8bbpwdBQ7Q7VqPBD4Ap2cJIwbSWP4hluNOoq+UKtTtaqRBoNB9tIJD7cksSJO8W18xhWj/uaCBZb9OzuLX4i2PQKPHzerWFEeEiD2NztgMEjEpv79SVdXGaCLVjpFx+cGEqMLst7cevx277eMeZBOEFUV529eo3e/IXSt/j8Lmp2QyMiSavyk0qXJZcu4Z7eBvr4SEWPNGrtIzRxSUsRrUHNfrFfP6NMfGSlJqpCt4xHG48aImgKonYoRfQrgPfX3ewA+UX9XB3AQgAuAcgDOAnBU83YDaAhAAbAOwDP29P/IMqKjR+X1/PRT2rzISIY4HmTdgocsvRZU9YjBjBHxl1/YurV4Mj3/y/P0G9OC8xbGEu96ERXXWgxqmn15/37LAbp5c1MXJ0+Sr75qFsggKooL0IfvYwrH+s/nhDEmVVG3F6/Toc1IBvf9jjOKjucsvMo5GMy5tb/mvIkXOWNGWoY3DhO5Gs9yXc/5/N8XR7gJzbll1BrjhnXvvEPuXXPNWH75r8k8gco8XaENT6Ayv309gp07y+JfrUxgIDl+yA0e8GnNRDjJotidO5mSIurCKlVEhTdypPzW6tXAYb6HD/l3i3FMPndBIl7Uq2e5C6AV3L0r43RwsLRToOADeoQtJF4JZtFPinLYH8N48LqVdU+pkJIiIXVeGpBEx4J30zyreYF9hNs4OcnindhY/vKLqDrLlk3rm5EtOHHCFAJKUcRN0ex5JCXJHGL06BzoW0eu4rFiRHI/CEjFiE4C8FV/+wI4qf5+H8D7ZuU2qMzHF8AJs/ReAL6xp+9HlhElJspoasPt+PNXThIgTzwz3KR3UVc8LkRvAmR97CSXLGHHjiIovf/HFMLrrAxkDoksWeVimsHt4EGT/4E1tdX+/TLQeHio2jiDgUE4kK7K61E4PDzEucHb23q+j/NtRrg1JM+csfnKDhyQLdI9PET6KeR/lkr7IcT7Hmz5Y0v+fPjnNItOreHkSdGWapKlk0s8UXqnkZa2ZVbSaXAgB7d2F/XosWM0GCS0HiCu5zesm5iyjsRE8eLUxEU/PzF2WUHZshLTTsejjdxkRE7IG5QgeQ0ASF5TFKW4ml4awC6zcpfVtCT1d+r0xxfOzkD16sDhw1aze46vjFHfGrBoXRFMmjEDGD4cuHEDAPACFgAAZuNVIHkkChYE4uOBPT88D0QHoFD34XC8XQ2elwfjeqp2g4IAd3cCUFAMN3ELPgCANm2ADRuAkBCgXj1g505JGzNGwVo8iy74HXtQF6OUz/EpRwEAJkwA3jwzBM8aluJQcUdsXl0CfhdikVS5BnrGzMGuq2UBAFvwFIriNu6gCD7H21iFTgCAACUS45psRcCEF5GSAhw5Arz1lu1H5uKUjGeTV6LpiDpwrhiAlBQgZf9BpCxYjJSiPkjpPxAphYsg5fBRpCz7DZMxHoA8OkWBlN/6N2ZFNQYAPFf3EgpXL4OUAwfhdGg/inw6EqhQIU2/JDBiBDBjBuBUIAlOtX4FgqfDo+plvBkyAC+FHET5IuXTfd23bgFLlwI//QTs3g04OACtWxF1G3+JX65fhdPmcHg6x2BSzU/wTtG7SP5uH4p22w8sqYcHCQoG9gUWLwb69gXmzgVcXdPtLnPYswcYNAg4dEiuu3UDvvkGKFrUavGAACAyMhv71/H4Ize4HdJKRNGp8u+o51kA+pqlfw+gK4C6ADaapTcBsDqd/gYD2Atgr7+//0PNCnITaQzKL7wgen8baN3KwHJu12hwcCS3beNBBPI1fGWcORsA8scfjds2ACTCPiHCwbGbxlqEbLN21HPeT0BUVk5OZMOGIhlpmhntaIotPIPy7F7zWJo2ktt34oXiLvR8D2wwEEz86UcOwWxjfkOvo2k6voWifKflXhZEHB0dDRwwQLy0g4Isi9ZCBMcqH3A3QpkyaLCoKb28xBZFympaRRHCzf2WDQZuDh1FgPz6wzumh686X3yLQQTEFs/t28Xib2MV8b2Ee+w2dK/QFDqLju8XY4upb/DzZX8zKcXGiLgbSwAAIABJREFUwqlr18i9exkfL2anjh1N/hdBQbLg+Opv//D75vWJCuI1+EypA4zwrkXPqvMIkF6F7/LaNyt57Zppi40pU7LZKeHePXE51BZnubmJcS+DTvr1y2SIJx35EtBVc0+eau6DD0S3X7myGMwHDSInt9nGn9CXW1fH8Pz5tAtCf/xR3uAOv+dJd3fuQEOLgdoAkN98w5495bp6jRRijHjOHf3vKA/+FUWAXIjeHKpMs8mQ2rUTngjQGJkZIF8aEkNFETWUD25wXdvpxs3WtOM6ipOlSnFJDYmJ1qjxQgJkP8wnQH7o9YlpoDM77sGNs0tPTpdRXh4y2bRSt08fCTH9+uvCfHr0kPQOHayGEGjdKI4lcI3x3V+QB6tFPAe48PPrBMhTe6LFo6J8eYtdWQ0GA/dc2cMhq4fQtftgAqR74J/s+t4fDK0n3mwVKlh/z4afl3C7R1sOLrzY2KWvrzD7gwcpRv/nnuOnnt0I1yg6OMVxepnJPKf4sXCJfQRIRUnmJjTnwfKdWaZ0MgsWFAeTbMX//mfaaRYQjw8rK2FjYyUQq3nw8/Hj5RXkiLu4jlzDk8CIPoOls8Kn6u8asHRWOAeTs8IeAA1gclZoZ0/fjwojOvT9bnbtmJg2qrXZ4eAg61saN5Zxd+hQSS9XOoHHUJVxKGhRvjU2MLLTMOP13r00BskkybntZI3QKVRk4qAhbIot6Q78qY8iLw6ib4+RVCDBUBWkGBevascGtDZe1A6V9UWdmu/jnA5rCJCHUUO4m6LwSusX+Q1e5rNYTRfEy8y/UBKrV7dss+uzkte2+gUaRo5SiVH3nxgzxlTw5ZethnPYs0eyP2n1P2PZRAdwbm2w/uw6/CR8KwEyorUqCv77L0ny9v3bnPnvTAbNDiLCwQIvdjB25eIiDFlzkpgxw7LPU3uiOb7mbywHsdG5uSTxhRdkvE9Opvh3jxjBO07F2M1F4sE5++7hdrdK3ObdmQU9bhv7Gu04jqvQnu6IZSmP6OwNYnDrFi1EaEURDxEzrqJ5Aw4aZNosb84cUxPz5klaVncU1pE/8FgxIgA/A7gGk51nIABvAJsg7tubABQ1Kz8G4i13EmaecQBCARxR877C4+S+nZQkA16dOrwbGcXFi2V5hja4ATJhf/ppkUyeCo5mQOFbdHIyWAzQGR17z5wnJqiM6PZtDnL+gUWcYkRymjqVEQ4hVusVd4nmxy+f4bChVvprPZJODT5Jt9+taGJUd7lXXcqywxzZJiCCATjHCNTiZIxh3RKRxvLlcJbDMY2b0Yz34WpMr1tXXLg1KQwgP58Ya7tjG/sYdOkizzPmyEUmOoDfh4Dl3pTn4jTRkXMLtSGgbjvx0YfcfG4ze//W27gOK2h6UzbqdNSiq379xPNOux4+XMb0r78mG1STxbQOSGZrbOBPfdabnB0TEyVMkLc3N6M5/dxvEUoSnRpP5JZSRTir1e90cEwmVGZfz2UDP8EoKkhhnQIHeWXfNav3mCmkpAg3XLJEYiNpN1GqlMV6qagoYbCBgZaPeeRIy2gZmzZJ+qZND0+ajrzDY8WI8vp4JBgRaQqkGRxstGfERBu4wP0VdvCPMM60y5YlR7aO4B7UYdKkDzl7tn1MyHg4xxI+R9im4ilj2qIC/fn38zPY2XWd1TreLufpgnguLPEWW1aMzFx/ZsczlU5z8851dOjRIU1eA//L/LDJWh5BdWGMAA237xjzy+K8GFP27eOh5WfYCcuNea9jpizk1BK0VbITJ6Z5zNr2Qe8Pvs55wWD5YcKAXCc4EeHguN6+3IomBMiBT/dhhRkViHCw8Iee7PLZ5+zw/C0LuseOFTdpzWPN/NAiJwTiID/FSF5GKZHSDAY5Vq8mq1RhPFz4dpmlVBQDCxU+TXQcwFKFzpra8t9KuN2gm/N/7ICVBMhuzisYty/Vng1//y12rm3b7PvmUlLIH36w/rI6dyZv3aLBQG7eLBMAzWFO247C0dH63kNnz0r+vHmZ+gfoyGfQGVE2Ho8MI7pzR4KJAhJGWpvNP/UU2aAB79wRm1C7djRKQuVwlm/1vEKALImrFuNIedcrtplC5ZUs53zSfiZS70uL69cdZhl/+7ndYsuA94lyG+1qq5CzKaROASWO32EAr3mqi3e0kU49AvxMa5IMEyeZ7DilSpEAf313tzHfrcA1jvJ8jQ/adpLn1r69PM9UISFe6JfCAi4JDHjZmwgH64zy5JJBDVh2OFhhgheX1gCbPB0q7fZux7CZHdl75B5Wq5aS5l4mTGAam5j5MaLoD4xALRHlAHmXCQliDGrVigQYUbYDa5YWtVu9krOJZuMt23FIIKrL7rWaCnSs44dMWb7SZJiJieGmjtPZAP8wyqu8fZsKbd9uudJXOwoWJOfM4bWrBn70kWl7eE9PMb99/708/kKFbG9HkpAgGr3x47PyR9CRX6Azomw88jUjSk6WWaym19D2AwckQNz162II8vCw0H3cvk3Oq/MV2+IPOiEx3YHfA2kXQpofo0aRhxu+zGJOt9Mtl9HRNrAX8eJTdpUtjGhCSWKhUc487wWJ5aZtO6oevbHQeGlcLxkdbSl6FCzIuf22WrTtU/i6RPretFUS1Cl7UkoSP//jV8Ihkaj/BUNeAVeN6UaDwcCOPzxttJ0hHPTuV5OA7AGkSaINGsiupRndW8WKBratdIYAebtkNfEyK1FCHB6OHBGJyMGByV7e/KT9Njo7JrOkco2vlHxNJJ902nZBPBeiD/nhh7J4uUoVcs0aHizeioURTRflAaM37BJGtH27BPibO1e2Vn/7bbH9pNarmR3JFatw7ewL7NzZFAW8aVNZUx0XJ7uSuLmJ/0ZGO1/4+Ym6UsejC50RZeORrxnRP//IK2jXTtRxycmWbmnVqpkG3tSW39WrSYir8yB8a3PwSoQTJwbMyxRTOYjANGmVg29QKX7koZhVGib5Snk2GgAmOUAGaTVjaqU5xjJRUVaemxZqB+DMUBCV1tDJIY5lw14jSomUVLmygT+XH82EihX50/75rPRlJaLel1QcEji3vB/jvpvNhQcX0n2Ku5EBte5cki8Ue88oeQASyHzzZvKzz2zfR7Vq6mtsFkeGhfFHvECAPLPtiqhaCxQQd0i1wvmXJrJJTfFY7IpfOLzqdKKAlQlDq3csrt/EF2k6vwg/lsYlAuRz+C3dB24AeKkwGO1imX4aFfgePqRfcYng7eMjExTNSc5gkDh5iiKR1K9ezfjTbtRIBEAdjy50RpSNR75mRAaDBCIDZAq5Y4fo97WpqLu7acBYscKybmKi0bBsHtLH2uEPses4usbRySGZhZoNzxLjcHRKoWPxU3Qd1NaYNhhzstSW+VG92C/8oewEbkYzfok3jOnHa3S1/txWrCAB/lsadB4HturkyyKIYn1lBzs870j06ETvsqKaLOB9kOjZkdVfLccCyn12LjiXr3/TiV4fewkDGu9A9G7HFgWWG/fuqVZZzq1aiWODNZpr1JAtHC5dIge8ZGABp2Sec6tBenpy1dvifbjnqbctKhkA/vB/9q4zKqqri+4ZehcUxQYIiApWxN5j773G7hdL7C0ajb1FxRKj0SRqooktttijxm4SNZbYe1fEgiigSJnZ34/DzDDM0JSmzl7rLN67fYb37pl77zn7NF5PB0U4HfGCQRjGBg67DdoOLDnAaJ958ZAxMNcmhMGJ/jivzV/beh0fTV1Krl7Nlzs3868/f+KS3dPYf1ZNVutjyRyjROFW6wFGw4Lr0Zr+Zjpi2/olg7lhg77ZdWwsOWCA5LdsKa5FqcGnn8p5pgnvL0yKKB0lWysiUhRKw4byrzA3F2/G9u0lbHVCVs6+fXV1Hj8Wfp34PX4VFNpidWE4saWnODnG0OPTaWmu1zjPyrfu08VFFhZNm8o5xcwCCzjT4nM6f9KfLi3HcVo+3Xjy4QHtag0h6g7Xro70pMyPNKs7lj519lChMNzWLI9jKY6nYf04jh4QzlE9HrNhKd1Z3AjM4nCfzayQUwxB/HCBQzCXgzFPb6sxOQnIs5Rwup1k/nq0JgG+gSVrYj8tEE1P7ze0solho+EbqVDGMd8o/a1GjbgPAXtULsKe1rPoisd67c5QjJZDrwQID5fFOmBoGZcSNOTxSQVDNCH7w6SI0lGysyJavlx2pLh5s/5so9mea91aF+oakPDfpPh1JCi/Fu0yVPmYxFAsEE1L6Aejs8Er2iJSL00TZv1dxREvmAOhLGXzJ7+upKBngVUESLOm3QibZ0SJXwnfrVK+3ELikzFErwp0HwIOqm3DCc5dWBWHCQhjdzVvnQItXpxUefnID6B43L8vLA9mZvo+QqmF5rjzzp30eVdMyHyYFFE6SrZVRJGRLFBATU9PMtDlBh/DVTbhE89A+/drWbVZqJC82S9ekM2ba8ukZUJbh7b0LnwtTXXeSSwislxpJCWWpRezufnqFMs1dDzKM5U/Zx5rMScfV/lPEuAuiL/RvK6nhRFhpDjXPkIeAuRsDGdffEdATLgXVl/HQu6xVCpT7/9VwGUfSzesHP9dxiu5ouKI7NtmKRtUbEKAzNl5IGGmrxg723/NflhIJ8i4C+MqZ+aZw8tbrrJMCd1qcPNmSpDBUqVICgu7JoxEUpZxKWFPvK/woUPp98qYkLkwKaJ0lGyriMqVY11PnQl1CZzlQ5/qfJCzJB8gHx8gH+8jP+8jP+/1/5r3UID3rHx4N38l3j14i3dnrOIduPMSihpMXnWwJ9UTXVZJP6cvaINXBukFrc5l+dhSI0Oho0T6psPfXOnYnxvRkrtQn1vRRK+sL67oBRlMi1g1/ZS+dQz9rpxdX7Hs0KmE5UsCpE2x7Um2Ya2I4gAs4LoGy7nsW/3vvBxOUN2nr4SMtbbm1s1xqbaMSw5Xr0r7K1ak3ytjQubCpIjSUbKtIrK15fBSe7N8QjXJxy17mi4gzc2pBjgfg6hQqBkYKLys7wJNdPXJk9PndTEh85GZiiirwkB83Hj1Cnj9GiXzhwqzXgI4KCIQ1O8WlEu+A3x8gGtXoQABAIratYGqVYFJE7VpPfGTtu5MfIFRmBWfvgz/IhDnUSpTPpKv45+4li8CuNIy4zqxfQLkuAMoCDys8E5NuSieoDt/QX3shgVitemPyzZGx1MjDMp/X3Aqrt+3QhBGorTva/x3zRYAUN3qOB7nLIbHwSq8gPM7jSkjUNbxGtyKOcPpzjmsflwbANCo/FPsPOGK8uWBOlsGIu56YwwpdxSLwruiJTfh13qXYWs7EIDjW/drbQ24uZnCQZiQOihE8X24CAwM5MmTJ7N6GPq4dQvw9sb2T9eg6aoOBtl9A09i0cArUHbrAvj7Axcv6jJnzQK++AIA8BD5UAAPAQDlcAInUAFr0R4dsRYHUBOhxQ6hTXsAEzP2f9w55xg0zDcDn9rNAY4lEzAoGXiaXcEdVVGD9OI4D+ciT3HktSXw0gMIzw9A+VZ9KBEHtf9GwHs3at9Wofl5e7yGPV7BDpGwxyPkxVp0NKhnjlg4KCIRxvRRNIXML6F43A1sQzOj+XmtruBRdPx3EbgYVk8KI/penXTpOyWUxFk4Ihx2FjGwL1oA9iW9YZ/DHHZ2gL29SMLrxPeaaysroHJlwNYW2LcvU4ZuQjpDoVCcIhmYKX2ZFFEW4NgxoFIlDKtxCvMOBWiTlVChXb6jWBtcA91aR2Bp2SUwH/NFks144wZuQQK1vcjpDafQW3gNG+TBY7THOrxo9xn2hndF+B8rtHV8cB03UDjdP5JZ8V+gutAl3dsFANQbJqugGHt43PbC3Ts90rV5BdSwRAyiYRhNrgYOwtXsPq7nL4Oz94qnue3PsQjfob/c2D/C4nyBaHjNHFVttuLBG38E+kzBf8G9EfdK4jyat+yAuFLrYL9tFt6c6Y/fA6pg8IMjuBlij24B57DidMkk+3roUwP5bhzGCzjBGS8AADZ4jSjI6q1NG6BBA4lxBwADBgALF+rqd7LagEg3H0S6eiHyejBevYxDpJkTIq1z4ZXKGm/eKFL9uc3MJNAgAPj6pl6BpZRnaZnqIZjwjjAponREtlREW7YALVrAyjwOMXFmelmjmlyA3e7NGB87Du3aEb+6DoPFovkGTUTDEtaI1t4TukmiG37G72iBqM7NoVq1G8V5BecyaYvufYQNXiEKdkbzlI53oH7lBqiSD3mqhAo1cRD7URs1cQA34IMHKKgrkPckvihUHy3/LoxGyi0Is7AG2rQHjg8GbjQEADhWH44etnPR9iJwPHgEhqtmp/ozmCEOX2Eq/kQdHENFqBLtui9cCPTvD4wfD0yZAixdCowbB0RGAuvXS7RdVKsmoWEPHZJKhw8DY8cCR48Cnp6IGz8Zr5p3QmSUGV69krqRkdC7Tng/bZo0064d8Pq1YVnNdUxMqj8mLCzeToEVKQJUqZL6fkzIXEWUKQdRWSnZ0lgh3snC2OFxTttXfD0liEEYRoBs1lTNqNafGhSsif3a206K1Xp5e1AnxUPqz3P3JopsTrHc+yQtsInbZl9mTK16LGt9nj6FYnXfhc8OVik/jZXwV7r2mQtPOAOjmBshtEIU52Aoj6G8fjmv3WzZwo5LzTvSTBFFON8g+hclao/WlmnrMI9x8Tc3nAPp4RZltL+UuAU1ojHZBsig/10iKTy69vbCLauxjDt/PsFz+b//CVtHQqjV5M6dOt+2YsUkCl8qQsF+951UefAg+XLR0cKfeP++0OT9+y958CC5fbtEpli2TMJPTJtGfvml0C717Em2aydW5zVqkGXLCvVegQLCjWtunuh7M4+P+2RCqgGT1dwHroimTOEbWCY5iSz/IZb09eUiV2FirltbpRfmIHEk1qv+LbU3aoDb0SjLlUJmizvucDhmcyuacB3aEiB/RC8+cICWPbyE/5d0rziQSq+dGTKG8/DnT+im7+jqt44Ya0Xv4pPl3uMg8YULS9evri3TTLmer2DDNWjPT8wNiU+9cEN7XQwXjfat4ZuzxmuOxnR2xCpt3r3qn5KUqN+aNKOWcUFBkmmM4E+lEo6/okWlTNmy4mSUjELauVOKHj2aju9OGhAdLR+ld28hFTchbcg2ighiNuNtJL1kZg3wXSVbKqKBA7kFhr4hGilTRk31H7tJgD+13kqlkqwe+IrhsGckbLXccRohxInya3xBH+g7q1bGUaN9zMFgKkusSnIMmSb2wRnbvkWEcULRdJY/8QkH4hvDvJG5tGEcUGYp8ZUFf8+fW5tvjmj2wWK6QOIceeKWHulqWqQLVvAuCnIw5hGgllZoYsEfebd2D225lm5/81XjtuIU3aKFSMuWuvCyefMKq0ebNiJt28ryo107SdeEZQVkOfLihdHH/OJFKbJqVaa+XQbo2VNCV5iQNmQLRQSgHYBgAP8BuAigXIK805k1wHeVbKmI2rXTbq3NnWt8UvnrLwrjpo0N13z7lGZmapbHMXaGIWdbi1xHtISdWvFJ+6/+9liT4RP2hyB98R0VUNELN/gXKvExXFlFkSjMurWwa1vYPpAQ6v7DiQngihJK2ir1aX8sEM3WWM9p+DLJPqdjNHtgWZL5p1CGaoCjMIMAOQxBVAOsi910TtBfK6c/qSpZmixVitHFA/iwWG0JDVG8uCwbNAX9/GQbrlgxWQUVLSp7X0WKCJN44cIiAQFJ7r1FRkpT06Zl7uuVGC1bCkmtCWlDdlFE/wHIG39dHsAVAK3i789k1gDfVbKlIqpZU/u+a15WjZghlhZmcezQgeTduzxrVY4N85ziN5PCkpyEciOEIzGT8zCYSsQxp+c6Fu8L+iHlsA1WeVIm+UwsHqN8iYngogCztNXtb8gCkSZxvJehCma1sjU/qV5dj5bIDsYpikriPwabO3CGVwBtbO7q59cdTlSdrr3vUaQpMQHsWTbQoB1fXGF1HExyTFUhbOyaUOvGpCL+5r5KbswdKFu5n2OhRLmtUIFzMFRbTqnUPYLXrgmjT548CXbX4uLkAGnkyHR71F1dZWssK1GzJlm1ataO4X1EdlFE5xPd5wVwCsAg04ro3aAuWkw7OZCy3Q6QTZoIB1lOq3Cam0sAzv+VPS1pylCjk9C66gsZDQtegS+dEEY/s9PEGFtOrwpOx+gkJ693kvYt2L4NGIocqa8zwpVo2yZDFYkxMVcYP/TPCFEijm18uhPtWmrTOuX8imjYn05O/6WprUGYz0K4ydbYwEXoZ5DfFuv00yrOIUA2t1lKFYSz8BTKMCeeass8XPknefky16yI1u6uLVyY6OEsUUJoztMJgYESxTYrUapUun6kjwbZRRH9nfh8CIADgH0AojNrgO8q2U0RxcTF8GxO3S9jUhfvZfhw0scumPnMHlGhIL/6KuUJi5C4NL64Qlc85heB7sRE8FYO8AxKZdikO8ZsHH/Bp5muWFIjTczX0qp+HwY2qMhw2PElHJLc1nLAy2RXJInFrNRSYmQuKmyeGOYhhnA9n6p2mmMzW2O90bytaEICrIEDRvMLWdzn6aWnDNJbljrDuKL+JMAtaGrABH4H7loSVoAcUWC1xMOaPFkOcv75R858fHzS7Xlv00Z28rIS7u6maLFvg+yiiEoB8DGSbgHg08wa4LtKdlJEYWFqFprrQ1SbKpNBxTm0nGJJyxafEyAtvI/SsfZEuXa9laoJrWXtwizoupNKRQzblq+qjT0zuTrYwbdDkvWUiMtyhZHVYocIEuB+1KRHbkMC1pSkCbZq4/q4Ke+mqo5L7oO8h/xJmpFfRDGqAU7BWIO8HY7y/xw7MYL+rTYQijiiuI49/M0bUn38hHDGQcVAnGAVHDHaT1uP41RVqSan+MYKFCkiRgzDh5OLFpG7dsl+XsKoeanA8OESWisV1t4ZBgcHcvDgrOv/fUVmKqIkueZInk0iPRbAqlS6KZmQAAEBCqgtjwBX3QAA9uU3oq7ZPFhWU2Hd70DszSpo1fcH/LZPBTvLmHjf+AQo8DfwoLLuXqHC5n3XAAC29XpjfeWj2qzxnwCYE5TkWNQwSzLvY8Er2Gs5+/AkmYI+O4F71YAYB73k7WiqvQ5Ru6eqz4EvtsIdD4zmRcEakzEeMzDGIO8FnLA4YC1wEFgcUQXPj6wGaAZc0FESrV4NnDoZiEUoh5bYhGGYi2o4Cl/vOFy7qXvVvUs9Qqufg6EsfTi+4yjg9m2hnpo6FTh+XLxMr10D/vgDePNGNxCFAihYEPDyAry95W/CaxcXKRMPT0+p/vixcM9lNuLigIgIwDkt7EykeNuGhQHPn4uk5trRETh50kT/8BYwkZ5mItq1A2bO1L2NkS8tsXnB5+gxUsclt3bQj3g16g+ceF7dsIGESgjAl3lWYkaI0N38tecE1scBX1cFrgY5wCzKCV7MnzEf5CNCrtwH4FzwZ1y/0SjVdTw8f8LdCr8D67YY5E2KmWO0zmf4ATZ4YzTvHErglUM4vv7PDch/DM/fRANP/QEAdbEHU7teR4WV/dGzJwAoMKL8Ycw80QZ18CcA6CkhALhZvzh23G6EDkXqi7IpVQrw8xPJlw8oWxaYPRto3RpQq4GQEFFSN2/KX41s3y4aJiEcHfUUlMerTwA0wN2/HsCtWR6hRsgsxMXhxY0XAHLB+eUdYOel1CuX2Nik27WwEIXr7Cx/g4Ple2jYMHM/3wcEE8VPJuHxYyBvXvmxlRxsbOQHakJ8gn1Yhl4ohDsG5fPjAVQwwxtYw7Z9feR95ojT+/aAb0kMmu1QZinWP5mEtg/vAwCWulaEMv9x9GxqDtz+BPh1dxYPUFCr4lEUOXYev9tXQMirkgDT7zfexKIlEVQ9FpE/XAbqD4HDyU6ICC0PH1zHWZRCKHLCHfL9fIYf8AP64Gd0Qw/8DACoVHI3jt8oC/XrXECBv2HXty4uRveCx+I1MvGGhgI5ckhnr14JJ87UqULvkxJevZLVVEIlpbm+fRvnY3xREuexFu3R3nqr0AaVK5f6D69ZnaRmVZI4LTwc1+EDX1zHSnRBF/yq37ajo75CSXhtLE1zbWenW/Xt2AG0aAFUqiSrR1vb1H+2bI5sTfEDoCCAkZm1d/iukl3OiGJi9P0A01MaQOcz9Jl7Z36CP9O3j2LGD9XTRUr9xG71cjAKVlyFjimWd0IY/0VZ/hgAscRLQ1/WinhTbOvn6Td+t1McXCk/CfCXknI+172hDacm4xOUGrFDBMfbDJT7T+sTNSYQULFe86+1ZSKOX+QplGHeHPrnW2ua/KK9dqnXlcj/DxVmr5nT6SRh/prTAnPoCgcEkGvWkMePk8+eyWGOuzvZufPbPehxceIEN2YMWbIkX8KBADnTYYpYLvzzj8iOHeSvv5ILFpATJ8ohTpcuwtlTubL4LeXOTVpYJP9FWViIDXrRolKvSRNpZ/BgctIkHh8u1oXbJvwr/V69Sj59SsbGvvtLfeCAHIAFBCTp1Ps+A9nBWEGvEJALQD8AhwHcBBCUWQN8V8kuioiUdyTFSWiQFwv0bpFxE392E0Us3fCQW9CUV1GYNnhFG+dzROFtydY7hdK0tn6Ytr5sntKhRTO6Oh1/pzEXc41nSii2gZ90sKVKAR4tCFp+BdbqBq5VtkqX78Y8YKFcN+tJRU79CK9jxpBbNsbSFpF0d3jO8+eNtFFpNp09NlKhUHGFUyc6dylNgPwG/ZPu1MlJ/gYGGj7AajUZEUHevUv+95+Esd+wgZwxgyxZMsk2nRHKfliU/Id1dCQ9PYXTrnZtYXPo3ZscPZqcNYv88Udy40aZ/P/7j7x3T5zwjFlBvHlD3rxJHjzIP0bKj7KjLYPEhrt06fTxkzp+XH5Z+vmJYvsAkS0UEcRUuyuAPwDcAjAHwIPMGlh6SbZQRE+fkqdOcU6QWvvefev3ndH38X+jrjJHDZ2pcVuL5UbL/YbW9PTQz7OwSMdf+ukoxvxgtJ/DoRJLQt/Hxrt7XmIi+G1Jhywfe7LSrCcLdvInS3luAAAgAElEQVTjgYJK5hoJevexo5fiWqb0PWAAqVCQ5Wwv8H7VDvzmW30rSAvHx2zktIgAOR+D2KsZaDYeLGZ+kiUVZ6kuG5hyJ40akZUqpX51klD8/OSXV9euLON6j40KXyO//VZWQTt3vv3qJDZWFOHRo7KSmzWLHDhQ6BMCA2V1lGAca9CeAHnRsaIoSzc30tv73d7nc+dIZ2eyUCFx9vtAkV0UURSAQwCqQXeWdCuzBpZeki0U0dixJMAgV922ys/lF6X4Lity3KDC5bJhnvthhluCR/IlTZyanaQoLnESxiWZHwUr2kC3vZSzSUtiInjl310cMPxlho8vj7NxE+dk/zeWCWh6LNNvjEq/NbSoO4gK/1WEMnmmbaVSzQ5uxrdhNcp9MObxgKdsGX5RB1yMPgTIE0iFIsqdW7c66dBBKH0Sl7GyInv1Erpslcro49+iheilFBEXJxP7sWNCsDp3Ljl0qGzpVahA5s8v9BCJx+DgIB3Ury8M4pMmkcuXk3v28LvxjwgkIHj9/HPSxeXt3+Vr10TZ5csnq64PGNlFEQ0FcBzABQBjAHibFNFb4ulTslgx+kPn7PgZvn/7CavuCKJxnwyfoDNbbJQv6WkVvzryX8sJW36kk8sbehV9mqXj8jXXrdgcO1UmJoI/l1ByZY7KhMeBNLfXHmv0wjRopcoMBn4G5h8mimNCTeOhQpKSyQU+0btviY2MNFPSdwDoNQh8ZQG+qNSAthbR/KzyBd3q5Ngx/dXJ/v3SwDffkLNnC0eOJq5Cjhxk+/bkihXk48epevyHDCFtbdVUPwohT54kN2+Ws6GRI0XBVaki51KJYzcAwn/n6ysKsXt3ctw4CaOyaxd54UKKZzPTpkkzb97EJ4wdK8osCaWZLO7dk3HmyiWMrh84MlMRpWg1p1AovAB0BNABQGEAEwBsJnntHe0kMgXZxWoODx5AUbCA9rYoLkMJNSKUTrivLpBMRROyFQr8A7zwBCLzpnvTn9byxB/l7iJWCfy6CfC8Vhwlcf6t29uOxjhU7TBm147Ens57UNe7LgCgRw9gwwbg0SMxkNPi9WvgwAGJmvf777r0kiWBRo1EKlUCzBNZBJJiqXb/PvDggfxNIPMv1MbQ0HF4ilzIhVBdPSsroEABkYIFjYuzs55fUloxciSwaJF8NADAnDnAiBHAixeAk1PqG3r8GKheXUzZDxwAAgJSrvOeI9tazQEoAWA6gJuZpSnfVbJsRfT8ucFBauIfe1O6XOH1+v3f6df65wWTZk8wyXsmli+Zt1YPXnQx40J8nnS5fCcM0grjapLlnRwusEd3NZcsIc+ckV00gFy6lLK99O23ZIMGss0GSNQ8QM6E7t2TVcf587J6+v57WZV07y6rFF9fXfmEYm5OeniQVatyc9UgAuS/I9bKaujkSVlNZQDdwsuX5C+/kOHhct+rV6IQEMuWyfhu3059o8+fC2GdjQ155Eh6DjdbA9lka84HQBUj6dVhhPonu0qWKKL79+UkuUQJ8qefyB49qB4+wuBd3b/xORkTw79/u284gXgcoJci6cnFJB+ONGniRgz0TlOdyjjKeyjAHRUnGzCEF1VeSbaujZXOsGEd2vIO3IWt29FRaKo7d9YVdnAwbECplPOaihXl/GjYMDnPWb9etvkePtQLh3r6tFTbsCHjXrnXryWuX86c0tfff0t6q1aJQkBs3iwFTp1KXcMREfI5LSwkEOBHhOyiiLbDSAA8AIEAtmXWAN9VskQR3b4tX20Cx6HTKG3wPkdCfkl+hclZPhmaJPPF3ewKC9RrQ5RdnGJZe88t2usv8DVjoDtP2Q9dWJGpGEP18RPM6/2McLjPXvl7sQm20grJs5DnwSM2xRZOxRjuzdGGL+AoGYMGyTnRmjViqXb3rjjFpQHPn0tTQUHp/6rFxMgiLb+4cjEgQD8ibK1aiUJAaJaDf/6ZcuNRUbLqUyrFdPwjQ3ZRRBeSyTuf3gPJKMkSRfT6dfysMJVcuZIE9JxONRIBO55D8bcjIK02Jcsn0vdBkoonlNnySWCndGlnW70FsuUFkNbWVEGhl2+JN1xg05FW9cRk/hjKkQAjYMeNaMkuWEFn6IcUCfB8xgblQ1nUO1ovvSgusVunGH73neympVH/aKFWy8Jq4MD0e8VUKiEM9/aWsbq6iqtRgoUYSXEb0gsBcfasVFi/PvkOYmLIZs2k7IoV6Tfw9wjZRRHdeJu87CZZdkbk4CC/JqdPJ2Hc+mkd2rIMTjE3QrJ8ojRJxoldmYXJ5hfFJY7CdNprYk7ZGoaYAMgW2ESWK6fbfwLYDzo3gOfIoQ0dYV55Gm0Rwe5YrmugYEFywQLGnjjN/Xv1f/woFEJIEBZG7tlDTu10kU2xhblddCbk1tZCXjBkiCyQbt1K/TFPeoU5UqvJrVulPUCOooYNS9p4ziAExL17UvGHH5LuRKUiO3WScgYBmz4eZBdFtAbAZ0bSewFYly6dA3cAnIdEgz0Zn+YCYC+A6/F/nROU/xLADQBXAdRPTR9Zpoh8fMj27Xnnegy9cV37MnfBCoMJZguashzezdvfJO+fNFRs5Tn4c5W3C21czmrTlYhlUVwyKO+OOwzLW0yUEaBn0PA3KpIA1xaxJIqv0qZbIJqhcDbs3NGRewMlcOKoTnfp7KxmhQoJnt/Ll0mA6hUreecOuW6dTPhVq+pHFHd1FVaeSZPkCOX5c+OvQ9Om4k/6Lti/X45rNH03aCDDTA4GISAiJPQHZ840XkGtJvv0kTLTp7/bgN9zZBdFlAcSHO8ghFVhDsTB9R8AbunSuSiiXInSZgEYHX89GsDM+Gs/AGcBWAEoBKEaMkupjyxTRFWqkDVrctUq/fc/cdTUbviJRNr8RUzyfksnz57MjRC6mt9l8dZ+RN6T2jxHvNAL4vcb9KPa5sd97kZdbkUTbVoDh6MkwDBrMO9wsNQQW45qqzN0mVJui66BO3fEf6hPH6r8irMQbjIHhJHjO69Z5KhR5LZtYtVmbi5cQokQEyMGCEuWkD16iC+pQqHronBhsXf49lvyxAkJYTRggNhCvI2h3IkTZN26uvZ9fGSIKbUVGyvlJ05MkKhWy+caPdqwglotvk2AfA8fObKFItIWAGoBGBgvn6Rr58YV0VUAeeOv8wK4Gn/9JYAvE5TbDaBSSn1kmSJq1YosVozjx+tPQq2wQe++DxZzDoZm+eRokswTb8vTdCm01iA9t3M0q5TXndPUxy6+gY4941+UZTFcNKh35gzJ+vXZt4sLlRMVPFlWgt0tQW9tmWC4ycXx43qP6dQxOkaL54F1dU6lCTXL6tWypZUMXr4k9+2TRUTz5sKko6luaam7XriQvH49dQrp4kVh7tHUtbeXhYzWOTUFPH0q9b75JlGGq6usehJj6lSp0K9f1kbyyybIFooIgDWAIQAWAugDwDzdOwduAzgN4BSA3vFpLxKVCYv/uxBA5wTpywC0SaLd3gBOAjjp7u7+7v+Rt0G/fqSLC9u315808uBRlk+EJsl8sXc9xgEerZjXf47eCiihuFnJGZEXbhAg/8Qn3IGGBEgFVCTASyiqVydvXnncjnz5KTERHLZzsCxZ4v1l2kGn8C6hqFDmJIDGwBOIT3j1SohFJ082HKCHhyx1liwRLZHMZK1Wi+5av163yEgoLi6ytTZhgrgnJeQNvXVLznUS6sLu3RPQ9KQS165J3ZUrE2X4+pLt2umnffONFO7c+e1YFz5AZBdFtA7Ar/FK6HcA89O9cyBf/N/c8dtu1ZNRRIuMKKLWKfWRZSuiiRNJgGVKqw1eQpOYJDXyBLnYE0sJkH64wNBfd7KoeySdEUpHK5059qDBsSwyyZseQ8CIk3/rnsE9exgFK225HHjOQ6imZ1qmcasBjFjFjR4tpsvHj5Pz55OtWwv/nKZCzpxiWTZ7tpCYJhNG/N9/pcqkSWIn8L//icFBQuo4OzvD76BCBYNFXKpx/Li0sW1boowKFWSvT4OffpKCLVqkT3iIDwTZRRGdT3BtDuB0hg4EmAhgxAezNbd4Me/APcsnM5NkvlgiirZFdTGBkOMmc31ahn0LN+ICRd93br+I/QMCpLWVWmO3QDjf4LwC5WRSffRIPDp79yYBDrdfQkBiOVniDVcHztE+ps2b69rdvDnRM/zzz5Jx7ZouTa2W+2XL5IDIx0fXgI2NOO6MGyemdxER2mpPnkiR+fP1u4iIEBedhKufhFK2LNm/v6xqrlxJ22Lljz+kjYR+RSRlKaYJc7F+vWjDunVTv+f3kSC7KKLTyd2/c8eAHQCHBNd/A2gAYHYiY4VZ8df+iYwVbmVnY4UHPxr6DZnkIxJFLOG1h1Ze25jX5jyjzMEYmBu1jnQr+TURaDwsyLuKO+5omc8bYgdL4QwB8uuvdfYIQ4bIFl/jxoke4mPHpJEtW5J/2B89kgl90CDxKNUsc8zMRJMMGUL1+g20tVFzyBBdtYgIOZbRhEAC5DypSxdx3Rk1SvRawoCSOXKQ9eqRX30lK50nT5Ie1po1UseAn7RjR3FA2rVLGBMqV5bYRiboIbsoIhWA8HiJABCX4Dr8nTsGvOIVy1kAFwGMjU/PCWAfxHx7HwCXBHXGQqzlrgJomJp+skoRff/FjayfDE2SpeLruIeBOEY3BDMOShZGIuodm2dEp4bEEHei/Dd6eT8Wmc0KvqGZMs7q1XXXixeL8+qDB2Ts0zBJTMrUOSm8fCnLka++ImvUEAckgMVwkS3tdzOqa2/O73iMri76vkzNmokhQ2LExQnV3bJlssgrVUp0nKaep6cQgs+dK6uf16+l3nffSX5wcKIGP/9cMmxsxOM1LOxtXvEPHtlCEX0oklWK6Mu+2TNInUmykeQytIB7W6ldm3SweK2X1rJGKJ8gFy99f5gDB6gIkNUt/+EwBOmV03CdJhaFgnRVPmVJ53usV4/s1k1WKfPnk2vXClvO1auid5K0W1CrxRJh5UrWdZXVWEHc1eunmOuTNNO4RUaShw/L8VTbtuK4qmnP3FwWZpr706cTbek1aCAZvr6pDmXxMSIzFVEiPncT0oynT4Fx44ABA4DixbXJd67FGC2+CJ+jP77LrNGZkJ3xzC9NxRspdmInG2FklxA0PtwBNe/vAdSWMFeqsG+fGfLlUGPUi7FotfdzTFqaH+vWueABdmCl+jXmzlNi0w9PYGOlwhyrSehSOxJlfp8AQB7bTZuAOnWA69fl+vFjiXjw6Md/EBKVA4/CCuLyZUmLjTUcm61lLNxsw5HX6jnclE+QV/UQbjF3kTfyBvLEPcBRVMVedAEA3Ie7tl4Xpy1oXjMK9vYd0vRd2NkB1aqJaBASApw4ARw/LqJBQIBEfNiwAaiT9yLwxx+SsWkTkDt3mvo1IYOQWRovqyTDV0TL4ylULC1lCyPeIqmi7X8p/oo1iUmMSY8eumtL8zheh46Z20ERzhU/qfTKV8ERrv3hJWP+OiEJmzaRJNdOv0kXPKO1ZRznziXHV9xNgLzReBCHWC2ihYWaK1ZIFAdPTzUnDg8nQO6eflKsA2bP1nVSvz5ZsiRVOV35DC48D3/uRW2uRGfOwggOxRx2xCrWxP5kQ1IkJ78FzOCRwMG8XrY9I8tUFdpsb2+J4+DiIgM1FqE1CdE4BlerJkmH1z6UwzBNmbSEgvgIAdPW3HukiOLNtNmihfytXJm8fp3m5iazbZOkXsZCSGwn+P3GO3V6adNz4ilD4Wy0Tn77EzyJgGQbfoQ8bAph7tZQTQ3BXLriMVtjPQnwX5RlboTQFpEEyDb4Lcn2YmHG+8jPf1CB69GaczGEwxDEdljLyjhKd9yhOZIPcZ5asUc4C+Mqq+EQ22IdJ2AC45B6RaRxHjczI3t1iJTDJBcXcsoUKXP6dMbODe85MlMRpRih9X1Hhkdo7dUL2LULePgQWLUKGDAAUTFmsI0KTbmuCR8MeuUahmXP5r5zO7WwHwfwCQCgBM7hPEoaLefRuD6u79oDC3XKbRLASnTFICxAOHRRSbehCZpgBwDgNjxRB3/iFrwBAN9gEGJgiQcooCePkBdqmOm1b6OIQgHzEBSwfIqnahdciPIxGEN+uzC0LXwW8/+rCSuzOESrzOGT6wUWdPwH9QOe4lmsE0KinPAo0gEhkfZ4FG6LkBc2eBRmhZBQS1y8boHQ50qEhsTCJbd5qqK2Vq8OHDkCuOVW4ZJTZTiHXAb27QNevQJq1ZLrTz5J+Qv8SJFtI7S+j5LhK6K6dcny5XX39+/zcpVeafrl9zmSZ2c2yfsvZoooLi8FXnCVhK1oQnuE0wpRnI9BqW9HGUX0qsBj+VMoOGiQmCkDZNeujDp8ggdWB+sVaWK2ky2axjIwUJ+SJ6HY2apYFJdYp+h99ughLkLff0/u2CERFUJDxR7hyhUxGgDEGE0TT8/aWuo8fy5hIDTtTp0q4X5SiyZNxLYgLdD0tbHQcBnIoUOS8d9/kpGRkfo+AMC0NfceKaIiRcg2bfSSdu1MeVvurWIQmeS9Enelvgn/fAxiFKw4EGKqXQJneR7+vAXP1LfbrToHNtRPfAUbXkVh7kMtrkAXTsOX7Od/iE1rvmRpnGYuh+SD4tWvL0wHEycKF5wmvVMnMjZaJWczCR2AEuDuXbJnTzm6sbMTAlTneLLv1q3lGGbXLiFC1bTbtm3aXrG4OPE1+uyz1NfR0PsAFF+hnTv1Bw1IACMTkkRmKiKT1dy7gATu3QMaN9ZLvnM35W2DxNsbJnx4KKG+DCuocB2+AIAh+AZD8A0AYDDm42uMhjWiMQbTDOq6IBTL0RNtsAFxsNBlrDiEK4qdaATgQZ6yePDSEWFvbAzq57z4DAUsHqAAHqJCeXsUqFkYBQoAm6dexNab/gAAJ8VLvKQTrK2BqVOBPHmkro2N7DivXg1ERCixxqcU7K5c0Wv/yRNg+nRg8WK5r1VLLO0uXABKlAA2bgS8vIChQ4HNm4HChcVYbdAgeW3SgnPngJcvgRo1UlderQY+66UGoEQ7/CZb5g0b6go4O8vfsLC0DcSEjENmabyskgxdEWnofeN5S3bs0PnKmcQkSckMjKJ61mwe8+7EmthvtIw9wmmG2BTb6tldxenTyV9+IQ/MOcXr8Obr8TOE0E1TKEFIg4BCofTAbVpZqtjH/wiDzEfRykrNnDl1QUsjI3Vba0olWc7lBkMKCiVOWBg5dqysfszMhGS+WTMp5+JCLlok9adMkS06W1th5Naw59StK+GU0oJ582Qs9++nrvz33+l2GyY2N2KQoAkF8eWXaRvIRwaYtubeE0V06pR8hfHmsp07Z/6kZpIPUxrn+kfvXlnmZ6PlnBHK/vk28WT3b6neslWYDGxthfr61191Bdev57lzcvkNBrJrpau0t4ljOOx5ceZWBgZKXseOcu7Tp48okpUrSVuLaObBI/boEqu37TZokCgfpVL44EJD5ceYJnx3mzayC5YQn30mURjSghYtSC+v1JV9cE9FR4tXLAlxnzAIAaGBqyvZt2/aBvKRITMVkTKrV2TvNe7dk7/u4qC3dCkw+HPjjqwmmJAcfHEVt1AIADBpEqAoW1abV31hFViX2goA2J6jM/wd78EeEZiLoWjoexPLHjVE4M8DULq5O+YfKo2nr23lmTx7VtdB27ZY8dkRWFgQnRy2o1+ezYiMMsMq54HwO/ID/v4bmDwZWL8e8PcH8uUDoqKA0FCgbeVgPIYbfvrFHCoVMHcucO0asGABUKoU8N9/wPDhQI8eskttbg7s2SNtubvrfUx4eIgP+OvXqfte1Grg8OHUbctRTfSvcR4xsQrM7HIRgG4XzgDOzqatueyEzNJ4WSUZuiKqWVN++j18qEvbutXwl6vZazo4XjBIb4gdtLIKyfJf3ybJPLFAtNH0tljHb9GfgNCfadL7erYlJoLjflpJgFzfYCnvWfkwv8ML5sMD3j1yl2Fh5OJvolm+2EttH62wgdvQmLEQUrYYmDMPHrElNpLu7lQHlGXp0mRJ14dUm1toY3yfPi3hGRKPrwDu6d17egpr9uvXYuRgbS3bdTNnJhsNQrtIu3Qpda+YZhX3008pl13fUkKkz6y+ncePicGQQQgIDSpUEPZUE5IETFtz74EiUqt1b6WLC9/06Er11q2MbNcjyyc7k2RfUUHBJ8hlkH4DXqyBA3pp/sozzDHeltV6KhhSrSUBcsHgGyTAcwN/oCNe0C/3E40OIUleuEAOHxRDV+VTAqQbgvmFWRCDCswlQP6OZtoOvi/7PQHyL1Qily7VPtYa1mqNVCyv4jhM1kubPJnculW2zAAhHU3NGc5RiWquZ8SWHL79VsrfupV8udBx85gHjxiQ6w5jY9RJh4DQIGEoCBOMwqSI0lEydEVUtSoJMNICtBkLug8B29TwS92k1PLTLJ8UTZK50tFpB2NgzjrYk2y5vHhIgKxWuTEtp1jy8g/TqYKCFspYjh6lJgsUIJs04f6Sg2mpiGb16moDn5yYVb/xdzRjM/xOM6WOEui7Zrv4EmKJEAE7OuAlO2Ml1QD37KH2rKhIEbJXL/1xNc9/gtevS2QHTVqRIhIiPLW4f1/qLV6cuvJt2pAFC6YQuXvRIvbAMpop4njmpFBsJRkCQgNNKAgTkoRJEaWjZKgiqlhRaI83bWLPZiAmgujUyGBisc1huC3nbms8XLRJPj4pg1N6924IZlHrv4gJ4KQxVWTbbPRouuMOuwZeJIcPF9+YmTO5Bu0JyIStxzCtVpNFi5IALw1eote+jVUcu2AFD6AG+/n+SUB8mgBhsV6+nDxxQvs7Syv5LUJYu7Z0rUlr2FCii6cWcXFSP4EhH588MR4YVa2WgLCdOyfT4MqV3IvaBMjRI3WRZ5MMAaHB55+LpYUJScKkiNJRMlQR5csnDJUkY4cPZat2IOyMnPm0aZflk51Jsqc4Oxo30c7ZoCOL9QffmEMmzKAgVsxxmXWwV8dvGBREWlpyTvXfCYgVm97K4c8/SYALFXL2dOaMhM/u01tNR7ww6HMBBvD+fbFsUyjEsKxrV8lzstIPMXHzpji/KpVCLJKWaApeXmSHDhJCoksXaSMoyLDcpUvSV5J+p5s2MVLpwELWD1nYR6WNQ0SS06ZJ3STZG8aOlY7TEvL1I4NJEaWjZJgiio6Wt3XCBJLkyJGkm9njLJ/YTPL+iidu6e7tQjjPtY5YAMQntrLaRj9c0KXVq0e2bEm6uXHoYNl+mz07wTMaGkoCDMQJliqim6WvXydb5j6S7FiGDhWfoYQMBe64w8KeQmjq7y8B9LZsETPvQoWE5ic1yJ9f2ktIpK3xYUqIJUskL2Gkci327CEtLTk8rxgoHDyonz1ihBhQJImgIGn8xYvUDfojRGYqIpP59tvi4UN5h+LtU63MVQhRmWKbfLSoMQm5HE+nWCwXnuLq0CXIjccGeXfizbfhuw2OjMCwp7sx3nomVPGvab7o2whGPiHtBMRGun59ICQEQQ3+RLt2wMiRwogAAFAqcRF+OIly6K5ejocPiD59gKJFgd1h5fGl4ms8D36DGqVeGIzl+XOgQwe9EFvYima4tngfdu4Uy+eKFYHTp4G9e4HISKByZeCvv5L+7FevAl26yKsDAMOGASNGyHXCuEIaHDoE5M0L+CTmUP3rL6BFC/zr3hrzHndE796G5t1hYcmYbgMmdoXshszSeFklGbYiOnhQflHt3UuS3DXzbJb/ojZJ9pfC7Ytxlltt7X1zbGYz/G5QLmEohaoW/zAYbpyO0QTIV7DRFezalcyRg+zShW/eiEeBhYXsyjE8nCMxkwDZBStoZRFHCwtywADy0dLtvA5vNq2miyRshljuQy3aKSL1xtK9u/wdijlCc0A5ttI4cAcEyMrI11eivf72m/6rcuUK+emnsgKytdW1GxVFNm0qBg+JoVbLzneHDokyTp0iHR0ZU9iPJf1imC+f8UVNq1bCe5ckNm2SQZhCQSQJmLbm3gNFtHKlfH3TpsnBZ9GirIc/jE4+vzhXzPIJ0CTZQ9zaVCEsZKIvb36Qz5FDGwdIIz7Wx9kdyw3OcbzyyjnNjQtRwpOTuPHISIaFkcWLk46O5MFdunMdJeLYzW49b1+OYng4OarvC1riDe2tojlzpmzFAaQ/zhMgPawfsXP7GFasqN/Fb3WWMCZG9xps3ChnSZaWYoBQqZKUCwoiL1/WV0AjR8pZ0s8/S5krV0SHGiMzvX5dyuhZ1126RObKRbq7c+qIMALk778bfz1r1SKrVEnm/T1wQDpIi8nfRwaTIkpHyTBFNHWqfH0zZ8pmNKB1SDTJhy0t25iTAF/AkVZIntk6ObEYZcNWVbtq7838VtPD6wcC5BY0ZRSsuBEt6Qd9q8uK9ud5rs5Q440GB+ud6wCkUqHixeXHqIKCK1r9rg1S2s1qDYM7DGVkpKw8NOXnY5A4wvr5kdeu8eJFslQpXX6ePHIGozGNfvxYjqoAw3AStrbkF1/oGzNoNhM0xzS//GL4ei1dKnlax9dbt+RwKU8eXt51m5aWybN4ly4toSOShCkURIowKaJ0lAxTRL17a0mzjv6zjoMagBWalMjySdIkGS/dXEdob+Zg6Fu306aBG1Fyhfbepk9h3rC3YgBO0glhvD58sZa941Gz3gb1/XGe0/Alb6IQCWFP+B6fMT/u65V7hDw8PmwtK0D468oXC+exIzFU12/A9e7DWLCgrqwScYyBuS7ByYncuZMqFZnfVrbxWrYUzlBAtuPq1zfOs6hQiGl2Yty5I/klS8rfxHx0pFjT5c4dbwX48KGY2jk7U3XmLKtWlVATjx4l/Xp6eEgbScIUCiJFmBRROkqGKaIGDcSzj2TL2YHiQ9ShaZZPkibJHCnVogR/LwK+ghUL4B59cYUBSJtvWA48108b7cijBcFb8KQzQlkS//HVmavi3FO8OJ8/Tl0I7kr4i5vQwiDdDcFcgS5UQcHLKKJ1rC1lf51Hm8zg1g5igeEbpgQAACAASURBVLYBraSCp6doC4WCnD6dk+uJpd2iWZHac6Pk5JNPROkkRmysMHcDojCMwd09PszX06eyMrO3J48d0/oHLV+e/Ovp6EgOHpxMgfBwaWjWrNS87R8lTIooHSXDFJGfn9ACX7zIRV3LE0PcWdBtc5ZPkCbJRBljw6L9we7uQuu0FD1TXbcTfjVIs/LeRYxXskNr8GfbBlRAxW4OG6netJkEqJ4dRGtrslEjefwUCtLZ5rVBO7VLPmFJq8sG6VP6P2Jr533aeyfFC36L/rINlycP42DGgrjL2tirrRQNCx5GVU7EeHpBF+jP0jyOrjmM8+Z5eOhMtB0cyGXLDJkR3N0l39iq5fZtyft29mv5sWdlRR44wPv3pb06dZJnWoiLk/oTJybz/qrVog1NoSCShEkRpaNkiCJSq+UX2qBBrGxtYkj4mCVfpaFE9UlvVdcOEQZplQrOovVYoYyq7jGRALmkzm9iXmZnRy/3WHbqRG7frl9vbrnVPA9/DsfsVPVtpXjDxyfvyc2338pzHRPDSZ/Jtt7/HNayAXZqx6iAioE4oa3fCNupgIp2iOBoTOdTOw9G+RTnGr/JrOt2jgqo9PqrVek1H97WsaHmySPpxnbGNMYM58p2lz3AbduoVsuZj62tONMmh2fPpH6SISA0yJXLFAoiGZgUUTpKhiiisDD56oKCuDLPCAKk0vztD63NPP7M8gnVJFknDX376N3PsenC9m1AjFfSymMXzRVveHz0RtLGhlZK3SokZ07dWU1aZHWPPXKxeDHVrrl5ucVoLlokJs8JyxXLF8YBWMDNQw/x+XPywuLDtIZuBfZlpzt8umSDbG8NGSLWA1WqkIUK8a6FNyfjK30nXZCDrZdQXbKU9v5q/2/I778XmuzTp8mQEPboGksXi5dUQUmuXUtSxx03Z07Kr6fG4m7lyhQKFi4sbK0mGIVJEaWjZIgiOntWvrrffhMXc4CLBppMtE2SSjF/pXcfambDcdBfVe1FbR52B0t2dSGc7hAgLc2Mb4UlJX/9lXSeDV7RU3GbeS2eaNM8PMiePXVlXv91mgwI4AW32mzfJpYKBbWKqBL+EhqHpPbI1Gry2TOqzpzlwZnHWNHLOOtINCwNEr1wgy0Q7+fTqhWf9fqCrnaRDCz0lLG794kp3cuXSfZ94oRUTTIEhAbly5tCQSQDkyJKR8kQRbRtGwnw6m//sZDFffrjPMvYGvchMsmHK5oooIkl0PlMsvVaVqpkkPYvyuo5sQKy/VUT+4y2Ub9OHEePlvOid/0cufCEF/99pZ3X928W/6WR5Q+yXa3HVEBFe8s3HDOGfNa0O7+0+4ZKqPgA+YTFOgXW0+ho8fvW8NYllJtXY4WS+/hxcuNG3kd+AuQ8DJbDID8/drVYTXPE8CwSBUqysxOzvZo1yU6dxFFp3jzuHnuIAHl0fbAuRrkx1K+f9rjlHxFMiigdJUMU0aJFJMCQo9ezfDI0yccp3Tt9wTJl5BymShXyVOmeDClS/a3askIUbwzSHahogtEBpL29mmN81/OZbUGxlx43jjeUhQmQU+oeEouJ0qXFwiABnj6VrbG2bcWCDRCbg0aNyMaNde0XLCg73VSryUGD+Cs6ERACBZLauEJjR0YL6dzBg+SqVbIaGzqUbNdOaMILFZIOAK6FkAxfRDGpnCuXWP81bCixLcaPFyI7e3vJf/TIRH5qBJmpiBTS34eLwMBAnjx5Mn0bHT0amDsXvapfw/J9nunbtgkfDKrjEA6jxju3E4BT2I36GIEgrEB3bbqZUzDadX+O4rn9MXasIsn6I7w2QdW8FebN009vWj8arXf3RmPsQC6E4kLl3phsPxPr9+TQltm74DLqNLQA/PyAbt2AWrWATz9F7QqRuPXYDjcX7oLy046gmTkuzdqO7c8qYts24J9/JMy3mxvQpAnQtClQuzZgZwf88gvQtatuHPnzA8trrEC91d3Ru/jf+O1+RYSGKhAVJVx31tYSjtzaOoUvigSeP8eS+W/Qb2p+BM9Zg7yvbgDBwSIPH8rfkBApmxDm5jLY/PklTnqCv6o8+RDpXBDhdnkRAQdERCoQHg5ERCDJvwmvmzYFxo9PYezZEAqF4hTJwEzpLLM0XlZJhqyIOnYkvbz4uNtIjlAEcQkMnQ1NYpLUiKPNDSptjIeL747l2uuceMqqOJzqdr+3H5ZknuYcaPlykgsX8hyKsw1+I0A64CW/KrmFN3ddpQ1e8bPif8szP2yYrH6WLycBrh5ynICwJgzq+pyFLHShxMuUUXP8eDmrMbbQ+N//dIuRRo3IYrmfESD7Fj3AfPnUbNxYyg0eLGWOHEnb66kJARESQt67J1Fr//lHCLs3bCB/WhrHbyaFcarPT/wCX7Nf1XP81P8MmxU8xVrOZ1jW+jx9ldfohmCjlo2pFTs72fn7/vt3mm2yDDCtiNIPGbIiqlpVfkHduwfcvo0wa8DlzYf9PZqQ/nDIdRwRzyoAjveAcHeD/GK4hDiY4zp809SumVINldo4sX7t2sKWXa4ccOoU0LyZGlu2KuGAcAwerMDQuNlw+XEmoFSi15uFWIsOCA61hpMiHPDxwdNC5bHrlCs2FP0K267IuKytgdo14tA05Ec0PjsNBTrXAn74AbCxMTqGIkWEAfzUKaCO+1Us+acUxhX5DUFXmwEA6tQBOnYEevUS5u2vv0565WFsBRISkvrvyhLRcMxpAQdHJRwdAQcHaP862MTBKi4SwXfjcO+BAvee2ODpK1uDNqzwBsVwGf64iOK4IH9zPIRHQTWU+fMarLC0f11dATOz1A82k5GZKyKTInobuLsDBQrI/gOAvd2qo96KQ7p8qxdAdI4kKptgQjLIfR54UiLN1RzzPEP441wAgIJe9/C/kJVoVSMc/seW4bLKF03Df8UteAOQ0A2VKgHR0VJ3nMdKDLk7BC5ffAbMnAncuQOMHYuTq6+iHE6ib6Hd8OhVG9uWPcE/t91AKJHXJgyPoiSUwp07gIcHZC9u2jTZhwoIADZv1oZJ0SAkREI7BAUBm394AvNrl3Cw0Wxg82YMHG6JhQtT/qxWVvoKI/HfH3+UcnPmJF3GwQFw2PgzrPr2AO7cQVx+D1y/Dly8CFy4IHLxInD9OqBSSXvm5oCvr2wX+vvH//UjvF3CYP74oeEWYMK/jx/L95MQZmbyZSRUUPnyAc2bSwdZDNPWXDpKum/NafhJnJy0a/CRP87UW5Jb+G7M8i0fk7w/kgeP3qm+OWLoYfGAAOlR5BtiIuj7lRO3+1tSbW1F9uvHvZ2WG63r5ERGb96hS9i5k2/eyDbWwFYP9MoGeIZygssC/ouyVJUqw/PnJd3At2frVrFQcHU1iFi3bp3UORF0iJ0Uq+hpHUxNaNV+/WT3z8dHynz+OXn0qHhL3L4tjqrR0UwRyYWAUKnIGzeEtXtapwvsiFUsUfg1LRNYkSsU4mLUogX51Vfiw3T+fOr6ThKxsRKS9ocfhJJcQz1hTHr2fIeO0g8wWc1lY0V0757+QzNjBssPmqv/cttfIsyiCL91WT7JmSRz5ABqZFnfO9GAYzCVSsQx2Kcad1R2ZZFZ7sREsH5ncFP7kQZ1LMxVHFpJSFB/UPTmE+Tiz+jK1livPb+JJ5UnQK7Ja4TtW61mxYpk0aJGXHquXJFAQ+bmwtwQX6B/f9LOOpaxlrYck3c5zczUjI2VKn5+YkVnYWEkDlEaUKsWWbmy8Jru3Cn+tt26CVuQjY3+R/DAbTau+JRffCFWfqdOpWiNnjxevxattWmTMPP/739k9erUUp4nlHz5yBo1pMzMmeTmzXKgpflCshgmRZTcgIEGAK4CuAFgdErl010RHT2q/zBFR9Oh+lLDCaLI70TXWlk+QZokc8QFz/jf5C2Z2mfigHqNoOP9iT5ykMOrVqN5otX5c+TgRRQzCC2hkXx4wN5Ng7l1q0zIkWu20glh7FjjocRmSDihbtzIZcvk8uhRI+/KixdCTQRIdL2oKJbwjmQ9s71k8eL8fq7EYbp7V1i6td+li37YiOSgVov19d695Pz5Mqcb/Vz5yLp1xeJ76VLy2DEy/K9z2s+RJkRHS7ClrVtlOdi3L1m7tmhRhUK/Y1dXsa/v3l2sKH77jTxzhoyISFufWQCTIkpqsIAZgJsAvABYAjgLwC+5OumuiFav1j1kAwbwceRjIucVw4e/RVejL4RJPnzxwO1M6ScPHrEQbmrv6+EPqgGeQSm2hCggR4SxbOEJhM1TWnhvZ/9a3fk5FjA3DC31TiKAakCCD8XFyfMeFcVBlt/RQhkryiEyUriF4itFfDaU9nYqduuWxPuiUonfDsBQSzcC5FSXOWRwMHfvlmYOHRJdoBnHihXGm3r2TMouWiTbdtWr6w2FgP794sXk4cNkaGgSY0suFERsrOzh7dolpHUDBogDrJeXRPpL2Kmzs7A0dO5MTpokc8S//xoPHfsewaSIkhosUAnA7gT3XwL4Mrk66a6I+vXTPYDh4dxyYZfhJKGIJdq1zPIJ0SQfhtT2mEWMB9HyU0KZulAQTgjjRIznNfgwCPqm3AqL16xov40/eE7l9Ik62qDtaKSLSJcgNOql5hKifMaU+C2j4GC9znqbL6ONRQxfBCezpzVzJrdAwqQc/mo3Sdm9A2RLrEULua5VS+bvv/8W/TA4nmAhccA9R0fZfuvdW/TEvn1irq1WS96gQal4l1+8kMbq1ye/+06WS40bC1uDhYV+hw4OEhO9fXs5OFq5UmzCnz17h8kke8OkiJIaLNAGwNIE910ALDRSrjeAkwBOuru7v+W/IQloHkwvL5JknyU/Gk4EnvuzfPIyyYcjD5GXu3xAp9Fgjs7l9PLMyn5rtE5N7GdF/K3Hgu3rq+aY7/6m52w/YiLYrAN4vVMDzpui85UZ1+U246rXkv0xzVJi507WxH565o6UhZJarevI358nasoZ1HdOo0WRaVZTGty5QxYsyOGYTStEMcrMjly8mKHP1ARIb++kP7utrfjidO8uEV137RJGoKQo7jQhICZMiE9QqyWw3oEDYigwcqRoPX9/LRODVmxshIGhdWty9GiJX3H4sE7DfWQwKaKkBgu0NaKIvk2uTrquiDR8IwA5YwZJsnj3xVk+UZnkw5PJ+Erv/ga8eCUn6DsAVNYdkup2JmACm0PiZL18KY9xVGwUZxyZQfuJVrQYB45obscSitPaOjUDIxisyCfbUSQZE8N1dhJzaceO+HehfHltJ+oDB1nKJ4IBdpclzd9fCsYf4Lzx9uM5h8ra9pvn/pveuG4QKgIQg7Lp0+X45ebNVDLvqNVyqHT0KJ8tkOB+80stly1GOzv9DiwtyWLFyObNJd45INYW9++baH4SwaSIkhpsVm7NvXkjNp2aB/r0aZKkTVmTZdz7IjltL2b5GNIi5XBce62AimdRgs+twSKBA1PdRj38wUCcoB8uyAF7AgS/fMjuIwsTE8EcbWtLny7XaGtL5rZ5yb3KekI8RzK6Vz/mUYSwScP41U7XrrJqKliQDAjgtwtEqawadIzr8/TnRIxnG6c9LIaLNEOs3piKFVOzbdFznIRxeukHDqTwDoaGipXBL7/IuVOHDmIKpyGzA3gd3gTIFXlGCm3D4MFyqLRnj9iAJ16tmUJBJAmTIkpqsIA5gFsACiUwVvBPrk66KaLp0/Xf8E6d+LBYASKnYSRMk5gkK+SkRWF2KdLKaF5+3BenoT//1H+uQ0L4bz6wUg8Q7odpYfeAP24/Rb8isVRAxXEeKxgXqyb37+dYTKFCoeatW+TNkd9xC5pyWrNj7IRf6Z5TnwpHoVDTB9fYAps41m4ee7QNJ5AoNMP69Xp1oqIoy7aTJ8V5Z/JkCeFaoYIovYSFlf9v77zDoyy6Nn5PekgCBEJCAoSEJiYISEdEKdLxBcQCooIFsCCCdBAECwq8drBgAT+l2VBEikgTeOmd0AKhE0hIAqmk7N7fH7PZzZJONlmSnN91nWt3pz0zm2eeOzM7M8dBH3TatateE/7xx+Rff3HXr/qooRUrCtivxRVErogQ5VVhoCeAk6bVc1PyS28TIYqM1JPVWTtC9epc9GQ3uz98xMq7WU9vbUNbjlHv68/KeiQy2uF9pjm6Wa8SM7lDNQKcEmTabtBjBB/54Wk+2trizuL1UQZ2dNmSYx0CXS6zp6vFueO/624yqX03/SE0lHRz4xSHmXRUGUw4H6vXhR88yFWTLeW1x+acG1izpl7BMHy4/pHojz+0P6Jc3DtkrsTLcTl5TogriFwRIbKh2USIzp0j27e3/LjZsCGNBiN7vb78DngQiZVna33fVVYb707lbnFwNx8vsAM20A3JDHXfaJXezTmOu92C9Y/2BgPZuzeNgbV5ZWs416GzOZ3y30+4Xs/1up9Pi+R2tOaN+UvNe+s2D9GnNyxs8oFONGWKPsLgtdfYHpvZGtvNBcTDk7VwzlzeC5hvKXzJEj0leBs7S5cu1UWEhRUww4AB+igHIRsiRDY0W03NRUeTq0LGcAamslfzSPr6luwDR0wsJ1uMATx35gAbDa9NuNwwhw/EIqu9QiMqj7bK51tpJ58K/IUPYiOruiXmWHb97muJXi+y0kPDWMkzlkoZ2Ry7CZDLFqXrRI89Rq7UG2mNABvgONthi1VBKXClC25ynPOH5rAR+JQKBjZvmkGAfHuGQR/lDegNoJGRt9VPv/hCF3H5cgEzvPSS3nwkZEOEyIZmCyGaPNnSrxQMDKmfxsGDjXZ/CImVfauG7C62s44kAHI9OjJxz3Z26dtOHy2VQzmdsS7HVWqVK+3nIx0P8pNP9M9HV+DLB7GR1StcZ3Iyue3Mv2wxqgIxuQKrNVliztfQ+VSOFZ6NsQTIoy9/Rv74I7lzJzevtP59aNtHO6lg4Kv4hL0radcW5tnCJUv0MuoaNbTX1kKS+VNuSkohOrejY7lcnp0fIkQ2NFsI0apVpIuLkT6I4knUI9PTeeZaBFEh+0NCTAwgHbqOtEk5vrjCn9G/QGnb1bmcZ/xgLOAcjOE4WB/Siyf6suuH93L9r/+lEeAmaE+vH+E10sWFBgUubAJWHwOrE0M+xQj9Zts2vagA4BX40snRyNdft/Sft97SJ9/Exuqfdu6+m6xVy8j4rxazkbNe7DOz4ULLfNr+/WRQkJ4K/+67QvXVceP0GXkFZs4c3YbMte2CGREiG5qtpubWvbmFHkhgXYQzIoKcO/djuz/sxIpmzkjNP13dNXavp63sn/bTzR/S4MRe+NMcp9yvElPc2HwY+FMI2AHr6YdIJjVuo4crnTox3gWcNLMznZ62uCSf6PQ2MyZP1R8GDyZ9fNjfZxN9fIzm9QQPPaS39JDm0364apU+bs3RUc8sDHP5Tq+EGzpUz6tFR5OdOunEr75KpqUVqJ++8II+Dq/AZJ4kcfZsoZ4H5QERIhuazZZvDx/O7WhNb8frDAgg27SaZ/cHi1jZsr6tHuRHHgOKVIYn4rOFKWSY359HTavI/Whildavy1PEdDBgaB8C5PvuE/VIJSmJDAwkGzfm6ca16B+8ypwntMIGXnp8pF788PnnXA29mnTZMq0fFSpoLTl8WJ+cM2iQ7lKZK9wAsmuHVL3nx9lZZ5g2jYyL055hAX1KdQFOQu3fP3cXEDmSecjd/v239Vgoy4gQ2dBsIkRGo54qAHiox3hW98s+1y4mlpv1b9ybveoPL5FrtcU2TsRMOiHLmXT9BtHX84D5842aIfpkAVOAAYq9scIc7+l4jU2eCCKC11FVuMKpvQIYc/6EPjkaIH18+K/SoyIP/02EcyKdK8bwi6XhZHo6M+5uxECni+zS2cAdO3SWpUv1diAfHz3YIS0/z3Trpj1GkNQHjT7+uM7k56dXHyxYoOfbatXSe4zyoGNHvdahwGzcqK+1YcNtPBjKNiJENjSbCFHm6YwAOWECt0+XY33ESsBUxm3l80EUTyPYOrz+Sjo6WUZLl+CvN4JOnWpO9D+0scrT0s00LdllDD3ecOCola/yXLc2JPQKuVAcZnPs5rQRr9DR7xgBA+99YgUvLV/C6ZhGwHJG8KRJ+nXRIku3atdO7ycdM0brjNV6gR079JYJQKvUtGlaiNzc9IGjudC0Kdm7dyH69oED+hqFdQVRDhAhsqHZRIg++cTSO+fNY2i/HvZ/SJVC64S/7V6H0mC7nO9m1xpv0tHrbJHLaop9ucbtnPy7vr/nzTMH3oAXH8CmbGkHPFyBTlNBp+kOfLofeMgXnIuXdX0ffosXr8UxtIs+ksgxeDNf7dXfvErP1VXPtvXoYRGbpCQ9CzduHPnpp/oaV67c0u+MRr2BtWFDnaBhQ4tnu9Gjc3QgV7u2XjdRYDJdQXzzzW08GMo2IkQ2NJsIUc+e5h65acYwuz+oxMq+7UEz3lSKk4I70bvejwXKMwvZPbH6IZLz8YIl7JZR1g8Tj+h7fNEic6AR4EJk96f1P69aHNUN9JgMYjrY5TEvujkkcoiv5dye9z67TEfXFMLjipXLCk9P/czPZP16Hb5ypT6OB9CDoBxJTye//FJP1WWtUKdOlnk+EwV2AZFJfLwua86cQmQqH4gQ2dCKLEQpKfrfOT8/pjuAXnVW5fkwEBOzlU3FDBJaGH4PrFSgPH3xW47hoThMgBzpNo2eQdaeXYe0DtPnyWX1TgfwOBpk8+T6HiYw0s2Z77QHq40D0ewrOjgm8fvNPzPDoA8UDQsjA+tZnz03eab1DtNp0/QiuevXyYMHdZply/Lpi/Hx2r9D1uO2PD3NCw2yuYAoCEaj/qFq8uRCZCofiBDZ0IosROvW6a+pQwdOahRi94eTWPmyqrjKRFRgAjzogQR2dM1ZaLKaA/L+bWmNczs2aZ19xBNxPJX87TerwJtwYWtst0p3F47xn2bjmOwETg5pqsO7j2SDNypx/i+TmJKWzMTEW+o0phZf+esVXkvSjuQefFD7mSMt/ulmzSpgn7x8WS/zznqBBQt47Zp++/HHhezjPj76xyzBChEiG1qRhWjsWNLFhZHPD7T7Q0ms/NrzLh8RILfiPvbBcvqqvDev5mf70Ygd672eLXxQ/xRe//73bBlyKuMJLOFFBLAVtrNGhRNsNkwR00G/iU6cOTP776jqmS70ft+bH/w7l66uRo4ebelmlStr99+FIizMyi9SeNXWBHJ3NZ4r9evrM+cEK0pSiBwg5M3atcD99+PBnT3tXROhGKmMOHtXIU++TRsFAFj3wHZ0qPQ9ougPf1y+7fLuxWF0O+WE5hWXAyoDFer/BABY9KsbKg/ug/cwEYnwMKffiVbZyliGAWiI40hBBVxKboA5veOxvspoNE3wwOTDjtkv+sNaVN7+McZ8+zNSUxUqNthnjgoKAs6eLWQjQkKAnTuBv/8GAMTFGAAA3ke2FK4cb28g7s7++5d5Skrx7GVFGhFdukQCXD5+st3/IxYrXuuKNRyC7+xej3zN5QYxuiaV2zUCpAPSedylepHLdagQSbdn21uFVcNVfoDRTIYbCbCX705WQhzHYA4dkEEHZLA6LCMzPz/dbW7csJSher5IVXsD3Vwj+R+vxdbXHe/N3ot788S1E+zTp5AbUW/FYODapuMJkFvQTh+vcOBAwfJ266ZHVoIVkKm5O0SIFixghsp5WkJM7E4xh9f92O5pVzqqAhxZlIc5u0cSEyrz7qq/WoX74xLn4mVuQ1sC5NsNvue/uJ81cZ7OSOWD2GhO27kz2a+fJe+GHWfYdfBs/fmZTmya5bepobN/oNdMLzq/5cx7+26mh4exSGePZrqAOIIQSwUGDybPn88744ABenpOsEKEyIZWJCF64gn2Cn7H7g8aMbE87amuxHQQ0xQR8lOu6XyrbaArkvIvb0Jlhtw93fy5AY4TIAOh9zV5Ip7X353LGHibV+nVxPls5fj46EVpKSlkZa9UNqq2mFXGOJnjFQwc3fQnPvt5b6LbKALkB/8sNK++KyyZLiAu7bti2XsEkC4u5MSJelVETrz0kq6sYIUIkQ3ttoUoI4Mn/IPs/5ARK7t2iwfVIlnj74nnW2sxyitdw9/YpHMBPAv3Gs6gTk/QDUmshXOcFbqQrbDDHF8PJ5lR1ZdGgPPwEl2Rs/uJTE+pI0eSLg5p/MWtLwHS54kRRFM9FdrQcz3H1Z6o8wxrxiZfNOGmM5sK3WUzXUAkJ1Mf833ryrqqVfXm9NRU64ziCiJHRIhsaLctRDt32v9BJVYurHbDJbYrzzlnJ3fZbGQw3UIX5J3GNY6eD4yln+M5uiOJy/AY/0Qvc3x1XOYyPEYDFA/inlzLGTxY+zoC9AZbgLx8JZ1LDi9h4DNTrOr8YvAjDJzkRkwH+y/uy4jYiAJ32RxdQHz5pT7CASCrV9evdevqc/MyhUdcQeSICJEN7XaFyNfjSP6dWaxMW1Vl7W8qCBHFdi1nt9iSb2PHKUSXsfmmU3776OWkv4upmME9aGYV3xgH+BbeyJZvKR7nhMar6ORkZOXKlvC7EWZ2emc0Gvn16m10qRyt413i+cqjFflyT7DCFND1TUdOXvQcE1IT8u2zubqA2LJFr6Tw9CSHDSMbNdIVad1ax4kriBwRIbKh3a4Q2fshKCZWYtbttUKl74vf2AVr6Yl4zsXLDMZpc1w9nDS/r4jr/AWP8Gi1B9ipcbRVGWzXzmoqzGoDbPB6Oo+txe5j/dnStDfJf4ITF84eREN0VK59Nk8XEBcuWPYcTZ6sfSwFBFg3TFxBWFGSQiT7iHKhstsle1dBuMNp7fGHvatgG9Z+DNyzqMDJf0c/rENXJMILV+GH4fjKHHcK9c3vG+I4HsWv+CR6IP48FIjhgavNcUO3Dca1BX+aP3t4AI0a6fduVzrA6ZsjWH+tKfYEANUdKiLSPQNDkhehzRQ/bH+mE7B6NWAwWNUrLk5vCcqRmjWBzZuBZ58FZs4E/vgD2LMHeOcdS5onnwSuXi3w9yDYDhGiXIhLJzBbPAAAEdxJREFUqZHn/4UZ6cTFI9ex4q29mPnAUvTw/N3eVRZKmJ2di0mIXOLhhfjiKTs3Dg/KPa5CVK5Rb2MaJmIWHsYKpMIF0zDDHEco3I8t+AovohV2IfX8FXPcNxiKu4a2x/x56TAadVhQENC4MbBntwOCAyoi4/u/cH/Eetx0cjbn2x1A3Fd3IwZ90xMXQ2oCU6YA4eEA8hEiAHBzA779Fpg7F1izBujYEejfX29aB4Bjx4B69YC33waSkvIoSLA5JTX0spfZzENrEUm+nspzv+zi7he+5F/owW8xhJMcprOf8w+s53TI/tMzYna3AOcTdq9DrvZsO72ZNpf4ORjDFLhyGR7LFueI7KsDR+BTs7uJli3J3bu1e6SKFXV/SUwkhwzRaR/okM4Zf85n4EeBepm6yZymKc7ooJjkDLJ9ewb5xPPpgQVzKc5Nm8hq1UgvL/Kzz/SFxo8nH3lEv/f319N3Gbe3lLwsAPmNqOwJUWHISDcyYsMZ/vnUEg71/plPYAnbYzOr4WrhHyBipcrcqtzB/5S0nUO8WrdAaYMQwWbYw1kYxyq4li2+LsJpBPgDBtHPKZpKGc1xcXGWvrBggXZB5OtLrl6Tzh8O/sB7Pr/HSpC8p7tz6UPVWQlxHOk8j3zuOb1uPL/l2OfOkc2bWyo1e7YO37qVbNtWh4WGal8V5XBptwiRDa00ClFhSU1I5bE/TnD96D85rtVGDnJfxh6uS1jDcxfhEl/4B47YnWPN5tu/Drdazf8RlQrmtG+tQwfegBcfwS/Z4j7HiyTA66jI1/CROXzk45E0ZFge/EeO6EUISmn3EenpRq4OX80OCztYBGmaAwFyaPPFpIeHLqhBA/L99/VRXbmRnEw+9ZSlUvHxOtxocotRv74O79gxXzflZQ0RIhtaeRCiwmA0knH7Irh3zCL+3WoKF2Aw38FkDsF3bI7ddEbRjokRKx3mgYQSu1b1mr/yLq91BMjBWGAV9xy+YQYcSIBf43lzeFv3fdw/+nuz29asU3UdO2pPECS58+JO9lvajxhfReftPpLtv76PkV9/RN5/v87g4ED26qWF5dbNrJmdIvPCISHkyZOWuLQ0cu5cffICQD75JHnmTPF31DsAESIbmghR0UhPSWfklnBufmsTZ/ZYzkF1/mIrtwOsjFg+iR/ZHatYG2fs/mAVs4+1CJ6Zf7osG1arNJ/Dx1u1y5ZmB1oxCj4EyHv9LrGaUwwdkMFX1WeM6/mkdhmelmY1VbduneU+XbfrjC6r79PmUVL/Zf158+hhctIky1JtHx9y1Cjy0CHrG71+fV1o1apkpUrkX39Zx9+4oZd9u7npI4PGjCFjYoq9/9kTESIbmghRyRIVfp1bPz/IhYM3cGrLVRxYcSVbYie9EWP3h6ZY8dhW11AGBOTvsC8/q4NTBMjR+ICx0z7kywNiqGCgn8NV/h+eotHXjxw3jkf+OGU1VZeRQe7apcv4flksH/3pUavfkIatGEZjWpoWl/79LScttGhBzptHxsbqPUbduunRTtOmuvB3383+29CFC+Szz+p4b2/yv//VxwmVQUSIbGgiRHcuhnQDo9fsYdikH7jh+R+5tNksfooRHI0P2Ab/s/sDVqyEzONKtrCzjtVIgHveXsVWLQ0EyPurhPGQQxMSYGLLDhxynz6MtWNH7QwP0AclkGT8zXh2/7G7lSCN/3s80zLSyOho7ca1cWOdydXVcmGDgUxKIgcO1J8ffZRMyOFUh0OHyO7ddZqgIHLRIp23DCFCZEMTISo7JF+N57kv/uLmvh/yLe8PzadCZ1pJ/u4hVjSriuh80wSHvst3m3vzWBXF+X3+ZNUqBjo6Gjn6gd28cVdLEuAC56F0d7xpznPkiPU9k5SWxJbzW1oJ0tQNU5mYmqhHO3v36nXjmQUEBuphVkSEHu04OOgjgU6dyvmmXLdOj6AAvQJvw4bi7wglREkKkdLXK7u0aNGCe/bssXc1hBKGRuJ62EVE/X0QF08mY+E/NRB9TWF/fF1Ewc/e1RMKw32zUbvxu+h8ygmXds/E3zeGorpjND4wjMIALMVRhKARwgAAL+BrfDloKxwb3Q14eQGenoCXF2JcjWgZ9hrOpFi82k5sMxaj242Fr6cf8NxzwIIFQNeuwLp1WpY6ddInMvz0E+DuDixZAnTrlr1+RiOweLHeXHv+PNCrFzBrFhAaWlLfULGglNpLskWJXEuESBCAtPibiN5xGlFL1mPT+TrIuJ6IX0/eg52JpfthUua4ZxEcqxyHw45XkZ7qi1YeW/Fd9VlYeroV3sFUAEBHbMAiDII/rmTLfrQa0OYFIMHVEvbyAReM2ZyGOnEAWrTQRzScPp3z9evUAWbM0CKXKXQmsYOTkxaz2bOBhAQtbjNmAAEBxfBFFD8iRDZEhEiwNTQSNy4n4fC2eHz8lTN+21jN3lUSbqEy4rAc/dABm3XA0KFAu3aAmxuYnIy/4nbi4YSvrPI8cQQYl9QUzRM8gcREID4eiIgo/MWV0iMqQI+kVq7Uo6tShgiRDREhEuxNRqoBF45dwtULEXAwHkVU9FlcjLqKiCupOBPlhuNnGuPcmY5IiL63eCpQdw3QZTxQ8RLqJseizUWg0VkfuJ1rjRVxo7ARDxXPde9Q/NyOobbbMdTxuYQLDY5hW9BmoEo44JQOAOhcuRkmNH4JD4X+B6pqVcDRUY+Svv0WGDfOurBhw4D27YGbN7V4JSbq0VDm682bwKRJwL3F9LctRsq8ECmlpgMYCiDaFDSZ5CpT3CQAzwMwABhJcq0pvDmAhQDcAawC8BoLUHkRIqG0YUxKROyFk7h66SSuXo3AuRspOFbhbuzZWhVH/1cHV4/Wz7+QwqAMQPOvgLuXA94RqFE1Hfd51kAbx0C0NQTg3pTKcLqWiMOHga92N8NX8QNte/07nBCEIQRHEep6GqGBCQgNX476CIczMiyJHn4YmDABaNsWcCgbZ0mXFyFKJPnfW8JDACwB0ApAAIB/ADQgaVBK7QLwGoAd0EL0KcnVyAcRIqGsk5yejKikKETGR+Hw8SRs+scduzf64dSeYNtdpOJ5wH8fELAX8N+LqsGX0S6kDtoGtkKbmm3QIqAFPF08tWuG5GTEXkjCF18Bb3xa3XZ1KCWE4ghCM8Wr4kWENkhHvaYecA5poI8Y9/UFqlXTr5Uq6am8O5DyLESTAIDke6bPawFMB3AWwEaSDU3hAwF0IDk8v2uJEAmCBSONiE2JxaHwGKxaTWxa64W9m2rY7gIeVwH/vYD/Png03IH2DxrQOqAN3OKa4e81jtixyRspp1sARotrB0dHoE8f4OWXgQ7tDTi8LR7LfzHg19XuCDvjYbu6FbQJflvh/VgXxFS6iRS4AjENgOhQPLU+BEnXQxGGUJzEXUW6xjo8hIewPufImjWBhg2Bu+7Srw0bWgTMy6vEhKu8CNEQAPEA9gAYQzJOKTUXwA6SP5rSfQtgNbQQvU/yIVN4ewATSPbOpfxhAIYBQGBgYPNz584Va3sEoSxCAvEpybgYG41jZ25gz750HDrgjPAjXrhwohpSEzzzL2RoS6DGLf8I3vQCznQGwnsC4T2AhJrmqHr1MzDiFQcMGeKASpUKVk9DuhHnzxEHDjvi2DHgwgXgjTeAGjV0G2JjgV27gA0btO3bl3tZv7+5D31eqgHExAAxMUiKuojo6HNIiY1CwzgHqJhY4No1HX/lSrbFDClww0k0QBi0YB1FCMIQinA0sEq3Ag/jYawsWAMLQnCwRbQyRaxZMy1ct0mZECKl1D8AchqXT4GeXrsGgADeBuBP8jml1DwA228RolUAzgN47xYhGk/y4fzqISMiQSgZDEYjjpy6jn+3J2LXXgOSGIWqnRZif/Ru7I3cm3MmArh6jxalUz2A8+0AOkG5JGPOt+EY81STkmvAzZvaeV5hMRiA69fN4mUWqszXevWA55/Pv5yUFL0oIiYGuHQJOHECOH7cYleyL0fPlyI830tSiJyKq+BM0cgPpdTXgPlfg4sAamWJrgngsim8Zg7hgiDcITg6OKBJgypo0qAKMBgAggG0zjV9cnoywmPCsTdyLw5eOYhg7/2Ii9uHvVu9cfpgDQTVCCqhmpu4HREC9Nxi1araioK7u7aAAOCee4Du3QuWLyUFuHjRWrROnACGDClafUoQe03N+ZOMNL0fDaA1yQFKqVAAi2FZrLAeQH3TYoXdAF4FsBN6lPRZ5kq7vJARkSAIQuEpEyOifJitlGoKPTA/C2A4AJAMU0r9BOAogAwAr5A0mPK8BMvy7dUmEwRBEEo5sqFVEARByEZJjojKxs4rQRAEodQiQiQIgiDYFREiQRAEwa6IEAmCIAh2RYRIEARBsCsiRIIgCIJdKfPLt5VS0QDsfdicD/SRRuURaXv5RNpe+qlNskS8PpZ5IboTUErtKan1+Hca0nZpe3mjPLf9dpGpOUEQBMGuiBAJgiAIdkWEqGSYb+8K2BFpe/lE2i4UGPmNSBAEQbArMiISBEEQ7IoIkSAIgmBXRIhsjFJqulLqklLqgMl6ZombpJQ6pZQ6oZTqliW8uVLqsCnuU6WUsk/tbYtSqrupraeUUhPtXZ/iQCl11vS3O6CU2mMKq6KUWqeUCje9emdJn+M9UBpQSn2nlIpSSh3JElbotpbG+z2XtktftxUkxWxoAKYDGJtDeAiAgwBcoX0onwbgaIrbBaAtAAXt8K+Hvdthg+/B0dTGOgBcTG0PsXe9iqGdZwH43BI2G8BE0/uJAGbldw+UBgPwAIBmAI4Upa2l8X7Ppe3S121kMiIqOfoAWEoyleQZAKcAtFJK+QOoSHI79Z36fwD62rOiNqIVgFMkI0imAVgK/R2UB/oA+N70/ntY/p453gN2qN9tQfJfALG3BBeqraX1fs+l7blRptpeEogQFQ8jlFKHTMP5zKmKGgAuZElz0RRWw/T+1vDSTm7tLWsQwN9Kqb1KqWGmMD+SkQBgevU1hZfF76SwbS1r97v0dRsgQnQbKKX+UUodycH6APgCQF0ATQFEAvggM1sORTGP8NJOWW3XrbQj2QxADwCvKKUeyCNteflOgPJxv0tftxFO9q5AaYTkQwVJp5T6GsBK08eLAGplia4J4LIpvGYO4aWd3NpbpiB52fQapZRaDj3VdlUp5U8y0jQdE2VKXha/k8K2tczc7ySvZr4v5329yMiIyMaYOmMm/QBkrrJZAWCAUspVKRUMoD6AXabpjASlVBvTCppnAPxRopUuHnYDqK+UClZKuQAYAP0dlBmUUh5KKa/M9wC6Qv+9VwAYbEo2GJa/Z473QMnW2uYUqq1l6X6Xvm47ZERke2YrpZpCD7nPAhgOACTDlFI/ATgKIAPAKyQNpjwvAVgIwB16Jc3qEq6zzSGZoZQaAWAt9Aq670iG2blatsYPwHLTClwnAItJrlFK7Qbwk1LqeQDnATwG5HsP3PEopZYA6ADARyl1EcCbAN5H4dta6u73XNreQfq6bZAjfgRBEAS7IlNzgiAIgl0RIRIEQRDsigiRIAiCYFdEiARBEAS7IkIkCIIg2BURIkEoIkopg+n05SNKqZ+VUhVM4dWVUkuVUqeVUkeVUquUUg2y5ButlLqplKqUR9lrlFLXlVIrc0sjCKUdESJBKDopJJuSbAQgDcCLpg2LywFsIlmXZAiAydB7jzIZCL3xt18eZc8B8HQx1VsQ7ghEiATBtmwBUA9ARwDpJL/MjCB5gOQWAFBK1QXgCeANaEHKEZLrASQUa40Fwc6IEAmCjVBKOUEffnoYQCMAe/NIPhDAEmjhuksp5ZtHWkEo04gQCULRcVdKHQCwB/qYm28LkGcAtM8aI4DfYDoaRxDKI3LWnCAUnRSSTbMGKKXCADyaU2KlVGPogzDXmc6pcwEQAWBeMddTEO5IZEQkCMXDBgCuSqmhmQFKqZZKqQehp+WmkwwyWQCAGkqp2vaqrCDYExEiQSgGTK6g+wHoYlq+HQZgOrT/mQHQK+qystwUboVSaguAnwF0VkpdVEp1K9aKC4IdkNO3BUEQBLsiIyJBEATBrogQCYIgCHZFhEgQBEGwKyJEgiAIgl0RIRIEQRDsigiRIAiCYFdEiARBEAS78v89xIEmQeGlSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "pca = PCA (n_components=2)\n",
    "concat = np.concatenate((X_train,X_val,test_data_clean),axis=0)\n",
    "\n",
    "pca.fit(concat)\n",
    "trainPoints = pca.transform(X_train)\n",
    "valPoints = pca.transform(X_val)\n",
    "testPoints = pca.transform (test_data_clean)\n",
    "\n",
    "plt.plot(trainPoints[:,0], trainPoints[:,1], c=\"red\")\n",
    "valPoints = pca.transform(X_val)\n",
    "plt.plot(valPoints[:,0], valPoints[:,1], c=\"green\")\n",
    "\n",
    "plt.plot(testPoints[:,0], testPoints[:,1], c=\"blue\")\n",
    "plt.title (\"PCA: All three datasets belong to the same distribution\", fontweight=\"bold\")\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.legend([\"Training Points\",\"Validation Points\",\"Test Points\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "def rmsle_error(y_true, y_pred): \n",
    "    return tf.math.sqrt(keras.losses.MSLE(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 260 samples\n",
      "Epoch 1/400\n",
      "1200/1200 [==============================] - 1s 747us/sample - loss: 5.5763 - val_loss: 4.3880\n",
      "Epoch 2/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 3.6270 - val_loss: 2.9255\n",
      "Epoch 3/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 2.3212 - val_loss: 1.7330\n",
      "Epoch 4/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 1.1885 - val_loss: 0.6845\n",
      "Epoch 5/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.4040 - val_loss: 0.2722\n",
      "Epoch 6/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.2660 - val_loss: 0.2705\n",
      "Epoch 7/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: 0.2649 - val_loss: 0.2690\n",
      "Epoch 8/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.2636 - val_loss: 0.2675\n",
      "Epoch 9/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.2620 - val_loss: 0.2659\n",
      "Epoch 10/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.2603 - val_loss: 0.2640\n",
      "Epoch 11/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.2584 - val_loss: 0.2605\n",
      "Epoch 12/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.2563 - val_loss: 0.2585\n",
      "Epoch 13/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.2550 - val_loss: 0.2578\n",
      "Epoch 14/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.2523 - val_loss: 0.2539\n",
      "Epoch 15/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.2495 - val_loss: 0.2523\n",
      "Epoch 16/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.2477 - val_loss: 0.2496\n",
      "Epoch 17/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.2453 - val_loss: 0.2472\n",
      "Epoch 18/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.2428 - val_loss: 0.2450\n",
      "Epoch 19/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.2402 - val_loss: 0.2426\n",
      "Epoch 20/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.2382 - val_loss: 0.2397\n",
      "Epoch 21/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.2352 - val_loss: 0.2367\n",
      "Epoch 22/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.2326 - val_loss: 0.2343\n",
      "Epoch 23/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.2302 - val_loss: 0.2314\n",
      "Epoch 24/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.2273 - val_loss: 0.2282\n",
      "Epoch 25/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.2242 - val_loss: 0.2257\n",
      "Epoch 26/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.2212 - val_loss: 0.2219\n",
      "Epoch 27/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.2179 - val_loss: 0.2194\n",
      "Epoch 28/400\n",
      "1200/1200 [==============================] - 0s 182us/sample - loss: 0.2154 - val_loss: 0.2179\n",
      "Epoch 29/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.2117 - val_loss: 0.2126\n",
      "Epoch 30/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.2080 - val_loss: 0.2097\n",
      "Epoch 31/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.2051 - val_loss: 0.2074\n",
      "Epoch 32/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.2038 - val_loss: 0.2053\n",
      "Epoch 33/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.2019 - val_loss: 0.2066\n",
      "Epoch 34/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1991 - val_loss: 0.2029\n",
      "Epoch 35/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1978 - val_loss: 0.2014\n",
      "Epoch 36/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1988 - val_loss: 0.2010\n",
      "Epoch 37/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1965 - val_loss: 0.2026\n",
      "Epoch 38/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1954 - val_loss: 0.1994\n",
      "Epoch 39/400\n",
      "1200/1200 [==============================] - 0s 163us/sample - loss: 0.1942 - val_loss: 0.1977\n",
      "Epoch 40/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1928 - val_loss: 0.2085\n",
      "Epoch 41/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1928 - val_loss: 0.1965\n",
      "Epoch 42/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1919 - val_loss: 0.1955\n",
      "Epoch 43/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1908 - val_loss: 0.1952\n",
      "Epoch 44/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: 0.1912 - val_loss: 0.1942\n",
      "Epoch 45/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1905 - val_loss: 0.1938\n",
      "Epoch 46/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1900 - val_loss: 0.1931\n",
      "Epoch 47/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1893 - val_loss: 0.1925\n",
      "Epoch 48/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1890 - val_loss: 0.1928\n",
      "Epoch 49/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1881 - val_loss: 0.1916\n",
      "Epoch 50/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: 0.1870 - val_loss: 0.1911\n",
      "Epoch 51/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1868 - val_loss: 0.1929\n",
      "Epoch 52/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.1861 - val_loss: 0.1911\n",
      "Epoch 53/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1857 - val_loss: 0.1946\n",
      "Epoch 54/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: 0.1850 - val_loss: 0.1921\n",
      "Epoch 55/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1850 - val_loss: 0.1881\n",
      "Epoch 56/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1840 - val_loss: 0.1873\n",
      "Epoch 57/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1832 - val_loss: 0.1854\n",
      "Epoch 58/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1826 - val_loss: 0.1852\n",
      "Epoch 59/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1821 - val_loss: 0.1834\n",
      "Epoch 60/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1818 - val_loss: 0.1847\n",
      "Epoch 61/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1809 - val_loss: 0.1833\n",
      "Epoch 62/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1797 - val_loss: 0.1823\n",
      "Epoch 63/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1791 - val_loss: 0.1813\n",
      "Epoch 64/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1782 - val_loss: 0.1806\n",
      "Epoch 65/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1785 - val_loss: 0.1798\n",
      "Epoch 66/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1779 - val_loss: 0.1791\n",
      "Epoch 67/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.1765 - val_loss: 0.1775\n",
      "Epoch 68/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1753 - val_loss: 0.1767\n",
      "Epoch 69/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1755 - val_loss: 0.1766\n",
      "Epoch 70/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: 0.1736 - val_loss: 0.1806\n",
      "Epoch 71/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1729 - val_loss: 0.1766\n",
      "Epoch 72/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1727 - val_loss: 0.1750\n",
      "Epoch 73/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1716 - val_loss: 0.1724\n",
      "Epoch 74/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1704 - val_loss: 0.1741\n",
      "Epoch 75/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1707 - val_loss: 0.1709\n",
      "Epoch 76/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1714 - val_loss: 0.1772\n",
      "Epoch 77/400\n",
      "1200/1200 [==============================] - 0s 217us/sample - loss: 0.1692 - val_loss: 0.1695\n",
      "Epoch 78/400\n",
      "1200/1200 [==============================] - 0s 181us/sample - loss: 0.1683 - val_loss: 0.1688\n",
      "Epoch 79/400\n",
      "1200/1200 [==============================] - 0s 181us/sample - loss: 0.1676 - val_loss: 0.1700\n",
      "Epoch 80/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1663 - val_loss: 0.1708\n",
      "Epoch 81/400\n",
      "1200/1200 [==============================] - 0s 164us/sample - loss: 0.1661 - val_loss: 0.1673\n",
      "Epoch 82/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1659 - val_loss: 0.1650\n",
      "Epoch 83/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1652 - val_loss: 0.1707\n",
      "Epoch 84/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1654 - val_loss: 0.1627\n",
      "Epoch 85/400\n",
      "1200/1200 [==============================] - 0s 175us/sample - loss: 0.1633 - val_loss: 0.1633\n",
      "Epoch 86/400\n",
      "1200/1200 [==============================] - 0s 173us/sample - loss: 0.1629 - val_loss: 0.1611\n",
      "Epoch 87/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: 0.1620 - val_loss: 0.1614\n",
      "Epoch 88/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1611 - val_loss: 0.1595\n",
      "Epoch 89/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1609 - val_loss: 0.1586\n",
      "Epoch 90/400\n",
      "1200/1200 [==============================] - 0s 158us/sample - loss: 0.1599 - val_loss: 0.1607\n",
      "Epoch 91/400\n",
      "1200/1200 [==============================] - 0s 160us/sample - loss: 0.1584 - val_loss: 0.1572\n",
      "Epoch 92/400\n",
      "1200/1200 [==============================] - 0s 164us/sample - loss: 0.1596 - val_loss: 0.1560\n",
      "Epoch 93/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1590 - val_loss: 0.1567\n",
      "Epoch 94/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1572 - val_loss: 0.1541\n",
      "Epoch 95/400\n",
      "1200/1200 [==============================] - 0s 171us/sample - loss: 0.1581 - val_loss: 0.1553\n",
      "Epoch 96/400\n",
      "1200/1200 [==============================] - 0s 171us/sample - loss: 0.1557 - val_loss: 0.1522\n",
      "Epoch 97/400\n",
      "1200/1200 [==============================] - 0s 173us/sample - loss: 0.1563 - val_loss: 0.1521\n",
      "Epoch 98/400\n",
      "1200/1200 [==============================] - 0s 160us/sample - loss: 0.1554 - val_loss: 0.1509\n",
      "Epoch 99/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1559 - val_loss: 0.1535\n",
      "Epoch 100/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1533 - val_loss: 0.1497\n",
      "Epoch 101/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1539 - val_loss: 0.1519\n",
      "Epoch 102/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1548 - val_loss: 0.1487\n",
      "Epoch 103/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1541 - val_loss: 0.1613\n",
      "Epoch 104/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1538 - val_loss: 0.1480\n",
      "Epoch 105/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1509 - val_loss: 0.1488\n",
      "Epoch 106/400\n",
      "1200/1200 [==============================] - 0s 168us/sample - loss: 0.1518 - val_loss: 0.1483\n",
      "Epoch 107/400\n",
      "1200/1200 [==============================] - 0s 165us/sample - loss: 0.1516 - val_loss: 0.1485\n",
      "Epoch 108/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1505 - val_loss: 0.1480\n",
      "Epoch 109/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1500 - val_loss: 0.1505\n",
      "Epoch 110/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1514 - val_loss: 0.1449\n",
      "Epoch 111/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1487 - val_loss: 0.1474\n",
      "Epoch 112/400\n",
      "1200/1200 [==============================] - 0s 164us/sample - loss: 0.1492 - val_loss: 0.1453\n",
      "Epoch 113/400\n",
      "1200/1200 [==============================] - 0s 162us/sample - loss: 0.1480 - val_loss: 0.1444\n",
      "Epoch 114/400\n",
      "1200/1200 [==============================] - 0s 158us/sample - loss: 0.1483 - val_loss: 0.1448\n",
      "Epoch 115/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1482 - val_loss: 0.1438\n",
      "Epoch 116/400\n",
      "1200/1200 [==============================] - 0s 161us/sample - loss: 0.1469 - val_loss: 0.1432\n",
      "Epoch 117/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1468 - val_loss: 0.1434\n",
      "Epoch 118/400\n",
      "1200/1200 [==============================] - 0s 159us/sample - loss: 0.1466 - val_loss: 0.1457\n",
      "Epoch 119/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1465 - val_loss: 0.1468\n",
      "Epoch 120/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1470 - val_loss: 0.1430\n",
      "Epoch 121/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1475 - val_loss: 0.1423\n",
      "Epoch 122/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1455 - val_loss: 0.1422\n",
      "Epoch 123/400\n",
      "1200/1200 [==============================] - 0s 162us/sample - loss: 0.1448 - val_loss: 0.1420\n",
      "Epoch 124/400\n",
      "1200/1200 [==============================] - 0s 161us/sample - loss: 0.1447 - val_loss: 0.1487\n",
      "Epoch 125/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1440 - val_loss: 0.1407\n",
      "Epoch 126/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1443 - val_loss: 0.1423\n",
      "Epoch 127/400\n",
      "1200/1200 [==============================] - 0s 167us/sample - loss: 0.1431 - val_loss: 0.1423\n",
      "Epoch 128/400\n",
      "1200/1200 [==============================] - 0s 160us/sample - loss: 0.1437 - val_loss: 0.1396\n",
      "Epoch 129/400\n",
      "1200/1200 [==============================] - 0s 159us/sample - loss: 0.1431 - val_loss: 0.1437\n",
      "Epoch 130/400\n",
      "1200/1200 [==============================] - 0s 180us/sample - loss: 0.1420 - val_loss: 0.1419\n",
      "Epoch 131/400\n",
      "1200/1200 [==============================] - 0s 158us/sample - loss: 0.1411 - val_loss: 0.1397\n",
      "Epoch 132/400\n",
      "1200/1200 [==============================] - 0s 177us/sample - loss: 0.1429 - val_loss: 0.1405\n",
      "Epoch 133/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: 0.1418 - val_loss: 0.1396\n",
      "Epoch 134/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1422 - val_loss: 0.1387\n",
      "Epoch 135/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.1403 - val_loss: 0.1388\n",
      "Epoch 136/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1415 - val_loss: 0.1456\n",
      "Epoch 137/400\n",
      "1200/1200 [==============================] - 0s 159us/sample - loss: 0.1393 - val_loss: 0.1382\n",
      "Epoch 138/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.1394 - val_loss: 0.1365\n",
      "Epoch 139/400\n",
      "1200/1200 [==============================] - 0s 159us/sample - loss: 0.1385 - val_loss: 0.1387\n",
      "Epoch 140/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1388 - val_loss: 0.1407\n",
      "Epoch 141/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1401 - val_loss: 0.1371\n",
      "Epoch 142/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1385 - val_loss: 0.1417\n",
      "Epoch 143/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1383 - val_loss: 0.1371\n",
      "Epoch 144/400\n",
      "1200/1200 [==============================] - 0s 166us/sample - loss: 0.1390 - val_loss: 0.1358\n",
      "Epoch 145/400\n",
      "1200/1200 [==============================] - 0s 165us/sample - loss: 0.1368 - val_loss: 0.1348\n",
      "Epoch 146/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1365 - val_loss: 0.1345\n",
      "Epoch 147/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1365 - val_loss: 0.1431\n",
      "Epoch 148/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1388 - val_loss: 0.1340\n",
      "Epoch 149/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1362 - val_loss: 0.1341\n",
      "Epoch 150/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1349 - val_loss: 0.1342\n",
      "Epoch 151/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1352 - val_loss: 0.1340\n",
      "Epoch 152/400\n",
      "1200/1200 [==============================] - 0s 165us/sample - loss: 0.1350 - val_loss: 0.1423\n",
      "Epoch 153/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1348 - val_loss: 0.1333\n",
      "Epoch 154/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1339 - val_loss: 0.1365\n",
      "Epoch 155/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1335 - val_loss: 0.1325\n",
      "Epoch 156/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1347 - val_loss: 0.1335\n",
      "Epoch 157/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.1327 - val_loss: 0.1416\n",
      "Epoch 158/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1334 - val_loss: 0.1322\n",
      "Epoch 159/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1333 - val_loss: 0.1344\n",
      "Epoch 160/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1328 - val_loss: 0.1306\n",
      "Epoch 161/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1344 - val_loss: 0.1319\n",
      "Epoch 162/400\n",
      "1200/1200 [==============================] - 0s 144us/sample - loss: 0.1319 - val_loss: 0.1300\n",
      "Epoch 163/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1329 - val_loss: 0.1357\n",
      "Epoch 164/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1313 - val_loss: 0.1296\n",
      "Epoch 165/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1314 - val_loss: 0.1305\n",
      "Epoch 166/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1311 - val_loss: 0.1291\n",
      "Epoch 167/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1311 - val_loss: 0.1401\n",
      "Epoch 168/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1336 - val_loss: 0.1314\n",
      "Epoch 169/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1318 - val_loss: 0.1311\n",
      "Epoch 170/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1296 - val_loss: 0.1283\n",
      "Epoch 171/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1290 - val_loss: 0.1274\n",
      "Epoch 172/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1285 - val_loss: 0.1314\n",
      "Epoch 173/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1305 - val_loss: 0.1316\n",
      "Epoch 174/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1280 - val_loss: 0.1284\n",
      "Epoch 175/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1288 - val_loss: 0.1276\n",
      "Epoch 176/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1280 - val_loss: 0.1271\n",
      "Epoch 177/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1273 - val_loss: 0.1304\n",
      "Epoch 178/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1269 - val_loss: 0.1272\n",
      "Epoch 179/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1273 - val_loss: 0.1289\n",
      "Epoch 180/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1263 - val_loss: 0.1277\n",
      "Epoch 181/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1272 - val_loss: 0.1270\n",
      "Epoch 182/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1273 - val_loss: 0.1270\n",
      "Epoch 183/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1257 - val_loss: 0.1305\n",
      "Epoch 184/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1264 - val_loss: 0.1255\n",
      "Epoch 185/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1251 - val_loss: 0.1249\n",
      "Epoch 186/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1255 - val_loss: 0.1242\n",
      "Epoch 187/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1244 - val_loss: 0.1293\n",
      "Epoch 188/400\n",
      "1200/1200 [==============================] - 0s 158us/sample - loss: 0.1240 - val_loss: 0.1260\n",
      "Epoch 189/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1246 - val_loss: 0.1238\n",
      "Epoch 190/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1251 - val_loss: 0.1242\n",
      "Epoch 191/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1242 - val_loss: 0.1305\n",
      "Epoch 192/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1246 - val_loss: 0.1311\n",
      "Epoch 193/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1236 - val_loss: 0.1239\n",
      "Epoch 194/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1253 - val_loss: 0.1220\n",
      "Epoch 195/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1229 - val_loss: 0.1215\n",
      "Epoch 196/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1239 - val_loss: 0.1225\n",
      "Epoch 197/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1230 - val_loss: 0.1228\n",
      "Epoch 198/400\n",
      "1200/1200 [==============================] - 0s 159us/sample - loss: 0.1247 - val_loss: 0.1208\n",
      "Epoch 199/400\n",
      "1200/1200 [==============================] - 0s 159us/sample - loss: 0.1240 - val_loss: 0.1298\n",
      "Epoch 200/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1244 - val_loss: 0.1214\n",
      "Epoch 201/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1226 - val_loss: 0.1230\n",
      "Epoch 202/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1224 - val_loss: 0.1257\n",
      "Epoch 203/400\n",
      "1200/1200 [==============================] - 0s 158us/sample - loss: 0.1214 - val_loss: 0.1238\n",
      "Epoch 204/400\n",
      "1200/1200 [==============================] - 0s 173us/sample - loss: 0.1215 - val_loss: 0.1216\n",
      "Epoch 205/400\n",
      "1200/1200 [==============================] - 0s 164us/sample - loss: 0.1214 - val_loss: 0.1201\n",
      "Epoch 206/400\n",
      "1200/1200 [==============================] - 0s 158us/sample - loss: 0.1217 - val_loss: 0.1226\n",
      "Epoch 207/400\n",
      "1200/1200 [==============================] - 0s 159us/sample - loss: 0.1199 - val_loss: 0.1196\n",
      "Epoch 208/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1203 - val_loss: 0.1208\n",
      "Epoch 209/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1192 - val_loss: 0.1197\n",
      "Epoch 210/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: 0.1195 - val_loss: 0.1263\n",
      "Epoch 211/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1209 - val_loss: 0.1253\n",
      "Epoch 212/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1198 - val_loss: 0.1195\n",
      "Epoch 213/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1207 - val_loss: 0.1184\n",
      "Epoch 214/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1191 - val_loss: 0.1195\n",
      "Epoch 215/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1191 - val_loss: 0.1192\n",
      "Epoch 216/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1186 - val_loss: 0.1198\n",
      "Epoch 217/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1179 - val_loss: 0.1203\n",
      "Epoch 218/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1194 - val_loss: 0.1267\n",
      "Epoch 219/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1211 - val_loss: 0.1265\n",
      "Epoch 220/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1221 - val_loss: 0.1177\n",
      "Epoch 221/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1213 - val_loss: 0.1178\n",
      "Epoch 222/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1198 - val_loss: 0.1255\n",
      "Epoch 223/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1189 - val_loss: 0.1244\n",
      "Epoch 224/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1168 - val_loss: 0.1185\n",
      "Epoch 225/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1184 - val_loss: 0.1169\n",
      "Epoch 226/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.1163 - val_loss: 0.1197\n",
      "Epoch 227/400\n",
      "1200/1200 [==============================] - 0s 158us/sample - loss: 0.1175 - val_loss: 0.1174\n",
      "Epoch 228/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1190 - val_loss: 0.1196\n",
      "Epoch 229/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1165 - val_loss: 0.1174\n",
      "Epoch 230/400\n",
      "1200/1200 [==============================] - 0s 158us/sample - loss: 0.1177 - val_loss: 0.1171\n",
      "Epoch 231/400\n",
      "1200/1200 [==============================] - 0s 158us/sample - loss: 0.1153 - val_loss: 0.1159\n",
      "Epoch 232/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: 0.1209 - val_loss: 0.1170\n",
      "Epoch 233/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1178 - val_loss: 0.1160\n",
      "Epoch 234/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1142 - val_loss: 0.1142\n",
      "Epoch 235/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1175 - val_loss: 0.1182\n",
      "Epoch 236/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1157 - val_loss: 0.1166\n",
      "Epoch 237/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.1138 - val_loss: 0.1143\n",
      "Epoch 238/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1137 - val_loss: 0.1173\n",
      "Epoch 239/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1164 - val_loss: 0.1174\n",
      "Epoch 240/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1149 - val_loss: 0.1134\n",
      "Epoch 241/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.1138 - val_loss: 0.1139\n",
      "Epoch 242/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: 0.1151 - val_loss: 0.1135\n",
      "Epoch 243/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1162 - val_loss: 0.1151\n",
      "Epoch 244/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1134 - val_loss: 0.1127\n",
      "Epoch 245/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1123 - val_loss: 0.1150\n",
      "Epoch 246/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1125 - val_loss: 0.1124\n",
      "Epoch 247/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1149 - val_loss: 0.1140\n",
      "Epoch 248/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1129 - val_loss: 0.1144\n",
      "Epoch 249/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1122 - val_loss: 0.1156\n",
      "Epoch 250/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1137 - val_loss: 0.1135\n",
      "Epoch 251/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1128 - val_loss: 0.1117\n",
      "Epoch 252/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1126 - val_loss: 0.1116\n",
      "Epoch 253/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1107 - val_loss: 0.1129\n",
      "Epoch 254/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1144 - val_loss: 0.1131\n",
      "Epoch 255/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: 0.1119 - val_loss: 0.1122\n",
      "Epoch 256/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1132 - val_loss: 0.1250\n",
      "Epoch 257/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1112 - val_loss: 0.1120\n",
      "Epoch 258/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1115 - val_loss: 0.1124\n",
      "Epoch 259/400\n",
      "1200/1200 [==============================] - 0s 160us/sample - loss: 0.1112 - val_loss: 0.1109\n",
      "Epoch 260/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1108 - val_loss: 0.1126\n",
      "Epoch 261/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1103 - val_loss: 0.1129\n",
      "Epoch 262/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: 0.1113 - val_loss: 0.1145\n",
      "Epoch 263/400\n",
      "1200/1200 [==============================] - 0s 158us/sample - loss: 0.1117 - val_loss: 0.1120\n",
      "Epoch 264/400\n",
      "1200/1200 [==============================] - 0s 177us/sample - loss: 0.1125 - val_loss: 0.1216\n",
      "Epoch 265/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1105 - val_loss: 0.1152\n",
      "Epoch 266/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1106 - val_loss: 0.1168\n",
      "Epoch 267/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1108 - val_loss: 0.1135\n",
      "Epoch 268/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1096 - val_loss: 0.1106\n",
      "Epoch 269/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1121 - val_loss: 0.1117\n",
      "Epoch 270/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1095 - val_loss: 0.1108\n",
      "Epoch 271/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.1096 - val_loss: 0.1172\n",
      "Epoch 272/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1103 - val_loss: 0.1108\n",
      "Epoch 273/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1106 - val_loss: 0.1105\n",
      "Epoch 274/400\n",
      "1200/1200 [==============================] - 0s 158us/sample - loss: 0.1075 - val_loss: 0.1099\n",
      "Epoch 275/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1089 - val_loss: 0.1109\n",
      "Epoch 276/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1094 - val_loss: 0.1099\n",
      "Epoch 277/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1082 - val_loss: 0.1126\n",
      "Epoch 278/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1086 - val_loss: 0.1108\n",
      "Epoch 279/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1076 - val_loss: 0.1120\n",
      "Epoch 280/400\n",
      "1200/1200 [==============================] - 0s 159us/sample - loss: 0.1073 - val_loss: 0.1087\n",
      "Epoch 281/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1076 - val_loss: 0.1164\n",
      "Epoch 282/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1084 - val_loss: 0.1096\n",
      "Epoch 283/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1083 - val_loss: 0.1122\n",
      "Epoch 284/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1076 - val_loss: 0.1091\n",
      "Epoch 285/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1087 - val_loss: 0.1087\n",
      "Epoch 286/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.1077 - val_loss: 0.1095\n",
      "Epoch 287/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1074 - val_loss: 0.1091\n",
      "Epoch 288/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1082 - val_loss: 0.1150\n",
      "Epoch 289/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1104 - val_loss: 0.1081\n",
      "Epoch 290/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1063 - val_loss: 0.1075\n",
      "Epoch 291/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1083 - val_loss: 0.1155\n",
      "Epoch 292/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1052 - val_loss: 0.1163\n",
      "Epoch 293/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1070 - val_loss: 0.1078\n",
      "Epoch 294/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1073 - val_loss: 0.1086\n",
      "Epoch 295/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1065 - val_loss: 0.1134\n",
      "Epoch 296/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1078 - val_loss: 0.1083\n",
      "Epoch 297/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1062 - val_loss: 0.1080\n",
      "Epoch 298/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1057 - val_loss: 0.1100\n",
      "Epoch 299/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1056 - val_loss: 0.1069\n",
      "Epoch 300/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1069 - val_loss: 0.1077\n",
      "Epoch 301/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1049 - val_loss: 0.1083\n",
      "Epoch 302/400\n",
      "1200/1200 [==============================] - 0s 158us/sample - loss: 0.1055 - val_loss: 0.1098\n",
      "Epoch 303/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1062 - val_loss: 0.1074\n",
      "Epoch 304/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1057 - val_loss: 0.1112\n",
      "Epoch 305/400\n",
      "1200/1200 [==============================] - 0s 165us/sample - loss: 0.1098 - val_loss: 0.1114\n",
      "Epoch 306/400\n",
      "1200/1200 [==============================] - 0s 159us/sample - loss: 0.1050 - val_loss: 0.1087\n",
      "Epoch 307/400\n",
      "1200/1200 [==============================] - 0s 193us/sample - loss: 0.1114 - val_loss: 0.1154\n",
      "Epoch 308/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1068 - val_loss: 0.1067\n",
      "Epoch 309/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1048 - val_loss: 0.1093\n",
      "Epoch 310/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1058 - val_loss: 0.1067\n",
      "Epoch 311/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1043 - val_loss: 0.1087\n",
      "Epoch 312/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1032 - val_loss: 0.1163\n",
      "Epoch 313/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1055 - val_loss: 0.1082\n",
      "Epoch 314/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1038 - val_loss: 0.1064\n",
      "Epoch 315/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1043 - val_loss: 0.1065\n",
      "Epoch 316/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1046 - val_loss: 0.1138\n",
      "Epoch 317/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1042 - val_loss: 0.1066\n",
      "Epoch 318/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1046 - val_loss: 0.1059\n",
      "Epoch 319/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1049 - val_loss: 0.1180\n",
      "Epoch 320/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1063 - val_loss: 0.1059\n",
      "Epoch 321/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1040 - val_loss: 0.1065\n",
      "Epoch 322/400\n",
      "1200/1200 [==============================] - 0s 164us/sample - loss: 0.1030 - val_loss: 0.1059\n",
      "Epoch 323/400\n",
      "1200/1200 [==============================] - 0s 178us/sample - loss: 0.1058 - val_loss: 0.1057\n",
      "Epoch 324/400\n",
      "1200/1200 [==============================] - 0s 193us/sample - loss: 0.1030 - val_loss: 0.1072\n",
      "Epoch 325/400\n",
      "1200/1200 [==============================] - 0s 163us/sample - loss: 0.1040 - val_loss: 0.1064\n",
      "Epoch 326/400\n",
      "1200/1200 [==============================] - 0s 162us/sample - loss: 0.1025 - val_loss: 0.1067\n",
      "Epoch 327/400\n",
      "1200/1200 [==============================] - 0s 160us/sample - loss: 0.1034 - val_loss: 0.1066\n",
      "Epoch 328/400\n",
      "1200/1200 [==============================] - 0s 165us/sample - loss: 0.1034 - val_loss: 0.1061\n",
      "Epoch 329/400\n",
      "1200/1200 [==============================] - 0s 158us/sample - loss: 0.1031 - val_loss: 0.1061\n",
      "Epoch 330/400\n",
      "1200/1200 [==============================] - 0s 160us/sample - loss: 0.1034 - val_loss: 0.1071\n",
      "Epoch 331/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: nan - val_loss: nan\n",
      "Epoch 332/400\n",
      "1200/1200 [==============================] - 0s 162us/sample - loss: nan - val_loss: nan\n",
      "Epoch 333/400\n",
      "1200/1200 [==============================] - 0s 164us/sample - loss: nan - val_loss: nan\n",
      "Epoch 334/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: nan - val_loss: nan\n",
      "Epoch 335/400\n",
      "1200/1200 [==============================] - 0s 160us/sample - loss: nan - val_loss: nan\n",
      "Epoch 336/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: nan - val_loss: nan\n",
      "Epoch 337/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: nan - val_loss: nan\n",
      "Epoch 338/400\n",
      "1200/1200 [==============================] - 0s 158us/sample - loss: nan - val_loss: nan\n",
      "Epoch 339/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: nan - val_loss: nan\n",
      "Epoch 340/400\n",
      "1200/1200 [==============================] - 0s 159us/sample - loss: nan - val_loss: nan\n",
      "Epoch 341/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: nan - val_loss: nan\n",
      "Epoch 342/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: nan - val_loss: nan\n",
      "Epoch 343/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: nan - val_loss: nan\n",
      "Epoch 344/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 345/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: nan - val_loss: nan\n",
      "Epoch 346/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: nan - val_loss: nan\n",
      "Epoch 347/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 348/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: nan - val_loss: nan\n",
      "Epoch 349/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: nan - val_loss: nan\n",
      "Epoch 350/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: nan - val_loss: nan\n",
      "Epoch 351/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: nan - val_loss: nan\n",
      "Epoch 352/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: nan - val_loss: nan\n",
      "Epoch 353/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: nan - val_loss: nan\n",
      "Epoch 354/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 355/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: nan - val_loss: nan\n",
      "Epoch 356/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 357/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: nan - val_loss: nan\n",
      "Epoch 358/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: nan - val_loss: nan\n",
      "Epoch 359/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: nan - val_loss: nan\n",
      "Epoch 360/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: nan - val_loss: nan\n",
      "Epoch 361/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: nan - val_loss: nan\n",
      "Epoch 362/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: nan - val_loss: nan\n",
      "Epoch 363/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: nan - val_loss: nan\n",
      "Epoch 364/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: nan - val_loss: nan\n",
      "Epoch 365/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: nan - val_loss: nan\n",
      "Epoch 366/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: nan - val_loss: nan\n",
      "Epoch 367/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: nan - val_loss: nan\n",
      "Epoch 368/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: nan - val_loss: nan\n",
      "Epoch 369/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: nan - val_loss: nan\n",
      "Epoch 370/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 371/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: nan - val_loss: nan\n",
      "Epoch 372/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: nan - val_loss: nan\n",
      "Epoch 373/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: nan - val_loss: nan\n",
      "Epoch 374/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: nan - val_loss: nan\n",
      "Epoch 375/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: nan - val_loss: nan\n",
      "Epoch 376/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 377/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: nan - val_loss: nan\n",
      "Epoch 378/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: nan - val_loss: nan\n",
      "Epoch 379/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: nan - val_loss: nan\n",
      "Epoch 380/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: nan - val_loss: nan\n",
      "Epoch 381/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: nan - val_loss: nan\n",
      "Epoch 382/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: nan - val_loss: nan\n",
      "Epoch 383/400\n",
      "1200/1200 [==============================] - 0s 173us/sample - loss: nan - val_loss: nan\n",
      "Epoch 384/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: nan - val_loss: nan\n",
      "Epoch 385/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: nan - val_loss: nan\n",
      "Epoch 386/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: nan - val_loss: nan\n",
      "Epoch 387/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: nan - val_loss: nan\n",
      "Epoch 388/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: nan - val_loss: nan\n",
      "Epoch 389/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: nan - val_loss: nan\n",
      "Epoch 390/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: nan - val_loss: nan\n",
      "Epoch 391/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: nan - val_loss: nan\n",
      "Epoch 392/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 393/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: nan - val_loss: nan\n",
      "Epoch 394/400\n",
      "1200/1200 [==============================] - 0s 161us/sample - loss: nan - val_loss: nan\n",
      "Epoch 395/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: nan - val_loss: nan\n",
      "Epoch 396/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: nan - val_loss: nan\n",
      "Epoch 397/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: nan - val_loss: nan\n",
      "Epoch 398/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: nan - val_loss: nan\n",
      "Epoch 399/400\n",
      "1200/1200 [==============================] - 0s 189us/sample - loss: nan - val_loss: nan\n",
      "Epoch 400/400\n",
      "1200/1200 [==============================] - 0s 188us/sample - loss: nan - val_loss: nan\n",
      "260/260 [==============================] - 0s 57us/sample - loss: nan\n",
      "nan\n",
      "Train on 1200 samples, validate on 260 samples\n",
      "Epoch 1/400\n",
      "1200/1200 [==============================] - 1s 539us/sample - loss: 6.7501 - val_loss: 5.4811\n",
      "Epoch 2/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 4.7592 - val_loss: 4.0608\n",
      "Epoch 3/400\n",
      "1200/1200 [==============================] - 0s 161us/sample - loss: 3.4489 - val_loss: 2.8405\n",
      "Epoch 4/400\n",
      "1200/1200 [==============================] - 0s 161us/sample - loss: 2.2318 - val_loss: 1.6410\n",
      "Epoch 5/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 1.1395 - val_loss: 0.6860\n",
      "Epoch 6/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.4140 - val_loss: 0.2668\n",
      "Epoch 7/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.2566 - val_loss: 0.2593\n",
      "Epoch 8/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.2546 - val_loss: 0.2580\n",
      "Epoch 9/400\n",
      "1200/1200 [==============================] - 0s 177us/sample - loss: 0.2532 - val_loss: 0.2565\n",
      "Epoch 10/400\n",
      "1200/1200 [==============================] - 0s 190us/sample - loss: 0.2520 - val_loss: 0.2555\n",
      "Epoch 11/400\n",
      "1200/1200 [==============================] - 0s 184us/sample - loss: 0.2506 - val_loss: 0.2543\n",
      "Epoch 12/400\n",
      "1200/1200 [==============================] - 0s 164us/sample - loss: 0.2495 - val_loss: 0.2519\n",
      "Epoch 13/400\n",
      "1200/1200 [==============================] - 0s 162us/sample - loss: 0.2473 - val_loss: 0.2497\n",
      "Epoch 14/400\n",
      "1200/1200 [==============================] - 0s 174us/sample - loss: 0.2452 - val_loss: 0.2476\n",
      "Epoch 15/400\n",
      "1200/1200 [==============================] - 0s 164us/sample - loss: 0.2431 - val_loss: 0.2461\n",
      "Epoch 16/400\n",
      "1200/1200 [==============================] - 0s 166us/sample - loss: 0.2412 - val_loss: 0.2434\n",
      "Epoch 17/400\n",
      "1200/1200 [==============================] - 0s 167us/sample - loss: 0.2391 - val_loss: 0.2414\n",
      "Epoch 18/400\n",
      "1200/1200 [==============================] - 0s 159us/sample - loss: 0.2372 - val_loss: 0.2395\n",
      "Epoch 19/400\n",
      "1200/1200 [==============================] - 0s 165us/sample - loss: 0.2355 - val_loss: 0.2374\n",
      "Epoch 20/400\n",
      "1200/1200 [==============================] - 0s 160us/sample - loss: 0.2332 - val_loss: 0.2360\n",
      "Epoch 21/400\n",
      "1200/1200 [==============================] - 0s 163us/sample - loss: 0.2316 - val_loss: 0.2334\n",
      "Epoch 22/400\n",
      "1200/1200 [==============================] - 0s 161us/sample - loss: 0.2291 - val_loss: 0.2319\n",
      "Epoch 23/400\n",
      "1200/1200 [==============================] - 0s 169us/sample - loss: 0.2277 - val_loss: 0.2290\n",
      "Epoch 24/400\n",
      "1200/1200 [==============================] - 0s 171us/sample - loss: 0.2256 - val_loss: 0.2268\n",
      "Epoch 25/400\n",
      "1200/1200 [==============================] - 0s 172us/sample - loss: 0.2233 - val_loss: 0.2252\n",
      "Epoch 26/400\n",
      "1200/1200 [==============================] - 0s 165us/sample - loss: 0.2213 - val_loss: 0.2229\n",
      "Epoch 27/400\n",
      "1200/1200 [==============================] - 0s 163us/sample - loss: 0.2191 - val_loss: 0.2211\n",
      "Epoch 28/400\n",
      "1200/1200 [==============================] - 0s 160us/sample - loss: 0.2170 - val_loss: 0.2192\n",
      "Epoch 29/400\n",
      "1200/1200 [==============================] - 0s 170us/sample - loss: 0.2147 - val_loss: 0.2173\n",
      "Epoch 30/400\n",
      "1200/1200 [==============================] - 0s 173us/sample - loss: 0.2126 - val_loss: 0.2152\n",
      "Epoch 31/400\n",
      "1200/1200 [==============================] - 0s 164us/sample - loss: 0.2107 - val_loss: 0.2125\n",
      "Epoch 32/400\n",
      "1200/1200 [==============================] - 0s 166us/sample - loss: 0.2085 - val_loss: 0.2107\n",
      "Epoch 33/400\n",
      "1200/1200 [==============================] - 0s 168us/sample - loss: 0.2067 - val_loss: 0.2085\n",
      "Epoch 34/400\n",
      "1200/1200 [==============================] - 0s 176us/sample - loss: 0.2051 - val_loss: 0.2078\n",
      "Epoch 35/400\n",
      "1200/1200 [==============================] - 0s 171us/sample - loss: 0.2035 - val_loss: 0.2062\n",
      "Epoch 36/400\n",
      "1200/1200 [==============================] - 0s 177us/sample - loss: 0.2022 - val_loss: 0.2054\n",
      "Epoch 37/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.2008 - val_loss: 0.2042\n",
      "Epoch 38/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1992 - val_loss: 0.2051\n",
      "Epoch 39/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1979 - val_loss: 0.2019\n",
      "Epoch 40/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1977 - val_loss: 0.2013\n",
      "Epoch 41/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: 0.1961 - val_loss: 0.2017\n",
      "Epoch 42/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1959 - val_loss: 0.2016\n",
      "Epoch 43/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1949 - val_loss: 0.2013\n",
      "Epoch 44/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1948 - val_loss: 0.1983\n",
      "Epoch 45/400\n",
      "1200/1200 [==============================] - 0s 186us/sample - loss: 0.1940 - val_loss: 0.1973\n",
      "Epoch 46/400\n",
      "1200/1200 [==============================] - 0s 158us/sample - loss: 0.1934 - val_loss: 0.1967\n",
      "Epoch 47/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1939 - val_loss: 0.1958\n",
      "Epoch 48/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1915 - val_loss: 0.1956\n",
      "Epoch 49/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1913 - val_loss: 0.1947\n",
      "Epoch 50/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1903 - val_loss: 0.1970\n",
      "Epoch 51/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: 0.1897 - val_loss: 0.1934\n",
      "Epoch 52/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1893 - val_loss: 0.1926\n",
      "Epoch 53/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1889 - val_loss: 0.1922\n",
      "Epoch 54/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1883 - val_loss: 0.1913\n",
      "Epoch 55/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1876 - val_loss: 0.1916\n",
      "Epoch 56/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1865 - val_loss: 0.1956\n",
      "Epoch 57/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1874 - val_loss: 0.1889\n",
      "Epoch 58/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1856 - val_loss: 0.1908\n",
      "Epoch 59/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1857 - val_loss: 0.1876\n",
      "Epoch 60/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1843 - val_loss: 0.1877\n",
      "Epoch 61/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1839 - val_loss: 0.1876\n",
      "Epoch 62/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1824 - val_loss: 0.1863\n",
      "Epoch 63/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1825 - val_loss: 0.1868\n",
      "Epoch 64/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.1827 - val_loss: 0.1839\n",
      "Epoch 65/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.1833 - val_loss: 0.1829\n",
      "Epoch 66/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1803 - val_loss: 0.1825\n",
      "Epoch 67/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1801 - val_loss: 0.1840\n",
      "Epoch 68/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1803 - val_loss: 0.1813\n",
      "Epoch 69/400\n",
      "1200/1200 [==============================] - 0s 158us/sample - loss: 0.1788 - val_loss: 0.1810\n",
      "Epoch 70/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1777 - val_loss: 0.1801\n",
      "Epoch 71/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1774 - val_loss: 0.1791\n",
      "Epoch 72/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1767 - val_loss: 0.1785\n",
      "Epoch 73/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1754 - val_loss: 0.1773\n",
      "Epoch 74/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1747 - val_loss: 0.1772\n",
      "Epoch 75/400\n",
      "1200/1200 [==============================] - 0s 174us/sample - loss: 0.1742 - val_loss: 0.1758\n",
      "Epoch 76/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: 0.1734 - val_loss: 0.1750\n",
      "Epoch 77/400\n",
      "1200/1200 [==============================] - 0s 193us/sample - loss: 0.1733 - val_loss: 0.1741\n",
      "Epoch 78/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: 0.1731 - val_loss: 0.1735\n",
      "Epoch 79/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.1719 - val_loss: 0.1755\n",
      "Epoch 80/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1708 - val_loss: 0.1714\n",
      "Epoch 81/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1704 - val_loss: 0.1706\n",
      "Epoch 82/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1692 - val_loss: 0.1702\n",
      "Epoch 83/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1685 - val_loss: 0.1686\n",
      "Epoch 84/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1673 - val_loss: 0.1677\n",
      "Epoch 85/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1662 - val_loss: 0.1665\n",
      "Epoch 86/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1664 - val_loss: 0.1652\n",
      "Epoch 87/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1650 - val_loss: 0.1633\n",
      "Epoch 88/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1635 - val_loss: 0.1646\n",
      "Epoch 89/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1637 - val_loss: 0.1618\n",
      "Epoch 90/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1628 - val_loss: 0.1635\n",
      "Epoch 91/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1617 - val_loss: 0.1595\n",
      "Epoch 92/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1616 - val_loss: 0.1575\n",
      "Epoch 93/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.1605 - val_loss: 0.1572\n",
      "Epoch 94/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1597 - val_loss: 0.1569\n",
      "Epoch 95/400\n",
      "1200/1200 [==============================] - 0s 172us/sample - loss: 0.1590 - val_loss: 0.1557\n",
      "Epoch 96/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1576 - val_loss: 0.1538\n",
      "Epoch 97/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1567 - val_loss: 0.1535\n",
      "Epoch 98/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1567 - val_loss: 0.1541\n",
      "Epoch 99/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1557 - val_loss: 0.1510\n",
      "Epoch 100/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1559 - val_loss: 0.1511\n",
      "Epoch 101/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1565 - val_loss: 0.1512\n",
      "Epoch 102/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1563 - val_loss: 0.1491\n",
      "Epoch 103/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1537 - val_loss: 0.1523\n",
      "Epoch 104/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1541 - val_loss: 0.1490\n",
      "Epoch 105/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1522 - val_loss: 0.1512\n",
      "Epoch 106/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1521 - val_loss: 0.1487\n",
      "Epoch 107/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1525 - val_loss: 0.1514\n",
      "Epoch 108/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1522 - val_loss: 0.1492\n",
      "Epoch 109/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1505 - val_loss: 0.1481\n",
      "Epoch 110/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1521 - val_loss: 0.1461\n",
      "Epoch 111/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1498 - val_loss: 0.1468\n",
      "Epoch 112/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1495 - val_loss: 0.1460\n",
      "Epoch 113/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1496 - val_loss: 0.1470\n",
      "Epoch 114/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1485 - val_loss: 0.1445\n",
      "Epoch 115/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1479 - val_loss: 0.1447\n",
      "Epoch 116/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1493 - val_loss: 0.1513\n",
      "Epoch 117/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1490 - val_loss: 0.1438\n",
      "Epoch 118/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1470 - val_loss: 0.1431\n",
      "Epoch 119/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1463 - val_loss: 0.1430\n",
      "Epoch 120/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1476 - val_loss: 0.1446\n",
      "Epoch 121/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1463 - val_loss: 0.1423\n",
      "Epoch 122/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1460 - val_loss: 0.1416\n",
      "Epoch 123/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1450 - val_loss: 0.1422\n",
      "Epoch 124/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1467 - val_loss: 0.1458\n",
      "Epoch 125/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1463 - val_loss: 0.1493\n",
      "Epoch 126/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1457 - val_loss: 0.1406\n",
      "Epoch 127/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.1436 - val_loss: 0.1406\n",
      "Epoch 128/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1453 - val_loss: 0.1418\n",
      "Epoch 129/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1431 - val_loss: 0.1389\n",
      "Epoch 130/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1424 - val_loss: 0.1392\n",
      "Epoch 131/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1437 - val_loss: 0.1418\n",
      "Epoch 132/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1430 - val_loss: 0.1401\n",
      "Epoch 133/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1437 - val_loss: 0.1381\n",
      "Epoch 134/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1425 - val_loss: 0.1401\n",
      "Epoch 135/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: 0.1419 - val_loss: 0.1402\n",
      "Epoch 136/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1419 - val_loss: 0.1372\n",
      "Epoch 137/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1408 - val_loss: 0.1380\n",
      "Epoch 138/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1421 - val_loss: 0.1415\n",
      "Epoch 139/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1403 - val_loss: 0.1370\n",
      "Epoch 140/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1389 - val_loss: 0.1360\n",
      "Epoch 141/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1387 - val_loss: 0.1358\n",
      "Epoch 142/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1383 - val_loss: 0.1356\n",
      "Epoch 143/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1379 - val_loss: 0.1366\n",
      "Epoch 144/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1392 - val_loss: 0.1357\n",
      "Epoch 145/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1387 - val_loss: 0.1356\n",
      "Epoch 146/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1363 - val_loss: 0.1340\n",
      "Epoch 147/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1363 - val_loss: 0.1369\n",
      "Epoch 148/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1359 - val_loss: 0.1336\n",
      "Epoch 149/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1354 - val_loss: 0.1380\n",
      "Epoch 150/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1372 - val_loss: 0.1354\n",
      "Epoch 151/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1345 - val_loss: 0.1341\n",
      "Epoch 152/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1368 - val_loss: 0.1334\n",
      "Epoch 153/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1337 - val_loss: 0.1328\n",
      "Epoch 154/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1343 - val_loss: 0.1315\n",
      "Epoch 155/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1334 - val_loss: 0.1319\n",
      "Epoch 156/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1325 - val_loss: 0.1316\n",
      "Epoch 157/400\n",
      "1200/1200 [==============================] - 0s 163us/sample - loss: 0.1337 - val_loss: 0.1307\n",
      "Epoch 158/400\n",
      "1200/1200 [==============================] - 0s 144us/sample - loss: 0.1318 - val_loss: 0.1357\n",
      "Epoch 159/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1331 - val_loss: 0.1299\n",
      "Epoch 160/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1324 - val_loss: 0.1306\n",
      "Epoch 161/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1326 - val_loss: 0.1344\n",
      "Epoch 162/400\n",
      "1200/1200 [==============================] - 0s 160us/sample - loss: 0.1321 - val_loss: 0.1299\n",
      "Epoch 163/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1300 - val_loss: 0.1291\n",
      "Epoch 164/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1302 - val_loss: 0.1335\n",
      "Epoch 165/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1297 - val_loss: 0.1328\n",
      "Epoch 166/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1312 - val_loss: 0.1284\n",
      "Epoch 167/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1289 - val_loss: 0.1308\n",
      "Epoch 168/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1292 - val_loss: 0.1276\n",
      "Epoch 169/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1284 - val_loss: 0.1273\n",
      "Epoch 170/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1295 - val_loss: 0.1283\n",
      "Epoch 171/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1274 - val_loss: 0.1263\n",
      "Epoch 172/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1285 - val_loss: 0.1289\n",
      "Epoch 173/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1265 - val_loss: 0.1263\n",
      "Epoch 174/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1267 - val_loss: 0.1283\n",
      "Epoch 175/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1256 - val_loss: 0.1258\n",
      "Epoch 176/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1263 - val_loss: 0.1268\n",
      "Epoch 177/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1263 - val_loss: 0.1254\n",
      "Epoch 178/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1255 - val_loss: 0.1273\n",
      "Epoch 179/400\n",
      "1200/1200 [==============================] - 0s 144us/sample - loss: 0.1255 - val_loss: 0.1254\n",
      "Epoch 180/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1262 - val_loss: 0.1264\n",
      "Epoch 181/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1249 - val_loss: 0.1268\n",
      "Epoch 182/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1249 - val_loss: 0.1239\n",
      "Epoch 183/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1240 - val_loss: 0.1253\n",
      "Epoch 184/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1230 - val_loss: 0.1246\n",
      "Epoch 185/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1240 - val_loss: 0.1251\n",
      "Epoch 186/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1235 - val_loss: 0.1266\n",
      "Epoch 187/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1238 - val_loss: 0.1224\n",
      "Epoch 188/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1224 - val_loss: 0.1227\n",
      "Epoch 189/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1241 - val_loss: 0.1222\n",
      "Epoch 190/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1211 - val_loss: 0.1246\n",
      "Epoch 191/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1207 - val_loss: 0.1223\n",
      "Epoch 192/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1224 - val_loss: 0.1216\n",
      "Epoch 193/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1205 - val_loss: 0.1223\n",
      "Epoch 194/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1210 - val_loss: 0.1231\n",
      "Epoch 195/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1218 - val_loss: 0.1236\n",
      "Epoch 196/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1202 - val_loss: 0.1263\n",
      "Epoch 197/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1191 - val_loss: 0.1251\n",
      "Epoch 198/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1188 - val_loss: 0.1207\n",
      "Epoch 199/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1203 - val_loss: 0.1205\n",
      "Epoch 200/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1198 - val_loss: 0.1204\n",
      "Epoch 201/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1192 - val_loss: 0.1218\n",
      "Epoch 202/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1195 - val_loss: 0.1199\n",
      "Epoch 203/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1203 - val_loss: 0.1210\n",
      "Epoch 204/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1209 - val_loss: 0.1212\n",
      "Epoch 205/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1205 - val_loss: 0.1217\n",
      "Epoch 206/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1169 - val_loss: 0.1193\n",
      "Epoch 207/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1174 - val_loss: 0.1194\n",
      "Epoch 208/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1179 - val_loss: 0.1216\n",
      "Epoch 209/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1170 - val_loss: 0.1207\n",
      "Epoch 210/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1165 - val_loss: 0.1213\n",
      "Epoch 211/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1173 - val_loss: 0.1185\n",
      "Epoch 212/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1159 - val_loss: 0.1192\n",
      "Epoch 213/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.1162 - val_loss: 0.1202\n",
      "Epoch 214/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1195 - val_loss: 0.1225\n",
      "Epoch 215/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1152 - val_loss: 0.1177\n",
      "Epoch 216/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1156 - val_loss: 0.1190\n",
      "Epoch 217/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1139 - val_loss: 0.1181\n",
      "Epoch 218/400\n",
      "1200/1200 [==============================] - 0s 176us/sample - loss: 0.1152 - val_loss: 0.1169\n",
      "Epoch 219/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1163 - val_loss: 0.1168\n",
      "Epoch 220/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1168 - val_loss: 0.1170\n",
      "Epoch 221/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1163 - val_loss: 0.1181\n",
      "Epoch 222/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1197 - val_loss: 0.1244\n",
      "Epoch 223/400\n",
      "1200/1200 [==============================] - 0s 158us/sample - loss: 0.1139 - val_loss: 0.1168\n",
      "Epoch 224/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1139 - val_loss: 0.1182\n",
      "Epoch 225/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1146 - val_loss: 0.1214\n",
      "Epoch 226/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1135 - val_loss: 0.1192\n",
      "Epoch 227/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1146 - val_loss: 0.1220\n",
      "Epoch 228/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1160 - val_loss: 0.1165\n",
      "Epoch 229/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1120 - val_loss: 0.1156\n",
      "Epoch 230/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1134 - val_loss: 0.1148\n",
      "Epoch 231/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1127 - val_loss: 0.1162\n",
      "Epoch 232/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1121 - val_loss: 0.1150\n",
      "Epoch 233/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1120 - val_loss: 0.1156\n",
      "Epoch 234/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1125 - val_loss: 0.1189\n",
      "Epoch 235/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1155 - val_loss: 0.1153\n",
      "Epoch 236/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1113 - val_loss: 0.1151\n",
      "Epoch 237/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1149 - val_loss: 0.1143\n",
      "Epoch 238/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1104 - val_loss: 0.1143\n",
      "Epoch 239/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1118 - val_loss: 0.1186\n",
      "Epoch 240/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1111 - val_loss: 0.1130\n",
      "Epoch 241/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1116 - val_loss: 0.1172\n",
      "Epoch 242/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1108 - val_loss: 0.1149\n",
      "Epoch 243/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1099 - val_loss: 0.1129\n",
      "Epoch 244/400\n",
      "1200/1200 [==============================] - 0s 162us/sample - loss: 0.1102 - val_loss: 0.1131\n",
      "Epoch 245/400\n",
      "1200/1200 [==============================] - 0s 165us/sample - loss: 0.1106 - val_loss: 0.1179\n",
      "Epoch 246/400\n",
      "1200/1200 [==============================] - 0s 173us/sample - loss: 0.1108 - val_loss: 0.1122\n",
      "Epoch 247/400\n",
      "1200/1200 [==============================] - 0s 171us/sample - loss: 0.1098 - val_loss: 0.1147\n",
      "Epoch 248/400\n",
      "1200/1200 [==============================] - 0s 171us/sample - loss: 0.1095 - val_loss: 0.1124\n",
      "Epoch 249/400\n",
      "1200/1200 [==============================] - 0s 170us/sample - loss: 0.1111 - val_loss: 0.1165\n",
      "Epoch 250/400\n",
      "1200/1200 [==============================] - 0s 166us/sample - loss: 0.1100 - val_loss: 0.1151\n",
      "Epoch 251/400\n",
      "1200/1200 [==============================] - 0s 180us/sample - loss: 0.1106 - val_loss: 0.1132\n",
      "Epoch 252/400\n",
      "1200/1200 [==============================] - 0s 166us/sample - loss: 0.1088 - val_loss: 0.1137\n",
      "Epoch 253/400\n",
      "1200/1200 [==============================] - 0s 164us/sample - loss: 0.1074 - val_loss: 0.1122\n",
      "Epoch 254/400\n",
      "1200/1200 [==============================] - 0s 169us/sample - loss: 0.1093 - val_loss: 0.1135\n",
      "Epoch 255/400\n",
      "1200/1200 [==============================] - 0s 172us/sample - loss: 0.1089 - val_loss: 0.1123\n",
      "Epoch 256/400\n",
      "1200/1200 [==============================] - 0s 168us/sample - loss: 0.1105 - val_loss: 0.1195\n",
      "Epoch 257/400\n",
      "1200/1200 [==============================] - 0s 188us/sample - loss: 0.1086 - val_loss: 0.1123\n",
      "Epoch 258/400\n",
      "1200/1200 [==============================] - 0s 168us/sample - loss: 0.1065 - val_loss: 0.1119\n",
      "Epoch 259/400\n",
      "1200/1200 [==============================] - 0s 191us/sample - loss: 0.1085 - val_loss: 0.1123\n",
      "Epoch 260/400\n",
      "1200/1200 [==============================] - 0s 178us/sample - loss: 0.1070 - val_loss: 0.1130\n",
      "Epoch 261/400\n",
      "1200/1200 [==============================] - 0s 176us/sample - loss: 0.1091 - val_loss: 0.1153\n",
      "Epoch 262/400\n",
      "1200/1200 [==============================] - 0s 168us/sample - loss: 0.1088 - val_loss: 0.1110\n",
      "Epoch 263/400\n",
      "1200/1200 [==============================] - 0s 172us/sample - loss: 0.1069 - val_loss: 0.1115\n",
      "Epoch 264/400\n",
      "1200/1200 [==============================] - 0s 170us/sample - loss: 0.1076 - val_loss: 0.1119\n",
      "Epoch 265/400\n",
      "1200/1200 [==============================] - 0s 168us/sample - loss: 0.1076 - val_loss: 0.1116\n",
      "Epoch 266/400\n",
      "1200/1200 [==============================] - 0s 162us/sample - loss: 0.1090 - val_loss: 0.1108\n",
      "Epoch 267/400\n",
      "1200/1200 [==============================] - 0s 164us/sample - loss: 0.1065 - val_loss: 0.1098\n",
      "Epoch 268/400\n",
      "1200/1200 [==============================] - 0s 166us/sample - loss: 0.1061 - val_loss: 0.1116\n",
      "Epoch 269/400\n",
      "1200/1200 [==============================] - 0s 171us/sample - loss: 0.1059 - val_loss: 0.1093\n",
      "Epoch 270/400\n",
      "1200/1200 [==============================] - 0s 169us/sample - loss: 0.1101 - val_loss: 0.1091\n",
      "Epoch 271/400\n",
      "1200/1200 [==============================] - 0s 169us/sample - loss: 0.1047 - val_loss: 0.1105\n",
      "Epoch 272/400\n",
      "1200/1200 [==============================] - 0s 166us/sample - loss: 0.1059 - val_loss: 0.1092\n",
      "Epoch 273/400\n",
      "1200/1200 [==============================] - 0s 170us/sample - loss: 0.1062 - val_loss: 0.1116\n",
      "Epoch 274/400\n",
      "1200/1200 [==============================] - 0s 176us/sample - loss: 0.1083 - val_loss: 0.1128\n",
      "Epoch 275/400\n",
      "1200/1200 [==============================] - 0s 196us/sample - loss: 0.1060 - val_loss: 0.1086\n",
      "Epoch 276/400\n",
      "1200/1200 [==============================] - 0s 169us/sample - loss: 0.1058 - val_loss: 0.1156\n",
      "Epoch 277/400\n",
      "1200/1200 [==============================] - 0s 171us/sample - loss: 0.1060 - val_loss: 0.1112\n",
      "Epoch 278/400\n",
      "1200/1200 [==============================] - 0s 173us/sample - loss: 0.1050 - val_loss: 0.1310\n",
      "Epoch 279/400\n",
      "1200/1200 [==============================] - 0s 178us/sample - loss: 0.1097 - val_loss: 0.1080\n",
      "Epoch 280/400\n",
      "1200/1200 [==============================] - 0s 167us/sample - loss: 0.1045 - val_loss: 0.1106\n",
      "Epoch 281/400\n",
      "1200/1200 [==============================] - 0s 165us/sample - loss: 0.1059 - val_loss: 0.1155\n",
      "Epoch 282/400\n",
      "1200/1200 [==============================] - 0s 166us/sample - loss: 0.1059 - val_loss: 0.1092\n",
      "Epoch 283/400\n",
      "1200/1200 [==============================] - 0s 164us/sample - loss: 0.1070 - val_loss: 0.1146\n",
      "Epoch 284/400\n",
      "1200/1200 [==============================] - 0s 165us/sample - loss: 0.1042 - val_loss: 0.1107\n",
      "Epoch 285/400\n",
      "1200/1200 [==============================] - 0s 162us/sample - loss: 0.1052 - val_loss: 0.1096\n",
      "Epoch 286/400\n",
      "1200/1200 [==============================] - 0s 164us/sample - loss: 0.1046 - val_loss: 0.1089\n",
      "Epoch 287/400\n",
      "1200/1200 [==============================] - 0s 161us/sample - loss: 0.1055 - val_loss: 0.1115\n",
      "Epoch 288/400\n",
      "1200/1200 [==============================] - 0s 161us/sample - loss: 0.1080 - val_loss: 0.1075\n",
      "Epoch 289/400\n",
      "1200/1200 [==============================] - 0s 168us/sample - loss: 0.1028 - val_loss: 0.1093\n",
      "Epoch 290/400\n",
      "1200/1200 [==============================] - 0s 167us/sample - loss: 0.1030 - val_loss: 0.1100\n",
      "Epoch 291/400\n",
      "1200/1200 [==============================] - 0s 167us/sample - loss: 0.1052 - val_loss: 0.1170\n",
      "Epoch 292/400\n",
      "1200/1200 [==============================] - 0s 167us/sample - loss: 0.1057 - val_loss: 0.1092\n",
      "Epoch 293/400\n",
      "1200/1200 [==============================] - 0s 162us/sample - loss: 0.1035 - val_loss: 0.1074\n",
      "Epoch 294/400\n",
      "1200/1200 [==============================] - 0s 166us/sample - loss: 0.1031 - val_loss: 0.1153\n",
      "Epoch 295/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1043 - val_loss: 0.1063\n",
      "Epoch 296/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1030 - val_loss: 0.1084\n",
      "Epoch 297/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1040 - val_loss: 0.1092\n",
      "Epoch 298/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1052 - val_loss: 0.1137\n",
      "Epoch 299/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1046 - val_loss: 0.1079\n",
      "Epoch 300/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.1059 - val_loss: 0.1074\n",
      "Epoch 301/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1054 - val_loss: 0.1096\n",
      "Epoch 302/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1019 - val_loss: 0.1085\n",
      "Epoch 303/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1023 - val_loss: 0.1062\n",
      "Epoch 304/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1019 - val_loss: 0.1074\n",
      "Epoch 305/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1022 - val_loss: 0.1105\n",
      "Epoch 306/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1024 - val_loss: 0.1087\n",
      "Epoch 307/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1028 - val_loss: 0.1130\n",
      "Epoch 308/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1022 - val_loss: 0.1083\n",
      "Epoch 309/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1037 - val_loss: 0.1100\n",
      "Epoch 310/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1056 - val_loss: 0.1071\n",
      "Epoch 311/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1034 - val_loss: 0.1096\n",
      "Epoch 312/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1036 - val_loss: 0.1076\n",
      "Epoch 313/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1013 - val_loss: 0.1068\n",
      "Epoch 314/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1001 - val_loss: 0.1126\n",
      "Epoch 315/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1015 - val_loss: 0.1090\n",
      "Epoch 316/400\n",
      "1200/1200 [==============================] - 0s 212us/sample - loss: 0.1035 - val_loss: 0.1048\n",
      "Epoch 317/400\n",
      "1200/1200 [==============================] - 0s 173us/sample - loss: 0.1026 - val_loss: 0.1061\n",
      "Epoch 318/400\n",
      "1200/1200 [==============================] - 0s 169us/sample - loss: 0.1024 - val_loss: 0.1128\n",
      "Epoch 319/400\n",
      "1200/1200 [==============================] - 0s 159us/sample - loss: 0.1024 - val_loss: 0.1058\n",
      "Epoch 320/400\n",
      "1200/1200 [==============================] - 0s 161us/sample - loss: 0.1001 - val_loss: 0.1070\n",
      "Epoch 321/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1036 - val_loss: 0.1086\n",
      "Epoch 322/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1013 - val_loss: 0.1055\n",
      "Epoch 323/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1014 - val_loss: 0.1088\n",
      "Epoch 324/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.0993 - val_loss: 0.1053\n",
      "Epoch 325/400\n",
      "1200/1200 [==============================] - 0s 165us/sample - loss: 0.1006 - val_loss: 0.1071\n",
      "Epoch 326/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1007 - val_loss: 0.1076\n",
      "Epoch 327/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.1001 - val_loss: 0.1061\n",
      "Epoch 328/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.0986 - val_loss: 0.1085\n",
      "Epoch 329/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.1026 - val_loss: 0.1066\n",
      "Epoch 330/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.0996 - val_loss: 0.1060\n",
      "Epoch 331/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.1032 - val_loss: 0.1048\n",
      "Epoch 332/400\n",
      "1200/1200 [==============================] - 0s 160us/sample - loss: 0.0997 - val_loss: 0.1053\n",
      "Epoch 333/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.0995 - val_loss: 0.1065\n",
      "Epoch 334/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.1021 - val_loss: 0.1054\n",
      "Epoch 335/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.0991 - val_loss: 0.1116\n",
      "Epoch 336/400\n",
      "1200/1200 [==============================] - 0s 180us/sample - loss: 0.1009 - val_loss: 0.1060\n",
      "Epoch 337/400\n",
      "1200/1200 [==============================] - 0s 176us/sample - loss: 0.1002 - val_loss: 0.1074\n",
      "Epoch 338/400\n",
      "1200/1200 [==============================] - 0s 171us/sample - loss: 0.1018 - val_loss: 0.1063\n",
      "Epoch 339/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.1005 - val_loss: 0.1051\n",
      "Epoch 340/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1002 - val_loss: 0.1061\n",
      "Epoch 341/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.0998 - val_loss: 0.1058\n",
      "Epoch 342/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.0999 - val_loss: 0.1043\n",
      "Epoch 343/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.0992 - val_loss: 0.1052\n",
      "Epoch 344/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.0988 - val_loss: 0.1086\n",
      "Epoch 345/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.1001 - val_loss: 0.1046\n",
      "Epoch 346/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1004 - val_loss: 0.1046\n",
      "Epoch 347/400\n",
      "1200/1200 [==============================] - 0s 168us/sample - loss: 0.1046 - val_loss: 0.1061\n",
      "Epoch 348/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.0989 - val_loss: 0.1084\n",
      "Epoch 349/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.1010 - val_loss: 0.1095\n",
      "Epoch 350/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.0995 - val_loss: 0.1040\n",
      "Epoch 351/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.0989 - val_loss: 0.1085\n",
      "Epoch 352/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.1013 - val_loss: 0.1052\n",
      "Epoch 353/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.1001 - val_loss: 0.1070\n",
      "Epoch 354/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.0981 - val_loss: 0.1056\n",
      "Epoch 355/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.0978 - val_loss: 0.1155\n",
      "Epoch 356/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.0998 - val_loss: 0.1035\n",
      "Epoch 357/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.0981 - val_loss: 0.1055\n",
      "Epoch 358/400\n",
      "1200/1200 [==============================] - 0s 169us/sample - loss: 0.0998 - val_loss: 0.1043\n",
      "Epoch 359/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.0997 - val_loss: 0.1040\n",
      "Epoch 360/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.0967 - val_loss: 0.1120\n",
      "Epoch 361/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.0983 - val_loss: 0.1095\n",
      "Epoch 362/400\n",
      "1200/1200 [==============================] - 0s 146us/sample - loss: 0.0978 - val_loss: 0.1037\n",
      "Epoch 363/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.0971 - val_loss: 0.1045\n",
      "Epoch 364/400\n",
      "1200/1200 [==============================] - 0s 156us/sample - loss: 0.0975 - val_loss: 0.1035\n",
      "Epoch 365/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.0968 - val_loss: 0.1035\n",
      "Epoch 366/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.0968 - val_loss: 0.1073\n",
      "Epoch 367/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.0980 - val_loss: 0.1042\n",
      "Epoch 368/400\n",
      "1200/1200 [==============================] - 0s 172us/sample - loss: 0.0976 - val_loss: 0.1050\n",
      "Epoch 369/400\n",
      "1200/1200 [==============================] - 0s 163us/sample - loss: 0.0999 - val_loss: 0.1048\n",
      "Epoch 370/400\n",
      "1200/1200 [==============================] - 0s 153us/sample - loss: 0.0972 - val_loss: 0.1048\n",
      "Epoch 371/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.0969 - val_loss: 0.1119\n",
      "Epoch 372/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.0986 - val_loss: 0.1071\n",
      "Epoch 373/400\n",
      "1200/1200 [==============================] - 0s 145us/sample - loss: 0.0966 - val_loss: 0.1051\n",
      "Epoch 374/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.0972 - val_loss: 0.1071\n",
      "Epoch 375/400\n",
      "1200/1200 [==============================] - 0s 144us/sample - loss: 0.0996 - val_loss: 0.1034\n",
      "Epoch 376/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.0970 - val_loss: 0.1046\n",
      "Epoch 377/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.0977 - val_loss: 0.1037\n",
      "Epoch 378/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.0965 - val_loss: 0.1048\n",
      "Epoch 379/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.0963 - val_loss: 0.1047\n",
      "Epoch 380/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.0963 - val_loss: 0.1023\n",
      "Epoch 381/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.0982 - val_loss: 0.1032\n",
      "Epoch 382/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.0962 - val_loss: 0.1038\n",
      "Epoch 383/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.0986 - val_loss: 0.1110\n",
      "Epoch 384/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.0968 - val_loss: 0.1039\n",
      "Epoch 385/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.0960 - val_loss: 0.1030\n",
      "Epoch 386/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.0962 - val_loss: 0.1047\n",
      "Epoch 387/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.0984 - val_loss: 0.1033\n",
      "Epoch 388/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.0973 - val_loss: 0.1024\n",
      "Epoch 389/400\n",
      "1200/1200 [==============================] - 0s 149us/sample - loss: 0.0965 - val_loss: 0.1071\n",
      "Epoch 390/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.0996 - val_loss: 0.1025\n",
      "Epoch 391/400\n",
      "1200/1200 [==============================] - 0s 155us/sample - loss: 0.0958 - val_loss: 0.1021\n",
      "Epoch 392/400\n",
      "1200/1200 [==============================] - 0s 147us/sample - loss: 0.0944 - val_loss: 0.1041\n",
      "Epoch 393/400\n",
      "1200/1200 [==============================] - 0s 175us/sample - loss: 0.0962 - val_loss: 0.1067\n",
      "Epoch 394/400\n",
      "1200/1200 [==============================] - 0s 148us/sample - loss: 0.0975 - val_loss: 0.1036\n",
      "Epoch 395/400\n",
      "1200/1200 [==============================] - 0s 154us/sample - loss: 0.0986 - val_loss: 0.1035\n",
      "Epoch 396/400\n",
      "1200/1200 [==============================] - 0s 157us/sample - loss: 0.0970 - val_loss: 0.1034\n",
      "Epoch 397/400\n",
      "1200/1200 [==============================] - 0s 168us/sample - loss: 0.0956 - val_loss: 0.1042\n",
      "Epoch 398/400\n",
      "1200/1200 [==============================] - 0s 150us/sample - loss: 0.0970 - val_loss: 0.1071\n",
      "Epoch 399/400\n",
      "1200/1200 [==============================] - 0s 152us/sample - loss: 0.0962 - val_loss: 0.1018\n",
      "Epoch 400/400\n",
      "1200/1200 [==============================] - 0s 151us/sample - loss: 0.0965 - val_loss: 0.1121\n",
      "260/260 [==============================] - 0s 48us/sample - loss: 0.1121\n",
      "0.11214919090270996\n"
     ]
    }
   ],
   "source": [
    "# Sometimes the model gets stuck because of a local optima. Other times the gradients exploit. So we have to restart it\n",
    "initialLoss = 100\n",
    "finalLoss = np.nan\n",
    "while (initialLoss > 8 or (not finalLoss > 0)):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(units=100, activation = \"relu\", input_shape = [X_train.shape[1],],kernel_initializer=keras.initializers.GlorotNormal()))\n",
    "    model.add(keras.layers.Dense(units=75, activation = \"relu\",kernel_initializer=keras.initializers.GlorotNormal()))\n",
    "    model.add(keras.layers.Dense(units=50, activation = \"relu\",kernel_initializer=keras.initializers.GlorotNormal()))\n",
    "    model.add(keras.layers.Dense(units=25, activation = \"relu\",kernel_initializer=keras.initializers.GlorotNormal()))\n",
    "    model.add(keras.layers.Dense(units=15, activation = \"relu\",kernel_initializer=keras.initializers.GlorotNormal()))\n",
    "    model.add(keras.layers.Dense(units=1,  activation = \"relu\",kernel_initializer=keras.initializers.GlorotNormal))\n",
    "    model.compile(optimizer = keras.optimizers.Adam(lr=0.0003), loss = rmsle_error)\n",
    "    history = model.fit (X_train, Y_train, batch_size=16, epochs = 400, verbose=1, validation_data = (X_val,Y_val))\n",
    "    initialLoss = history.history[\"loss\"][0]\n",
    "    finalLoss = history.history[\"loss\"][-1]\n",
    "    print (model.evaluate(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was succesfully saved!\n"
     ]
    }
   ],
   "source": [
    "predictions = np.squeeze(model.predict(test_data_clean), axis=1)\n",
    "output = pd.DataFrame({'Id':IdTest,'SalePrice':predictions})\n",
    "output.to_csv(\"my_submission.csv\", index=False)\n",
    "print (\"Your submission was succesfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
